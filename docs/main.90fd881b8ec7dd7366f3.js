/*! For license information please see main.90fd881b8ec7dd7366f3.js.LICENSE.txt */
(()=>{var t={238:(t,e,n)=>{t.exports=n.p+"1e3fce069b2ac7de8972354eb2a5732f.jpg"},377:(t,e,n)=>{var s=n(832),r=n(652),a=n(801),i=n(30),o=n(618),l=n(49),u=n(971);u.alea=s,u.xor128=r,u.xorwow=a,u.xorshift7=i,u.xor4096=o,u.tychei=l,t.exports=u},832:function(t,e,n){var s;!function(t,r,a){function i(t){var e,n=this,s=(e=4022871197,function(t){t=t.toString();for(var n=0;n<t.length;n++){var s=.02519603282416938*(e+=t.charCodeAt(n));s-=e=s>>>0,e=(s*=e)>>>0,e+=4294967296*(s-=e)}return 2.3283064365386963e-10*(e>>>0)});n.next=function(){var t=2091639*n.s0+2.3283064365386963e-10*n.c;return n.s0=n.s1,n.s1=n.s2,n.s2=t-(n.c=0|t)},n.c=1,n.s0=s(" "),n.s1=s(" "),n.s2=s(" "),n.s0-=s(t),n.s0<0&&(n.s0+=1),n.s1-=s(t),n.s1<0&&(n.s1+=1),n.s2-=s(t),n.s2<0&&(n.s2+=1),s=null}function o(t,e){return e.c=t.c,e.s0=t.s0,e.s1=t.s1,e.s2=t.s2,e}function l(t,e){var n=new i(t),s=e&&e.state,r=n.next;return r.int32=function(){return 4294967296*n.next()|0},r.double=function(){return r()+11102230246251565e-32*(2097152*r()|0)},r.quick=r,s&&("object"==typeof s&&o(s,n),r.state=function(){return o(n,{})}),r}r&&r.exports?r.exports=l:n.amdD&&n.amdO?void 0===(s=function(){return l}.call(e,n,e,r))||(r.exports=s):this.alea=l}(0,t=n.nmd(t),n.amdD)},49:function(t,e,n){var s;!function(t,r,a){function i(t){var e=this,n="";e.next=function(){var t=e.b,n=e.c,s=e.d,r=e.a;return t=t<<25^t>>>7^n,n=n-s|0,s=s<<24^s>>>8^r,r=r-t|0,e.b=t=t<<20^t>>>12^n,e.c=n=n-s|0,e.d=s<<16^n>>>16^r,e.a=r-t|0},e.a=0,e.b=0,e.c=-1640531527,e.d=1367130551,t===Math.floor(t)?(e.a=t/4294967296|0,e.b=0|t):n+=t;for(var s=0;s<n.length+20;s++)e.b^=0|n.charCodeAt(s),e.next()}function o(t,e){return e.a=t.a,e.b=t.b,e.c=t.c,e.d=t.d,e}function l(t,e){var n=new i(t),s=e&&e.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},r.int32=n.next,r.quick=r,s&&("object"==typeof s&&o(s,n),r.state=function(){return o(n,{})}),r}r&&r.exports?r.exports=l:n.amdD&&n.amdO?void 0===(s=function(){return l}.call(e,n,e,r))||(r.exports=s):this.tychei=l}(0,t=n.nmd(t),n.amdD)},652:function(t,e,n){var s;!function(t,r,a){function i(t){var e=this,n="";e.x=0,e.y=0,e.z=0,e.w=0,e.next=function(){var t=e.x^e.x<<11;return e.x=e.y,e.y=e.z,e.z=e.w,e.w^=e.w>>>19^t^t>>>8},t===(0|t)?e.x=t:n+=t;for(var s=0;s<n.length+64;s++)e.x^=0|n.charCodeAt(s),e.next()}function o(t,e){return e.x=t.x,e.y=t.y,e.z=t.z,e.w=t.w,e}function l(t,e){var n=new i(t),s=e&&e.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},r.int32=n.next,r.quick=r,s&&("object"==typeof s&&o(s,n),r.state=function(){return o(n,{})}),r}r&&r.exports?r.exports=l:n.amdD&&n.amdO?void 0===(s=function(){return l}.call(e,n,e,r))||(r.exports=s):this.xor128=l}(0,t=n.nmd(t),n.amdD)},618:function(t,e,n){var s;!function(t,r,a){function i(t){var e=this;e.next=function(){var t,n,s=e.w,r=e.X,a=e.i;return e.w=s=s+1640531527|0,n=r[a+34&127],t=r[a=a+1&127],n^=n<<13,t^=t<<17,n^=n>>>15,t^=t>>>12,n=r[a]=n^t,e.i=a,n+(s^s>>>16)|0},function(t,e){var n,s,r,a,i,o=[],l=128;for(e===(0|e)?(s=e,e=null):(e+="\0",s=0,l=Math.max(l,e.length)),r=0,a=-32;a<l;++a)e&&(s^=e.charCodeAt((a+32)%e.length)),0===a&&(i=s),s^=s<<10,s^=s>>>15,s^=s<<4,s^=s>>>13,a>=0&&(i=i+1640531527|0,r=0==(n=o[127&a]^=s+i)?r+1:0);for(r>=128&&(o[127&(e&&e.length||0)]=-1),r=127,a=512;a>0;--a)s=o[r+34&127],n=o[r=r+1&127],s^=s<<13,n^=n<<17,s^=s>>>15,n^=n>>>12,o[r]=s^n;t.w=i,t.X=o,t.i=r}(e,t)}function o(t,e){return e.i=t.i,e.w=t.w,e.X=t.X.slice(),e}function l(t,e){null==t&&(t=+new Date);var n=new i(t),s=e&&e.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},r.int32=n.next,r.quick=r,s&&(s.X&&o(s,n),r.state=function(){return o(n,{})}),r}r&&r.exports?r.exports=l:n.amdD&&n.amdO?void 0===(s=function(){return l}.call(e,n,e,r))||(r.exports=s):this.xor4096=l}(0,t=n.nmd(t),n.amdD)},30:function(t,e,n){var s;!function(t,r,a){function i(t){var e=this;e.next=function(){var t,n,s=e.x,r=e.i;return t=s[r],n=(t^=t>>>7)^t<<24,n^=(t=s[r+1&7])^t>>>10,n^=(t=s[r+3&7])^t>>>3,n^=(t=s[r+4&7])^t<<7,t=s[r+7&7],n^=(t^=t<<13)^t<<9,s[r]=n,e.i=r+1&7,n},function(t,e){var n,s=[];if(e===(0|e))s[0]=e;else for(e=""+e,n=0;n<e.length;++n)s[7&n]=s[7&n]<<15^e.charCodeAt(n)+s[n+1&7]<<13;for(;s.length<8;)s.push(0);for(n=0;n<8&&0===s[n];++n);for(8==n?s[7]=-1:s[n],t.x=s,t.i=0,n=256;n>0;--n)t.next()}(e,t)}function o(t,e){return e.x=t.x.slice(),e.i=t.i,e}function l(t,e){null==t&&(t=+new Date);var n=new i(t),s=e&&e.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},r.int32=n.next,r.quick=r,s&&(s.x&&o(s,n),r.state=function(){return o(n,{})}),r}r&&r.exports?r.exports=l:n.amdD&&n.amdO?void 0===(s=function(){return l}.call(e,n,e,r))||(r.exports=s):this.xorshift7=l}(0,t=n.nmd(t),n.amdD)},801:function(t,e,n){var s;!function(t,r,a){function i(t){var e=this,n="";e.next=function(){var t=e.x^e.x>>>2;return e.x=e.y,e.y=e.z,e.z=e.w,e.w=e.v,(e.d=e.d+362437|0)+(e.v=e.v^e.v<<4^t^t<<1)|0},e.x=0,e.y=0,e.z=0,e.w=0,e.v=0,t===(0|t)?e.x=t:n+=t;for(var s=0;s<n.length+64;s++)e.x^=0|n.charCodeAt(s),s==n.length&&(e.d=e.x<<10^e.x>>>4),e.next()}function o(t,e){return e.x=t.x,e.y=t.y,e.z=t.z,e.w=t.w,e.v=t.v,e.d=t.d,e}function l(t,e){var n=new i(t),s=e&&e.state,r=function(){return(n.next()>>>0)/4294967296};return r.double=function(){do{var t=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===t);return t},r.int32=n.next,r.quick=r,s&&("object"==typeof s&&o(s,n),r.state=function(){return o(n,{})}),r}r&&r.exports?r.exports=l:n.amdD&&n.amdO?void 0===(s=function(){return l}.call(e,n,e,r))||(r.exports=s):this.xorwow=l}(0,t=n.nmd(t),n.amdD)},971:(t,e,n)=>{var s;!function(r,a){var i,o=this,l=256,u=a.pow(l,6),h=a.pow(2,52),c=2*h,p=255;function d(t,e,n){var s=[],p=y(g((e=1==e?{entropy:!0}:e||{}).entropy?[t,b(r)]:null==t?function(){try{var t;return i&&(t=i.randomBytes)?t=t(l):(t=new Uint8Array(l),(o.crypto||o.msCrypto).getRandomValues(t)),b(t)}catch(t){var e=o.navigator,n=e&&e.plugins;return[+new Date,o,n,o.screen,b(r)]}}():t,3),s),d=new f(s),k=function(){for(var t=d.g(6),e=u,n=0;t<h;)t=(t+n)*l,e*=l,n=d.g(1);for(;t>=c;)t/=2,e/=2,n>>>=1;return(t+n)/e};return k.int32=function(){return 0|d.g(4)},k.quick=function(){return d.g(4)/4294967296},k.double=k,y(b(d.S),r),(e.pass||n||function(t,e,n,s){return s&&(s.S&&m(s,d),t.state=function(){return m(d,{})}),n?(a.random=t,e):t})(k,p,"global"in e?e.global:this==a,e.state)}function f(t){var e,n=t.length,s=this,r=0,a=s.i=s.j=0,i=s.S=[];for(n||(t=[n++]);r<l;)i[r]=r++;for(r=0;r<l;r++)i[r]=i[a=p&a+t[r%n]+(e=i[r])],i[a]=e;(s.g=function(t){for(var e,n=0,r=s.i,a=s.j,i=s.S;t--;)e=i[r=p&r+1],n=n*l+i[p&(i[r]=i[a=p&a+e])+(i[a]=e)];return s.i=r,s.j=a,n})(l)}function m(t,e){return e.i=t.i,e.j=t.j,e.S=t.S.slice(),e}function g(t,e){var n,s=[],r=typeof t;if(e&&"object"==r)for(n in t)try{s.push(g(t[n],e-1))}catch(t){}return s.length?s:"string"==r?t:t+"\0"}function y(t,e){for(var n,s=t+"",r=0;r<s.length;)e[p&r]=p&(n^=19*e[p&r])+s.charCodeAt(r++);return b(e)}function b(t){return String.fromCharCode.apply(0,t)}if(a.seedrandom=d,y(a.random(),r),t.exports){t.exports=d;try{i=n(906)}catch(t){}}else void 0===(s=function(){return d}.call(e,n,e,t))||(t.exports=s)}([],Math)},906:()=>{},352:()=>{},758:()=>{}},e={};function n(s){if(e[s])return e[s].exports;var r=e[s]={id:s,loaded:!1,exports:{}};return t[s].call(r.exports,r,r.exports,n),r.loaded=!0,r.exports}n.amdD=function(){throw new Error("define cannot be used indirect")},n.amdO={},n.n=t=>{var e=t&&t.__esModule?()=>t.default:()=>t;return n.d(e,{a:e}),e},n.d=(t,e)=>{for(var s in e)n.o(e,s)&&!n.o(t,s)&&Object.defineProperty(t,s,{enumerable:!0,get:e[s]})},n.g=function(){if("object"==typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(t){if("object"==typeof window)return window}}(),n.o=(t,e)=>Object.prototype.hasOwnProperty.call(t,e),n.r=t=>{"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(t,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(t,"__esModule",{value:!0})},n.nmd=t=>(t.paths=[],t.children||(t.children=[]),t),n.p="",(()=>{"use strict";var t={};n.r(t),n.d(t,{json:()=>dN});var e={};n.r(e),n.d(e,{json:()=>fN});var s={};n.r(s),n.d(s,{json:()=>mN});var r={};n.r(r),n.d(r,{json:()=>gN});var a={};n.r(a),n.d(a,{json:()=>yN});var i={};n.r(i),n.d(i,{json:()=>bN});var o={};n.r(o),n.d(o,{json:()=>kN});var l={};n.r(l),n.d(l,{json:()=>wN});var u={};n.r(u),n.d(u,{json:()=>xN});var h={};n.r(h),n.d(h,{json:()=>NN});var c={};n.r(c),n.d(c,{json:()=>vN});var p={};n.r(p),n.d(p,{json:()=>IN});var d={};n.r(d),n.d(d,{json:()=>SN});var f={};n.r(f),n.d(f,{json:()=>TN});var m={};n.r(m),n.d(m,{json:()=>EN});var g={};n.r(g),n.d(g,{json:()=>AN});var y={};n.r(y),n.d(y,{json:()=>DN});class b{constructor(t,e){this.backend=t,this.dataMover=e,this.data=new WeakMap,this.dataIdsCount=0}get(t){return this.data.has(t)||this.dataMover.moveData(this.backend,t),this.data.get(t)}set(t,e){this.dataIdsCount++,this.data.set(t,e)}has(t){return this.data.has(t)}delete(t){return this.dataIdsCount--,this.data.delete(t)}numDataIds(){return this.dataIdsCount}}class k{time(t){return w("time")}read(t){return w("read")}readSync(t){return w("readSync")}numDataIds(){return w("numDataIds")}disposeData(t){return w("disposeData")}write(t,e,n){return w("write")}move(t,e,n,s){return w("move")}memory(){return w("memory")}floatPrecision(){return w("floatPrecision")}epsilon(){return 32===this.floatPrecision()?1e-7:1e-4}batchMatMul(t,e,n,s){return w("batchMatMul")}fusedBatchMatMul({a:t,b:e,transposeA:n,transposeB:s,bias:r,activation:a,preluActivationWeights:i}){return w("fusedBatchMatMul")}slice(t,e,n){return w("slice")}stridedSlice(t,e,n,s){return w("stridedSlice")}unstack(t,e){return w("unstack")}reverse(t,e){return w("reverse")}concat(t,e){return w("concat")}neg(t){return w("neg")}add(t,e){return w("add")}addN(t){return w("addN")}subtract(t,e){return w("subtract")}multiply(t,e){return w("multiply")}realDivide(t,e){return w("realDivide")}floorDiv(t,e){return w("floorDiv")}sum(t,e){return w("sum")}prod(t,e){return w("prod")}unsortedSegmentSum(t,e,n){return w("unsortedSegmentSum")}argMin(t,e){return w("argMin")}argMax(t,e){return w("argMax")}equal(t,e){return w("equal")}notEqual(t,e){return w("notEqual")}less(t,e){return w("less")}lessEqual(t,e){return w("lessEqual")}greater(t,e){return w("greater")}greaterEqual(t,e){return w("greaterEqual")}logicalNot(t){return w("logicalNot")}logicalAnd(t,e){return w("logicalAnd")}logicalOr(t,e){return w("logicalOr")}where(t){return w("where")}select(t,e,n){return w("select")}topk(t,e,n){return w("topk")}min(t,e){return w("min")}minimum(t,e){return w("minimum")}mod(t,e){return w("mod")}max(t,e){return w("max")}maximum(t,e){return w("maximum")}all(t,e){return w("all")}any(t,e){return w("any")}squaredDifference(t,e){return w("squaredDifference")}ceil(t){return w("ceil")}floor(t){return w("floor")}round(t){return w("round")}sign(t){return w("sign")}isNaN(t){return w("isNaN")}isInf(t){return w("isInf")}isFinite(t){return w("isFinite")}pow(t,e){return w("pow")}exp(t){return w("exp")}expm1(t){return w("expm1")}softmax(t,e){return w("softmax")}log(t){return w("log")}log1p(t){return w("log1p")}sqrt(t){return w("sqrt")}rsqrt(t){return w("rsqrt")}square(t){return w("square")}reciprocal(t){return w("reciprocal")}relu(t){return w("relu")}relu6(t){return w("relu6")}prelu(t,e){return w("prelu")}elu(t){return w("elu")}eluDer(t,e){return w("eluDer")}selu(t){return w("selu")}int(t){return w("int")}clip(t,e,n){return w("clip")}abs(t){return w("abs")}complexAbs(t){return w("complexAbs")}sigmoid(t){return w("sigmoid")}softplus(t){return w("softplus")}sin(t){return w("sin")}cos(t){return w("cos")}tan(t){return w("tan")}asin(t){return w("asin")}acos(t){return w("acos")}atan(t){return w("atan")}atan2(t,e){return w("atan2")}sinh(t){return w("sinh")}cosh(t){return w("cosh")}tanh(t){return w("tanh")}asinh(t){return w("asinh")}acosh(t){return w("acosh")}atanh(t){return w("atanh")}erf(t){return w("erf")}step(t,e){return w("step")}fusedConv2d({input:t,filter:e,convInfo:n,bias:s,activation:r,preluActivationWeights:a}){return w("fusedConv2d")}conv2d(t,e,n){return w("conv2d")}conv2dDerInput(t,e,n){return w("conv2dDerInput")}conv2dDerFilter(t,e,n){return w("conv2dDerFilter")}fusedDepthwiseConv2D({input:t,filter:e,convInfo:n,bias:s,activation:r,preluActivationWeights:a}){return w("fusedDepthwiseConv2D")}depthwiseConv2D(t,e,n){return w("depthwiseConv2D")}depthwiseConv2DDerInput(t,e,n){return w("depthwiseConv2DDerInput")}depthwiseConv2DDerFilter(t,e,n){return w("depthwiseConv2DDerFilter")}conv3d(t,e,n){return w("conv3d")}conv3dDerInput(t,e,n){return w("conv3dDerInput")}conv3dDerFilter(t,e,n){return w("conv3dDerFilter")}maxPool(t,e){return w("maxPool")}maxPoolBackprop(t,e,n,s){return w("maxPoolBackprop")}avgPool(t,e){return w("avgPool")}avgPoolBackprop(t,e,n){return w("avgPoolBackprop")}avgPool3d(t,e){return w("avgPool3d")}avgPool3dBackprop(t,e,n){return w("avgPool3dBackprop")}maxPool3d(t,e){return w("maxPool3d")}maxPool3dBackprop(t,e,n,s){return w("maxPool3dBackprop")}reshape(t,e){return w("reshape")}cast(t,e){return w("cast")}tile(t,e){return w("tile")}pad(t,e,n){return w("pad")}transpose(t,e){return w("transpose")}gather(t,e,n,s=0){return w("gather")}gatherND(t,e){return w("gatherND")}scatterND(t,e,n){return w("scatterND")}batchToSpaceND(t,e,n){return w("batchToSpaceND")}spaceToBatchND(t,e,n){return w("spaceToBatchND")}resizeBilinear(t,e,n,s,r){return w("resizeBilinear")}resizeBilinearBackprop(t,e,n){return w("resizeBilinearBackprop")}resizeNearestNeighbor(t,e,n,s,r){return w("resizeNearestNeighbor")}resizeNearestNeighborBackprop(t,e,n){return w("resizeNearestNeighborBackprop")}batchNorm(t,e,n,s,r,a){return w("batchNorm")}localResponseNormalization4D(t,e,n,s,r){return w("localResponseNormalization4D")}LRNGrad(t,e,n,s,r,a,i){return w("LRNGrad")}multinomial(t,e,n,s){return w("multinomial")}oneHot(t,e,n,s){return w("oneHot")}cumsum(t,e,n,s){return w("cumsum")}nonMaxSuppression(t,e,n,s,r){return w("nonMaxSuppression")}fft(t){return w("fft")}ifft(t){return w("ifft")}complex(t,e){return w("complex")}real(t){return w("real")}imag(t){return w("imag")}cropAndResize(t,e,n,s,r,a){return w("cropAndResize")}depthToSpace(t,e,n){return w("depthToSpace")}split(t,e,n){return w("split")}sparseToDense(t,e,n,s){return w("sparseToDense")}diag(t){return w("diag")}fill(t,e,n){return w("fill")}onesLike(t){return w("onesLike")}zerosLike(t){return w("zerosLike")}linspace(t,e,n){return w("linspace")}dispose(){return w("dispose")}}function w(t){throw new Error(`'${t}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`)}function x(t){let e=t.length,n=0,s=0;for(;e>0;)s=Math.random()*e|0,e--,n=t[e],t[e]=t[s],t[s]=n}function N(t,e,n){return Math.max(t,Math.min(e,n))}function v(t,e){if(!t)throw new Error("string"==typeof e?e:e())}function I(t,e,n=""){v(A(t,e),(()=>n+` Shapes ${t} and ${e} must match`))}function S(t){v(null!=t,(()=>"The input to the tensor constructor must be a non-null value."))}function T(t,e=[],n=!1){if(null==e&&(e=[]),Array.isArray(t)||z(t)&&!n)for(let s=0;s<t.length;++s)T(t[s],e,n);else e.push(t);return e}function E(t){if(0===t.length)return 1;let e=t[0];for(let n=1;n<t.length;n++)e*=t[n];return e}function A(t,e){if(t===e)return!0;if(null==t||null==e)return!1;if(t.length!==e.length)return!1;for(let n=0;n<t.length;n++)if(t[n]!==e[n])return!1;return!0}function D(t){return t%1==0}function $(t,e){return e<=t.length?t:t+" ".repeat(e-t.length)}function M(t,e){const n=e.length;return v((t=null==t?e.map(((t,e)=>e)):[].concat(t)).every((t=>t>=-n&&t<n)),(()=>`All values in axis param must be in range [-${n}, ${n}) but got axis ${t}`)),v(t.every((t=>D(t))),(()=>`All values in axis param must be integers but got axis ${t}`)),t.map((t=>t<0?n+t:t))}function F(t,e){let n=null;if(null==t||"float32"===t)n=new Float32Array(e);else if("int32"===t)n=new Int32Array(e);else{if("bool"!==t)throw new Error(`Unknown data type ${t}`);n=new Uint8Array(e)}return n}function _(t,e){let n=null;if(null==t||"float32"===t)n=new Float32Array(e);else if("int32"===t)n=new Int32Array(e);else if("bool"===t)n=new Uint8Array(e);else{if("string"!==t)throw new Error(`Unknown data type ${t}`);n=new Array(e)}return n}function z(t){return t instanceof Float32Array||t instanceof Int32Array||t instanceof Uint8Array}function C(t){return"string"==typeof t||t instanceof String}function O(t){return"number"==typeof t}function L(t){return Array.isArray(t)?L(t[0]):t instanceof Float32Array?"float32":t instanceof Int32Array||t instanceof Uint8Array?"int32":O(t)?"float32":C(t)?"string":"boolean"==typeof t?"bool":"float32"}function R(t){return!!(t&&t.constructor&&t.call&&t.apply)}function B(t){const e=t.length;if(e<2)return[];const n=new Array(e-1);n[e-2]=t[e-1];for(let s=e-3;s>=0;--s)n[s]=n[s+1]*t[s+1];return n}function W(t,e,n){const s=new Array;if(1===e.length){const r=e[0];for(let e=0;e<r;e++)s[e]=n[t+e]}else{const r=e[0],a=e.slice(1),i=a.reduce(((t,e)=>t*e));for(let e=0;e<r;e++)s[e]=W(t+e*i,a,n)}return s}function P(t,e){if(0===t.length)return e[0];const n=t.reduce(((t,e)=>t*e));if(0===n)return[];if(n!==e.length)throw new Error(`[${t}] does not match the input size ${e.length}.`);return W(0,t,e)}function V(t,e){const n=U(t,e);for(let t=0;t<n.length;t++)n[t]=1;return n}function U(t,e){if(null==e||"float32"===e||"complex64"===e)return new Float32Array(t);if("int32"===e)return new Int32Array(t);if("bool"===e)return new Uint8Array(t);throw new Error(`Unknown data type ${e}`)}function H(t,e){const n=t.reduce(((t,e)=>t*e),1);if(null==e||"float32"===e)return P(t,new Float32Array(n));if("int32"===e)return P(t,new Int32Array(n));if("bool"===e)return P(t,new Uint8Array(n));throw new Error(`Unknown data type ${e}`)}function j(t){t.forEach((e=>{v(Number.isInteger(e)&&e>=0,(()=>`Tensor must have a shape comprised of positive integers but got shape [${t}].`))}))}function q(t,e,n){if(0===e)return 0;if(1===e)return t[0];let s=t[t.length-1];for(let e=0;e<t.length-1;++e)s+=n[e]*t[e];return s}function G(t,e,n){if(0===e)return[];if(1===e)return[t];const s=new Array(e);for(let e=0;e<s.length-1;++e)s[e]=Math.floor(t/n[e]),t-=s[e]*n[e];return s[s.length-1]=t,s}function K(t){return t&&t.then&&"function"==typeof t.then}class J{constructor(t){this.global=t,this.flags={},this.flagRegistry={},this.urlFlags={},this.populateURLFlags()}setPlatform(t,e){null!=this.platform&&console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${e}.`),this.platformName=t,this.platform=e}registerFlag(t,e,n){if(this.flagRegistry[t]={evaluationFn:e,setHook:n},null!=this.urlFlags[t]){const e=this.urlFlags[t];console.warn(`Setting feature override from URL ${t}: ${e}.`),this.set(t,e)}}async getAsync(t){return t in this.flags||(this.flags[t]=await this.evaluateFlag(t)),this.flags[t]}get(t){if(t in this.flags)return this.flags[t];const e=this.evaluateFlag(t);if(K(e))throw new Error(`Flag ${t} cannot be synchronously evaluated. Please use getAsync() instead.`);return this.flags[t]=e,this.flags[t]}getNumber(t){return this.get(t)}getBool(t){return this.get(t)}getFlags(){return this.flags}get features(){return this.flags}set(t,e){if(null==this.flagRegistry[t])throw new Error(`Cannot set flag ${t} as it has not been registered.`);this.flags[t]=e,null!=this.flagRegistry[t].setHook&&this.flagRegistry[t].setHook(e)}evaluateFlag(t){if(null==this.flagRegistry[t])throw new Error(`Cannot evaluate flag '${t}': no evaluation function found.`);return this.flagRegistry[t].evaluationFn()}setFlags(t){this.flags=Object.assign({},t)}reset(){this.flags={},this.urlFlags={},this.populateURLFlags()}populateURLFlags(){if(void 0===this.global||void 0===this.global.location||void 0===this.global.location.search)return;const t=function(t){const e={};return t.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g,((t,...n)=>(function(t,e,n){t[decodeURIComponent(e)]=decodeURIComponent(n||"")}(e,n[0],n[1]),n.join("=")))),e}(this.global.location.search);"tfjsflags"in t&&t.tfjsflags.split(",").forEach((t=>{const[e,n]=t.split(":");this.urlFlags[e]=function(t,e){if("true"===(e=e.toLowerCase())||"false"===e)return"true"===e;if(""+ +e===e)return+e;throw new Error(`Could not parse value flag value ${e} for flag ${t}.`)}(e,n)}))}}function Z(){return X}let Y,X=null;function Q(){if(null==Y){let t;if("undefined"!=typeof window)t=window;else if(void 0!==n.g)t=n.g;else if("undefined"!=typeof process)t=process;else{if("undefined"==typeof self)throw new Error("Could not find a global object");t=self}Y=t}return Y}function tt(t,e){const n=function(){const t=Q();return null==t._tfGlobals&&(t._tfGlobals=new Map),t._tfGlobals}();if(n.has(t))return n.get(t);{const s=e();return n.set(t,s),n.get(t)}}const et="Abs",nt="Acos",st="Acosh",rt="Add",at="AddN",it="ArgMax",ot="ArgMin",lt="Asin",ut="Asinh",ht="Atan",ct="Atanh",pt="Atan2",dt="AvgPool",ft="AvgPoolGrad",mt="AvgPool3D",gt="AvgPool3DGrad",yt="BatchMatMul",bt="BatchToSpaceND",kt="Bincount",wt="Cast",xt="Ceil",Nt="ClipByValue",vt="Complex",It="ComplexAbs",St="Concat",Tt="Conv2D",Et="Conv2DBackpropFilter",At="Conv2DBackpropInput",Dt="Conv3D",$t="Conv3DBackpropFilterV2",Mt="Conv3DBackpropInputV2",Ft="Cos",_t="Cosh",zt="Cumsum",Ct="CropAndResize",Ot="DenseBincount",Lt="DepthToSpace",Rt="DepthwiseConv2dNative",Bt="DepthwiseConv2dNativeBackpropFilter",Wt="DepthwiseConv2dNativeBackpropInput",Pt="Dilation2D",Vt="Dilation2DBackpropInput",Ut="Dilation2DBackpropFilter",Ht="RealDiv",jt="Elu",qt="EluGrad",Gt="Erf",Kt="Equal",Jt="Exp",Zt="ExpandDims",Yt="Expm1",Xt="Fill",Qt="FlipLeftRight",te="Floor",ee="FloorDiv",ne="FusedBatchNorm",se="GatherV2",re="GatherNd",ae="Greater",ie="GreaterEqual",oe="Identity",le="IFFT",ue="Imag",he="IsFinite",ce="IsInf",pe="IsNan",de="LeakyRelu",fe="Less",me="LessEqual",ge="LinSpace",ye="Log",be="Log1p",ke="LogicalAnd",we="LogicalNot",xe="LogicalOr",Ne="LRN",ve="LRNGrad",Ie="Max",Se="Maximum",Te="MaxPool",Ee="MaxPoolGrad",Ae="MaxPool3D",De="MaxPool3DGrad",$e="MaxPoolWithArgmax",Me="Mean",Fe="Min",_e="Minimum",ze="MirrorPad",Ce="Mod",Oe="Multinomial",Le="Multiply",Re="Neg",Be="NotEqual",We="NonMaxSuppressionV3",Pe="NonMaxSuppressionV4",Ve="NonMaxSuppressionV5",Ue="OnesLike",He="OneHot",je="Pack",qe="PadV2",Ge="Pow",Ke="Prelu",Je="Prod",Ze="Range",Ye="Real",Xe="Reciprocal",Qe="Relu",tn="Reshape",en="ResizeNearestNeighbor",nn="ResizeNearestNeighborGrad",sn="ResizeBilinear",rn="ResizeBilinearGrad",an="Relu6",on="Reverse",ln="Round",un="Rsqrt",hn="ScatterNd",cn="Select",pn="Selu",dn="Slice",fn="Sin",mn="Sinh",gn="Sign",yn="Sigmoid",bn="Softplus",kn="Sqrt",wn="Sum",xn="SpaceToBatchND",Nn="SplitV",vn="Softmax",In="SquaredDifference",Sn="Square",Tn="Sub",En="SparseToDense",An="StridedSlice",Dn="Tan",$n="Tanh",Mn="Tile",Fn="TopK",_n="Transpose",zn="Unique",Cn="Unpack",On="UnsortedSegmentSum",Ln="ZerosLike",Rn="Step",Bn="FromPixels",Wn="RotateWithOffset",Pn="_FusedMatMul",Vn="FusedConv2D",Un="FusedDepthwiseConv2D",Hn=tt("kernelRegistry",(()=>new Map)),jn=tt("gradRegistry",(()=>new Map));function qn(t,e){const n=Yn(t,e);return Hn.get(n)}function Gn(t){return jn.get(t)}function Kn(t){const e=Hn.entries(),n=[];for(;;){const{done:s,value:r}=e.next();if(s)break;const[a,i]=r,[o]=a.split("_");o===t&&n.push(i)}return n}function Jn(t){const{kernelName:e,backendName:n}=t,s=Yn(e,n);Hn.has(s)&&console.warn(`The kernel '${e}' for backend '${n}' is already registered`),Hn.set(s,t)}function Zn(t){const{kernelName:e}=t;jn.has(e)&&Z().getBool("DEBUG")&&console.warn(`Overriding the gradient for '${e}'`),jn.set(e,t)}function Yn(t,e){return`${e}_${t}`}class Xn{constructor(t,e){this.backendTimer=t,this.logger=e,null==e&&(this.logger=new ts)}profileKernel(t,e,n){let s;const r=this.backendTimer.time((()=>{s=n()}));if(Z().getBool("CHECK_COMPUTATION_FOR_ERRORS"))for(let e=0;e<s.length;e++){const n=s[e];n.data().then((e=>{Qn(e,n.dtype,t)}))}return{kernelName:t,outputs:s,inputs:e,timeMs:r.then((t=>t.kernelMs)),extraInfo:r.then((t=>null!=t.getExtraProfileInfo?t.getExtraProfileInfo():""))}}logKernelProfile(t){const{kernelName:e,outputs:n,timeMs:s,inputs:r,extraInfo:a}=t;n.forEach((t=>{Promise.all([t.data(),s,a]).then((n=>{this.logger.logKernelProfile(e,t,n[0],n[1],r,n[2])}))}))}}function Qn(t,e,n){if("float32"!==e)return!1;for(let e=0;e<t.length;e++){const s=t[e];if(isNaN(s)||!isFinite(s))return console.warn(`Found ${s} in the result of '${n}'`),!0}return!1}class ts{logKernelProfile(t,e,n,s,r,a){const i="number"==typeof s?$(`${s}ms`,9):s.error,o=$(t,25),l=e.rank,u=e.size,h=$(e.shape.toString(),14);let c="";for(const t in r){const n=r[t];if(null!=n){const s=n.shape||e.shape,r=s.length;c+=`${t}: ${r}D ${r>0?s:""} `}}console.log(`%c${o}\t%c${i}\t%c${l}D ${h}\t%c${u}\t%c${c}\t%c${a}`,"font-weight:bold","color:red","color:blue","color: orange","color: green","color: steelblue")}}function es(t,e,n,s){const r=B(e),a=function(t,e,n,s){const r=E(e),a=s[s.length-1],i=new Array(a).fill(0),o=e.length,l="complex64"===n?as(t):t;if(o>1)for(let t=0;t<r/a;t++){const e=t*a;for(let t=0;t<a;t++)i[t]=Math.max(i[t],ns(l[e+t],0,n).length)}return i}(t,e,n,r),i=e.length,o=rs(t,e,n,r,a),l=["Tensor"];return s&&(l.push(`  dtype: ${n}`),l.push(`  rank: ${i}`),l.push(`  shape: [${e}]`),l.push("  values:")),l.push(o.map((t=>"    "+t)).join("\n")),l.join("\n")}function ns(t,e,n){let s;return s=Array.isArray(t)?`${parseFloat(t[0].toFixed(7))} + ${parseFloat(t[1].toFixed(7))}j`:C(t)?`'${t}'`:"bool"===n?ss(t):parseFloat(t.toFixed(7)).toString(),$(s,e)}function ss(t){return 0===t?"false":"true"}function rs(t,e,n,s,r,a=!0){const i="complex64"===n?2:1,o=e[0],l=e.length;if(0===l)return"complex64"===n?[ns(as(t)[0],0,n)]:"bool"===n?[ss(t[0])]:[t[0].toString()];if(1===l){if(o>20){const e=3*i;let s=Array.from(t.slice(0,e)),a=Array.from(t.slice((o-3)*i,o*i));return"complex64"===n&&(s=as(s),a=as(a)),["["+s.map(((t,e)=>ns(t,r[e],n))).join(", ")+", ..., "+a.map(((t,e)=>ns(t,r[o-3+e],n))).join(", ")+"]"]}return["["+("complex64"===n?as(t):Array.from(t)).map(((t,e)=>ns(t,r[e],n))).join(", ")+"]"]}const u=e.slice(1),h=s.slice(1),c=s[0]*i,p=[];if(o>20){for(let e=0;e<3;e++){const s=e*c,a=s+c;p.push(...rs(t.slice(s,a),u,n,h,r,!1))}p.push("...");for(let e=o-3;e<o;e++){const s=e*c,a=s+c;p.push(...rs(t.slice(s,a),u,n,h,r,e===o-1))}}else for(let e=0;e<o;e++){const s=e*c,a=s+c;p.push(...rs(t.slice(s,a),u,n,h,r,e===o-1))}const d=2===l?",":"";p[0]="["+p[0]+d;for(let t=1;t<p.length-1;t++)p[t]=" "+p[t]+d;let f=",\n";for(let t=2;t<l;t++)f+="\n";return p[p.length-1]=" "+p[p.length-1]+"]"+(a?"":f),p}function as(t){const e=[];for(let n=0;n<t.length;n+=2)e.push([t[n],t[n+1]]);return e}function is(t,e){return"string"===e?us(t):os([t],e)}function os(t,e){if("string"===e)throw new Error("Cannot convert a string[] to a TypedArray");if(Array.isArray(t)&&(t=T(t)),Z().getBool("DEBUG")&&function(t,e){for(let n=0;n<t.length;n++){const s=t[n];if(isNaN(s)||!isFinite(s))throw Error(`A tensor of type ${e} being uploaded contains ${s}.`)}}(t,e),function(t,e){return t instanceof Float32Array&&"float32"===e||t instanceof Int32Array&&"int32"===e||t instanceof Uint8Array&&"bool"===e}(t,e))return t;if(null==e||"float32"===e||"complex64"===e)return new Float32Array(t);if("int32"===e)return new Int32Array(t);if("bool"===e){const e=new Uint8Array(t.length);for(let n=0;n<e.length;++n)0!==Math.round(t[n])&&(e[n]=1);return e}throw new Error(`Unknown data type ${e}`)}function ls(){return Z().platform.now()}function us(t,e="utf-8"){return e=e||"utf-8",Z().platform.encode(t,e)}function hs(t,e="utf-8"){return e=e||"utf-8",Z().platform.decode(t,e)}class cs{constructor(t,e,n){if(this.dtype=e,this.shape=t.slice(),this.size=E(t),null!=n){const t=n.length;v(t===this.size,(()=>`Length of values '${t}' does not match the size inferred by the shape '${this.size}'.`))}if("complex64"===e)throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");this.values=n||_(e,this.size),this.strides=B(t)}set(t,...e){0===e.length&&(e=[0]),v(e.length===this.rank,(()=>`The number of provided coordinates (${e.length}) must match the rank (${this.rank})`));const n=this.locToIndex(e);this.values[n]=t}get(...t){0===t.length&&(t=[0]);let e=0;for(const n of t){if(n<0||n>=this.shape[e]){const e=`Requested out of range element at ${t}.   Buffer shape=${this.shape}`;throw new Error(e)}e++}let n=t[t.length-1];for(let e=0;e<t.length-1;++e)n+=this.strides[e]*t[e];return this.values[n]}locToIndex(t){if(0===this.rank)return 0;if(1===this.rank)return t[0];let e=t[t.length-1];for(let n=0;n<t.length-1;++n)e+=this.strides[n]*t[n];return e}indexToLoc(t){if(0===this.rank)return[];if(1===this.rank)return[t];const e=new Array(this.shape.length);for(let n=0;n<e.length-1;++n)e[n]=Math.floor(t/this.strides[n]),t-=e[n]*this.strides[n];return e[e.length-1]=t,e}get rank(){return this.shape.length}toTensor(){return ps().makeTensor(this.values,this.shape,this.dtype)}}let ps=null,ds=null,fs=null;class ms{constructor(t,e,n,s){this.kept=!1,this.isDisposedInternal=!1,this.shape=t.slice(),this.dtype=e||"float32",this.size=E(t),this.strides=B(t),this.dataId=n,this.id=s,this.rankType=this.rank<5?this.rank.toString():"higher"}get rank(){return this.shape.length}async buffer(){const t=await this.data();return ds.buffer(this.shape,this.dtype,t)}bufferSync(){return ds.buffer(this.shape,this.dtype,this.dataSync())}async array(){const t=await this.data();return P(this.shape,t)}arraySync(){return P(this.shape,this.dataSync())}async data(){this.throwIfDisposed();const t=ps().read(this.dataId);if("string"===this.dtype){const e=await t;try{return e.map((t=>hs(t)))}catch(t){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}}return t}dataSync(){this.throwIfDisposed();const t=ps().readSync(this.dataId);if("string"===this.dtype)try{return t.map((t=>hs(t)))}catch(t){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}return t}async bytes(){this.throwIfDisposed();const t=await ps().read(this.dataId);return"string"===this.dtype?t:new Uint8Array(t.buffer)}dispose(){this.isDisposed||(ps().disposeTensor(this),this.isDisposedInternal=!0)}get isDisposed(){return this.isDisposedInternal}throwIfDisposed(){if(this.isDisposed)throw new Error("Tensor is disposed.")}print(t=!1){return ds.print(this,t)}clone(){return this.throwIfDisposed(),ds.clone(this)}toString(t=!1){return es(this.dataSync(),this.shape,this.dtype,t)}cast(t){return this.throwIfDisposed(),ds.cast(this,t)}variable(t=!0,e,n){return this.throwIfDisposed(),ps().makeVariable(this,t,e,n)}}Object.defineProperty(ms,Symbol.hasInstance,{value:t=>!!t&&null!=t.data&&null!=t.dataSync&&null!=t.throwIfDisposed});class gs extends ms{constructor(t,e,n,s){super(t.shape,t.dtype,t.dataId,s),this.trainable=e,this.name=n}assign(t){if(t.dtype!==this.dtype)throw new Error(`dtype of the new value (${t.dtype}) and previous value (${this.dtype}) must match`);if(!A(t.shape,this.shape))throw new Error(`shape of the new value (${t.shape}) and previous value (${this.shape}) must match`);ps().disposeTensor(this),this.dataId=t.dataId,ps().incRef(this,null)}dispose(){ps().disposeVariable(this),this.isDisposedInternal=!0}}var ys,bs,ks,ws,xs;Object.defineProperty(gs,Symbol.hasInstance,{value:t=>t instanceof ms&&null!=t.assign&&t.assign instanceof Function}),function(t){t.R0="R0",t.R1="R1",t.R2="R2",t.R3="R3",t.R4="R4",t.R5="R5",t.R6="R6"}(ys||(ys={})),function(t){t.float32="float32",t.int32="int32",t.bool="int32",t.complex64="complex64"}(bs||(bs={})),function(t){t.float32="float32",t.int32="int32",t.bool="bool",t.complex64="complex64"}(ks||(ks={})),function(t){t.float32="float32",t.int32="float32",t.bool="float32",t.complex64="complex64"}(ws||(ws={})),function(t){t.float32="complex64",t.int32="complex64",t.bool="complex64",t.complex64="complex64"}(xs||(xs={}));const Ns={float32:ws,int32:bs,bool:ks,complex64:xs};function vs(t,e){if("string"===t||"string"===e){if("string"===t&&"string"===e)return"string";throw new Error(`Can not upcast ${t} with ${e}`)}return Ns[t][e]}function Is(t,e){if(t.dtype===e.dtype)return[t,e];const n=vs(t.dtype,e.dtype);return[t.cast(n),e.cast(n)]}function Ss(t){const e=[];return Ts(t,e,new Set),e}function Ts(t,e,n){if(null==t)return;if(t instanceof ms)return void e.push(t);if(s=t,!Array.isArray(s)&&"object"!=typeof s)return;var s;const r=t;for(const t in r){const s=r[t];n.has(s)||(n.add(s),Ts(s,e,n))}}class Es{constructor(){this.registeredVariables={},this.nextTapeNodeId=0,this.numBytes=0,this.numTensors=0,this.numStringTensors=0,this.numDataBuffers=0,this.gradientDepth=0,this.kernelDepth=0,this.scopeStack=[],this.numDataMovesStack=[],this.nextScopeId=0,this.tensorInfo=new WeakMap,this.profiling=!1,this.activeProfile={newBytes:0,newTensors:0,peakBytes:0,kernels:[],result:null,get kernelNames(){return Array.from(new Set(this.kernels.map((t=>t.name))))}}}dispose(){for(const t in this.registeredVariables)this.registeredVariables[t].dispose()}}class As{constructor(t){this.ENV=t,this.registry={},this.registryFactory={},this.pendingBackendInitId=0,this.state=new Es}async ready(){if(null!=this.pendingBackendInit)return this.pendingBackendInit.then((()=>{}));if(null!=this.backendInstance)return;const t=this.getSortedBackends();for(let e=0;e<t.length;e++){const n=t[e];if(await this.initializeBackend(n).success)return void await this.setBackend(n)}throw new Error("Could not initialize any backends, all backend initializations failed.")}get backend(){if(null!=this.pendingBackendInit)throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);if(null==this.backendInstance){const{name:t,asyncInit:e}=this.initializeBackendsAndReturnBest();if(e)throw new Error(`The highest priority backend '${t}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);this.setBackend(t)}return this.backendInstance}backendNames(){return Object.keys(this.registryFactory)}findBackend(t){if(!(t in this.registry)){if(!(t in this.registryFactory))return null;{const{asyncInit:e}=this.initializeBackend(t);if(e)return null}}return this.registry[t]}findBackendFactory(t){return t in this.registryFactory?this.registryFactory[t].factory:null}registerBackend(t,e,n=1){return t in this.registryFactory?(console.warn(`${t} backend was already registered. Reusing existing backend factory.`),!1):(this.registryFactory[t]={factory:e,priority:n},!0)}async setBackend(t){if(null==this.registryFactory[t])throw new Error(`Backend name '${t}' not found in registry`);if(this.backendName=t,null==this.registry[t]){this.backendInstance=null;const{success:e,asyncInit:n}=this.initializeBackend(t);if(!(n?await e:e))return!1}return this.backendInstance=this.registry[t],this.setupRegisteredKernels(),this.profiler=new Xn(this.backendInstance),!0}setupRegisteredKernels(){Kn(this.backendName).forEach((t=>{null!=t.setupFunc&&t.setupFunc(this.backendInstance)}))}disposeRegisteredKernels(t){Kn(t).forEach((e=>{null!=e.disposeFunc&&e.disposeFunc(this.registry[t])}))}initializeBackend(t){const e=this.registryFactory[t];if(null==e)throw new Error(`Cannot initialize backend ${t}, no registration found.`);try{const n=e.factory();if(!n||n instanceof k||"function"!=typeof n.then)return this.registry[t]=n,{success:!0,asyncInit:!1};{const e=++this.pendingBackendInitId,s=n.then((n=>!(e<this.pendingBackendInitId||(this.registry[t]=n,this.pendingBackendInit=null,0)))).catch((n=>(e<this.pendingBackendInitId||(this.pendingBackendInit=null,console.warn(`Initialization of backend ${t} failed`),console.warn(n.stack||n.message)),!1)));return this.pendingBackendInit=s,{success:s,asyncInit:!0}}}catch(e){return console.warn(`Initialization of backend ${t} failed`),console.warn(e.stack||e.message),{success:!1,asyncInit:!1}}}removeBackend(t){if(!(t in this.registryFactory))throw new Error(`${t} backend not found in registry`);this.backendName===t&&null!=this.pendingBackendInit&&this.pendingBackendInitId++,t in this.registry&&(this.disposeRegisteredKernels(t),this.registry[t].dispose(),delete this.registry[t]),delete this.registryFactory[t],this.backendName===t&&(this.pendingBackendInit=null,this.backendName=null,this.backendInstance=null)}getSortedBackends(){if(0===Object.keys(this.registryFactory).length)throw new Error("No backend found in registry.");return Object.keys(this.registryFactory).sort(((t,e)=>this.registryFactory[e].priority-this.registryFactory[t].priority))}initializeBackendsAndReturnBest(){const t=this.getSortedBackends();for(let e=0;e<t.length;e++){const n=t[e],{success:s,asyncInit:r}=this.initializeBackend(n);if(r||s)return{name:n,asyncInit:r}}throw new Error("Could not initialize any backends, all backend initializations failed.")}moveData(t,e){const n=this.state.tensorInfo.get(e),s=n.backend,r=this.readSync(e);s.disposeData(e),n.backend=t,t.move(e,r,n.shape,n.dtype),this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack[this.state.numDataMovesStack.length-1]++}tidy(t,e){let n,s=null;if(null==e){if("function"!=typeof t)throw new Error("Please provide a function to tidy()");e=t}else{if("string"!=typeof t&&!(t instanceof String))throw new Error("When calling with two arguments, the first argument to tidy() must be a string");if("function"!=typeof e)throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");s=t}return this.scopedRun((()=>this.startScope(s)),(()=>this.endScope(n)),(()=>(n=e(),n instanceof Promise&&console.error("Cannot return a Promise inside of tidy."),n)))}scopedRun(t,e,n){t();try{const t=n();return e(),t}catch(t){throw e(),t}}nextTensorId(){return As.nextTensorId++}nextVariableId(){return As.nextVariableId++}clone(t){const e=this.makeTensorFromDataId(t.dataId,t.shape,t.dtype),n={x:t};return this.addTapeNode(this.state.activeScope.name,n,[e],(t=>({x:()=>{const e="float32",n={x:t},s={dtype:e};return $s.runKernelFunc((n=>n.cast(t,e)),n,null,wt,s)}})),[],{}),e}runKernel(t,e,n,s,r){return this.runKernelFunc(null,e,null,t,n,s,r)}shouldCheckForMemLeaks(){return this.ENV.getBool("IS_TEST")}checkKernelForMemLeak(t,e,n){const s=this.backend.numDataIds();let r=0;n.forEach((t=>{r+="complex64"===t.dtype?3:1}));const a=this.state.numDataMovesStack[this.state.numDataMovesStack.length-1],i=s-e-r-a;if(i>0)throw new Error(`Backend '${this.backendName}' has an internal memory leak (${i} data ids) after running '${t}'`)}runKernelFunc(t,e,n,s,r,a,i){let o,l=[];const u=this.isTapeOn();null==s&&(s=null!=this.state.activeScope?this.state.activeScope.name:"");const h=this.state.numBytes,c=this.state.numTensors;let p;this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack.push(0),null==this.backendName&&this.backend;const d=qn(s,this.backendName);let f,m;if(null!=d)p=()=>{const t=this.backend.numDataIds();f=d.kernelFunc({inputs:e,attrs:r,backend:this.backend});const n=Array.isArray(f)?f:[f];this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(s,t,n);const o=n.map((t=>{if(null!=t.rank)return t;const{dataId:e,shape:n,dtype:s}=t;return this.makeTensorFromDataId(e,n,s)}));if(u){let t=this.getTensorsForGradient(s,e,o);if(null==t){null==i&&(i=[]);const e=o.filter(((t,e)=>i[e]));t=(a||[]).slice().concat(e)}l=this.saveTensorsForBackwardMode(t)}return o};else{if(null==t)throw new Error(`Error running ${s}: Neither modular kernel nor forward func passed`);const e=t=>{u&&(l=t.map((t=>this.keep(this.clone(t)))))};p=()=>{const n=this.backend.numDataIds();f=this.tidy((()=>t(this.backend,e)));const r=Array.isArray(f)?f:[f];return this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(s,n,r),r}}return this.scopedRun((()=>this.state.kernelDepth++),(()=>this.state.kernelDepth--),(()=>{this.ENV.getBool("DEBUG")||this.state.profiling?(m=this.profiler.profileKernel(s,e,(()=>p())),this.ENV.getBool("DEBUG")&&this.profiler.logKernelProfile(m),o=m.outputs):o=p()})),u&&this.addTapeNode(s,e,o,n,l,r),this.state.profiling&&this.state.activeProfile.kernels.push({name:s,bytesAdded:this.state.numBytes-h,totalBytesSnapshot:this.state.numBytes,tensorsAdded:this.state.numTensors-c,totalTensorsSnapshot:this.state.numTensors,inputShapes:Object.keys(e).map((t=>null!=e[t]?e[t].shape:null)),outputShapes:o.map((t=>t.shape)),kernelTimeMs:m.timeMs,extraInfo:m.extraInfo}),Array.isArray(f)?o:o[0]}saveTensorsForBackwardMode(t){return t.map((t=>this.keep(this.clone(t))))}getTensorsForGradient(t,e,n){const s=Gn(t);if(null!=s){const t=s.inputsToSave||[],r=s.outputsToSave||[];let a;s.saveAllInputs?(v(Array.isArray(e),(()=>"saveAllInputs is true, expected inputs to be an array.")),a=Object.keys(e).map((t=>e[t]))):a=t.map((t=>e[t]));const i=n.filter(((t,e)=>r[e]));return a.concat(i)}return null}makeTensor(t,e,n,s){if(null==t)throw new Error("Values passed to engine.makeTensor() are null");n=n||"float32",s=s||this.backend;let r=t;"string"===n&&C(t[0])&&(r=t.map((t=>us(t))));const a=s.write(r,e,n),i=new ms(e,n,a,this.nextTensorId());if(this.incRef(i,s),"string"===n){const t=this.state.tensorInfo.get(a),e=function(t){if(null==t)return 0;let e=0;return t.forEach((t=>e+=t.length)),e}(r);this.state.numBytes+=e-t.bytes,t.bytes=e}return i}makeTensorFromDataId(t,e,n,s){const r=new ms(e,n=n||"float32",t,this.nextTensorId());return this.incRef(r,s),r}makeVariable(t,e=!0,n,s){n=n||this.nextVariableId().toString(),null!=s&&s!==t.dtype&&(t=t.cast(s));const r=new gs(t,e,n,this.nextTensorId());if(null!=this.state.registeredVariables[r.name])throw new Error(`Variable with name ${r.name} was already registered`);return this.state.registeredVariables[r.name]=r,this.incRef(r,this.backend),r}incRef(t,e){const n=this.state.tensorInfo.has(t.dataId)?this.state.tensorInfo.get(t.dataId).refCount:0;if(this.state.numTensors++,"string"===t.dtype&&this.state.numStringTensors++,0===n){this.state.numDataBuffers++;let n=0;"complex64"!==t.dtype&&"string"!==t.dtype&&(n=t.size*function(t){if("float32"===t||"int32"===t)return 4;if("complex64"===t)return 8;if("bool"===t)return 1;throw new Error(`Unknown dtype ${t}`)}(t.dtype)),this.state.tensorInfo.set(t.dataId,{backend:e||this.backend,dtype:t.dtype,shape:t.shape,bytes:n,refCount:0}),this.state.numBytes+=n}this.state.tensorInfo.get(t.dataId).refCount++,t instanceof gs||this.track(t)}disposeTensor(t){if(!this.state.tensorInfo.has(t.dataId))return;this.state.numTensors--,"string"===t.dtype&&this.state.numStringTensors--;const e=this.state.tensorInfo.get(t.dataId);e.refCount<=1?("complex64"!==t.dtype&&(this.state.numBytes-=e.bytes),this.state.numDataBuffers--,e.backend.disposeData(t.dataId),this.state.tensorInfo.delete(t.dataId)):this.state.tensorInfo.get(t.dataId).refCount--}disposeVariables(){for(const t in this.state.registeredVariables){const e=this.state.registeredVariables[t];this.disposeVariable(e)}}disposeVariable(t){this.disposeTensor(t),null!=this.state.registeredVariables[t.name]&&delete this.state.registeredVariables[t.name]}memory(){const t=this.backend.memory();return t.numTensors=this.state.numTensors,t.numDataBuffers=this.state.numDataBuffers,t.numBytes=this.state.numBytes,this.state.numStringTensors>0&&(t.unreliable=!0,null==t.reasons&&(t.reasons=[]),t.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")),t}async profile(t){this.state.profiling=!0;const e=this.state.numBytes,n=this.state.numTensors;this.state.activeProfile.kernels=[],this.state.activeProfile.result=await t(),this.state.profiling=!1,this.state.activeProfile.peakBytes=Math.max(...this.state.activeProfile.kernels.map((t=>t.totalBytesSnapshot))),this.state.activeProfile.newBytes=this.state.numBytes-e,this.state.activeProfile.newTensors=this.state.numTensors-n;for(const t of this.state.activeProfile.kernels)t.kernelTimeMs=await t.kernelTimeMs,t.extraInfo=await t.extraInfo;return this.state.activeProfile}isTapeOn(){return this.state.gradientDepth>0&&0===this.state.kernelDepth}addTapeNode(t,e,n,s,r,a){const i={id:this.state.nextTapeNodeId++,kernelName:t,inputs:e,outputs:n,saved:r},o=Gn(t);null!=o&&(s=o.gradFunc),null!=s&&(i.gradient=t=>(t=t.map(((t,e)=>{if(null==t){const t=n[e],s=U(t.size,t.dtype);return this.makeTensor(s,t.shape,t.dtype)}return t})),s(t.length>1?t:t[0],r,a))),this.state.activeTape.push(i)}keep(t){return t.kept=!0,t}startTape(){0===this.state.gradientDepth&&(this.state.activeTape=[]),this.state.gradientDepth++}endTape(){this.state.gradientDepth--}startScope(t){const e={track:[],name:"unnamed scope",id:this.state.nextScopeId++};t&&(e.name=t),this.state.scopeStack.push(e),this.state.activeScope=e}endScope(t){const e=Ss(t),n=new Set(e.map((t=>t.id)));for(let t=0;t<this.state.activeScope.track.length;t++){const e=this.state.activeScope.track[t];e.kept||n.has(e.id)||e.dispose()}const s=this.state.scopeStack.pop();this.state.activeScope=0===this.state.scopeStack.length?null:this.state.scopeStack[this.state.scopeStack.length-1],e.forEach((t=>{t.kept||t.scopeId!==s.id||this.track(t)}))}gradients(t,e,n,s=!1){if(v(e.length>0,(()=>"gradients() received an empty list of xs.")),null!=n&&"float32"!==n.dtype)throw new Error(`dy must have 'float32' dtype, but has '${n.dtype}'`);const r=this.scopedRun((()=>this.startTape()),(()=>this.endTape()),(()=>this.tidy("forward",t)));v(r instanceof ms,(()=>"The result y returned by f() must be a tensor."));const a=function(t,e,n){const s={},r={};for(let t=0;t<e.length;t++)s[e[t].id]=!0;for(let n=0;n<t.length;n++){const a=t[n],i=a.inputs;for(const t in i){const n=i[t];let o=!1;for(let t=0;t<e.length;t++)if(s[n.id]){a.outputs.forEach((t=>s[t.id]=!0)),o=!0,r[a.id]=!0;break}if(o)break}}const a={};a[n.id]=!0;const i={};for(let e=t.length-1;e>=0;e--){const n=t[e],s=n.inputs;for(let t=0;t<n.outputs.length;t++)if(a[n.outputs[t].id]){for(const t in s)a[s[t].id]=!0,i[n.id]=!0;break}}const o=[];for(let e=0;e<t.length;e++){const n=t[e];if(r[n.id]&&i[n.id]){const t={};for(const e in n.inputs){const r=n.inputs[e];s[r.id]&&(t[e]=r)}const e=Object.assign({},n);e.inputs=t,e.outputs=n.outputs,o.push(e)}}return o}(this.state.activeTape,e,r);if(!s&&0===a.length&&e.length>0)throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");return this.tidy("backward",(()=>{const t={};t[r.id]=null==n?function(t){const e=V(E(t),"float32");return $s.makeTensor(e,t,"float32")}(r.shape):n,function(t,e,n,s){for(let r=e.length-1;r>=0;r--){const a=e[r],i=[];if(a.outputs.forEach((e=>{const n=t[e.id];null!=n?i.push(n):i.push(null)})),null==a.gradient)throw new Error(`Cannot compute gradient: gradient function not found for ${a.kernelName}.`);const o=a.gradient(i);for(const e in a.inputs){if(!(e in o))throw new Error(`Cannot backprop through input ${e}. Available gradients found: ${Object.keys(o)}.`);const r=n((()=>o[e]()));if("float32"!==r.dtype)throw new Error(`Error in gradient for op ${a.kernelName}. The gradient of input ${e} must have 'float32' dtype, but has '${r.dtype}'`);const i=a.inputs[e];if(!A(r.shape,i.shape))throw new Error(`Error in gradient for op ${a.kernelName}. The gradient of input '${e}' has shape '${r.shape}', which does not match the shape of the input '${i.shape}'`);if(null==t[i.id])t[i.id]=r;else{const e=t[i.id];t[i.id]=s(e,r),e.dispose()}}}}(t,a,(t=>this.tidy(t)),Ms);const s=e.map((e=>t[e.id]));return 0===this.state.gradientDepth&&(this.state.activeTape.forEach((t=>{for(const e of t.saved)e.dispose()})),this.state.activeTape=null),{value:r,grads:s}}))}customGrad(t){return v(R(t),(()=>"The f passed in customGrad(f) must be a function.")),(...e)=>{let n;v(e.every((t=>t instanceof ms)),(()=>"The args passed in customGrad(f)(x1, x2,...) must all be tensors"));const s={};return e.forEach(((t,e)=>{s[e]=t})),this.runKernelFunc(((s,r)=>(n=t(...e,r),v(n.value instanceof ms,(()=>"The function f passed in customGrad(f) must return an object where `obj.value` is a tensor")),v(R(n.gradFunc),(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function.")),n.value)),s,((t,s)=>{const r=n.gradFunc(t,s),a=Array.isArray(r)?r:[r];v(a.length===e.length,(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...).")),v(a.every((t=>t instanceof ms)),(()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors."));const i={};return a.forEach(((t,e)=>{i[e]=()=>t})),i}))}}readSync(t){return this.state.tensorInfo.get(t).backend.readSync(t)}read(t){return this.state.tensorInfo.get(t).backend.read(t)}async time(t){const e=ls(),n=await this.backend.time(t);return n.wallMs=ls()-e,n}track(t){return null!=this.state.activeScope&&(t.scopeId=this.state.activeScope.id,this.state.activeScope.track.push(t)),t}get registeredVariables(){return this.state.registeredVariables}reset(){this.pendingBackendInitId++,this.state.dispose(),this.ENV.reset(),this.state=new Es;for(const t in this.registry)this.disposeRegisteredKernels(t),this.registry[t].dispose(),delete this.registry[t];this.backendName=null,this.backendInstance=null,this.pendingBackendInit=null}}function Ds(){const t=Q();if(null==t._tfengine){const e=new J(t);t._tfengine=new As(e)}var e;return e=t._tfengine.ENV,X=e,ps=()=>t._tfengine,t._tfengine}As.nextTensorId=0,As.nextVariableId=0;const $s=Ds();function Ms(t,e){const n={a:t,b:e};return $s.runKernel(rt,n)}const Fs=Z();function _s(t,e){let n=t;if(z(t))return"string"===e?[]:[t.length];if(!Array.isArray(t))return[];const s=[];for(;Array.isArray(n)||z(n)&&"string"!==e;)s.push(n.length),n=n[0];return Array.isArray(t)&&Z().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")&&zs(t,s,[]),s}function zs(t,e,n){if(n=n||[],!Array.isArray(t)&&!z(t))return void v(0===e.length,(()=>`Element arr[${n.join("][")}] is a primitive, but should be an array/TypedArray of ${e[0]} elements`));v(e.length>0,(()=>`Element arr[${n.join("][")}] should be a primitive, but is an array of ${t.length} elements`)),v(t.length===e[0],(()=>`Element arr[${n.join("][")}] should have ${e[0]} elements, but has ${t.length} elements`));const s=e.slice(1);for(let e=0;e<t.length;++e)zs(t[e],s,n.concat(e))}function Cs(t,e,n,s){if("string_or_numeric"!==t){if(null==t)throw new Error("Expected dtype cannot be null.");if("numeric"!==t&&t!==e||"numeric"===t&&"string"===e)throw new Error(`Argument '${n}' passed to '${s}' must be ${t} tensor, but got ${e} tensor`)}}function Os(t,e,n,s="numeric"){if(t instanceof ms)return Cs(s,t.dtype,e,n),t;let r=L(t);if("string"!==r&&["bool","int32","float32"].indexOf(s)>=0&&(r=s),Cs(s,r,e,n),null==t||!z(t)&&!Array.isArray(t)&&"number"!=typeof t&&"boolean"!=typeof t&&"string"!=typeof t){const s=null==t?"null":t.constructor.name;throw new Error(`Argument '${e}' passed to '${n}' must be a Tensor or TensorLike, but got '${s}'`)}const a=_s(t,r);z(t)||Array.isArray(t)||(t=[t]);const i="string"!==r?os(t,r):T(t,[],!0);return $s.makeTensor(i,a,r)}function Ls(t,e,n,s="numeric"){if(!Array.isArray(t))throw new Error(`Argument ${e} passed to ${n} must be a \`Tensor[]\` or \`TensorLike[]\``);return t.map(((t,r)=>Os(t,`${e}[${r}]`,n,s)))}function Rs(t){const e=Object.keys(t);if(1!==e.length)throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${e.length} keys.`);let n=e[0];const s=t[n];n.endsWith("_")&&(n=n.substring(0,n.length-1)),n+="__op";const r=(...t)=>{$s.startScope(n);try{const e=s(...t);return K(e)&&console.error("Cannot return a Promise inside of tidy."),$s.endScope(e),e}catch(t){throw $s.endScope(null),t}};return Object.defineProperty(r,"name",{value:n,configurable:!0}),r}Fs.registerFlag("DEBUG",(()=>!1),(t=>{t&&console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.")})),Fs.registerFlag("IS_BROWSER",(()=>"undefined"!=typeof window&&null!=window.document||"undefined"!=typeof WorkerGlobalScope)),Fs.registerFlag("IS_NODE",(()=>"undefined"!=typeof process&&void 0!==process.versions&&void 0!==process.versions.node)),Fs.registerFlag("IS_CHROME",(()=>"undefined"!=typeof navigator&&null!=navigator&&null!=navigator.userAgent&&/Chrome/.test(navigator.userAgent)&&/Google Inc/.test(navigator.vendor))),Fs.registerFlag("PROD",(()=>!1)),Fs.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY",(()=>Fs.getBool("DEBUG"))),Fs.registerFlag("DEPRECATION_WARNINGS_ENABLED",(()=>!0)),Fs.registerFlag("IS_TEST",(()=>!1)),Fs.registerFlag("CHECK_COMPUTATION_FOR_ERRORS",(()=>!0));const Bs=Rs({complex_:function(t,e){const n=Os(t,"real","complex"),s=Os(e,"imag","complex");I(n.shape,s.shape,`real and imag shapes, ${n.shape} and ${s.shape}, must match in call to tf.complex().`);const r={real:n,imag:s};return $s.runKernel(vt,r)}});function Ws(t,e,n,s){if(null==s&&(s=L(t)),"complex64"===s)throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");if(!z(t)&&!Array.isArray(t)&&"number"!=typeof t&&"boolean"!=typeof t&&"string"!=typeof t)throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");if(null!=e){j(e);const t=E(e),s=E(n);v(t===s,(()=>`Based on the provided shape, [${e}], the tensor should have ${t} values but has ${s}`));for(let t=0;t<n.length;++t){const s=n[t],r=t!==n.length-1||s!==E(e.slice(t));v(n[t]===e[t]||!r,(()=>`Error creating a new Tensor. Inferred shape (${n}) does not match the provided shape (${e}). `))}}return z(t)||Array.isArray(t)||(t=[t]),e=e||n,t="string"!==s?os(t,s):T(t,[],!0),$s.makeTensor(t,e,s)}function Ps(t,e,n){return Ws(t,e,_s(t,n),n)}const Vs={float32:4,float16:2,int32:4,uint16:2,uint8:1,bool:1,complex64:8};async function Us(t,e){const n=[],s=[],r=Array.isArray(t)?t.map((t=>t.name)):Object.keys(t);for(let a=0;a<r.length;++a){const i=r[a],o=Array.isArray(t)?t[a].tensor:t[i];if("float32"!==o.dtype&&"int32"!==o.dtype&&"bool"!==o.dtype&&"string"!==o.dtype&&"complex64"!==o.dtype)throw new Error(`Unsupported dtype in weight '${i}': ${o.dtype}`);const l={name:i,shape:o.shape,dtype:o.dtype};if("string"===o.dtype){const t=new Promise((async t=>{const e=await o.bytes(),n=e.reduce(((t,e)=>t+e.length),0)+4*e.length,s=new Uint8Array(n);let r=0;for(let t=0;t<e.length;t++){const n=e[t],a=new Uint8Array(new Uint32Array([n.length]).buffer);s.set(a,r),r+=4,s.set(n,r),r+=n.length}t(s)}));s.push(t)}else s.push(o.data());null!=e&&(l.group=e),n.push(l)}return{data:js(await Promise.all(s)),specs:n}}function Hs(t,e){const n={};let s,r=0;for(const a of e){const e=a.name,i=a.dtype,o=a.shape,l=E(o);let u;if("quantization"in a){const n=a.quantization;if("uint8"===n.dtype||"uint16"===n.dtype){if(!("min"in n)||!("scale"in n))throw new Error(`Weight ${a.name} with quantization ${n.dtype} doesn't have corresponding metadata min and scale.`)}else{if("float16"!==n.dtype)throw new Error(`Weight ${a.name} has unknown quantization dtype ${n.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);if("float32"!==i)throw new Error(`Weight ${a.name} is quantized with ${n.dtype} which only supports weights of type float32 not ${i}.`)}const o=Vs[n.dtype],h=t.slice(r,r+l*o),c="uint8"===n.dtype?new Uint8Array(h):new Uint16Array(h);if("float32"===i)if("uint8"===n.dtype||"uint16"===n.dtype){u=new Float32Array(c.length);for(let t=0;t<c.length;t++){const e=c[t];u[t]=e*n.scale+n.min}}else{if("float16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type float32.`);void 0===s&&(s=Zs()),u=s(c)}else{if("int32"!==i)throw new Error(`Unsupported dtype in weight '${e}': ${i}`);if("uint8"!==n.dtype&&"uint16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type int32.`);u=new Int32Array(c.length);for(let t=0;t<c.length;t++){const e=c[t];u[t]=Math.round(e*n.scale+n.min)}}r+=l*o}else if("string"===i){const e=E(a.shape);u=[];for(let n=0;n<e;n++){const e=new Uint32Array(t.slice(r,r+4))[0];r+=4;const n=new Uint8Array(t.slice(r,r+e));u.push(n),r+=e}}else{const s=Vs[i],a=t.slice(r,r+l*s);if("float32"===i)u=new Float32Array(a);else if("int32"===i)u=new Int32Array(a);else if("bool"===i)u=new Uint8Array(a);else{if("complex64"!==i)throw new Error(`Unsupported dtype in weight '${e}': ${i}`);{u=new Float32Array(a);const t=new Float32Array(u.length/2),s=new Float32Array(u.length/2);for(let e=0;e<t.length;e++)t[e]=u[2*e],s[e]=u[2*e+1];const r=Ps(t,o,"float32"),i=Ps(s,o,"float32");n[e]=Bs(r,i),r.dispose(),i.dispose()}}r+=l*s}"complex64"!==i&&(n[e]=Ps(u,o,i))}return n}function js(t){if(null===t)throw new Error(`Invalid input value: ${JSON.stringify(t)}`);let e=0;const n=[];t.forEach((t=>{if(e+=t.byteLength,n.push(t.byteLength===t.buffer.byteLength?t:new t.constructor(t)),!(t instanceof Float32Array||t instanceof Int32Array||t instanceof Uint8Array))throw new Error(`Unsupported TypedArray subtype: ${t.constructor.name}`)}));const s=new Uint8Array(e);let r=0;return n.forEach((t=>{s.set(new Uint8Array(t.buffer),r),r+=t.byteLength})),s.buffer}const qs="undefined"!=typeof Buffer&&("undefined"==typeof Blob||"undefined"==typeof atob||"undefined"==typeof btoa);function Gs(t){return qs?Buffer.byteLength(t):new Blob([t]).size}function Ks(t){if(1===t.length)return t[0];let e=0;t.forEach((t=>{e+=t.byteLength}));const n=new Uint8Array(e);let s=0;return t.forEach((t=>{n.set(new Uint8Array(t),s),s+=t.byteLength})),n.buffer}function Js(t){if(t.modelTopology instanceof ArrayBuffer)throw new Error("Expected JSON model topology, received ArrayBuffer.");return{dateSaved:new Date,modelTopologyType:"JSON",modelTopologyBytes:null==t.modelTopology?0:Gs(JSON.stringify(t.modelTopology)),weightSpecsBytes:null==t.weightSpecs?0:Gs(JSON.stringify(t.weightSpecs)),weightDataBytes:null==t.weightData?0:t.weightData.byteLength}}function Zs(){const t=function(){const t=t=>{let e=t<<13,n=0;for(;0==(8388608&e);)n-=8388608,e<<=1;return e&=-8388609,n+=947912704,e|n},e=new Uint32Array(2048);e[0]=0;for(let n=1;n<1024;n++)e[n]=t(n);for(let t=1024;t<2048;t++)e[t]=939524096+(t-1024<<13);return e}(),e=function(){const t=new Uint32Array(64);t[0]=0,t[31]=1199570944,t[32]=2147483648,t[63]=3347054592;for(let e=1;e<31;e++)t[e]=e<<23;for(let e=33;e<63;e++)t[e]=2147483648+(e-32<<23);return t}(),n=function(){const t=new Uint32Array(64);for(let e=0;e<64;e++)t[e]=1024;return t[0]=t[32]=0,t}();return s=>{const r=new ArrayBuffer(4*s.length),a=new Uint32Array(r);for(let r=0;r<s.length;r++){const i=s[r],o=t[n[i>>10]+(1023&i)]+e[i>>10];a[r]=o}return new Float32Array(r)}}class Ys{constructor(){this.saveRouters=[],this.loadRouters=[]}static getInstance(){return null==Ys.instance&&(Ys.instance=new Ys),Ys.instance}static registerSaveRouter(t){Ys.getInstance().saveRouters.push(t)}static registerLoadRouter(t){Ys.getInstance().loadRouters.push(t)}static getSaveHandlers(t){return Ys.getHandlers(t,"save")}static getLoadHandlers(t,e){return Ys.getHandlers(t,"load",e)}static getHandlers(t,e,n){const s=[];return("load"===e?Ys.getInstance().loadRouters:Ys.getInstance().saveRouters).forEach((e=>{const r=e(t,n);null!==r&&s.push(r)})),s}}const Xs=t=>Ys.getSaveHandlers(t),Qs=(t,e)=>Ys.getLoadHandlers(t,e),tr="tensorflowjs",er="models_store",nr="model_info_store";function sr(){if(!Z().getBool("IS_BROWSER"))throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");const t="undefined"==typeof window?self:window,e=t.indexedDB||t.mozIndexedDB||t.webkitIndexedDB||t.msIndexedDB||t.shimIndexedDB;if(null==e)throw new Error("The current browser does not appear to support IndexedDB.");return e}function rr(t){const e=t.result;e.createObjectStore(er,{keyPath:"modelPath"}),e.createObjectStore(nr,{keyPath:"modelPath"})}class ar{constructor(t){if(this.indexedDB=sr(),null==t||!t)throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");this.modelPath=t}async save(t){if(t.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");return this.databaseAction(this.modelPath,t)}async load(){return this.databaseAction(this.modelPath)}databaseAction(t,e){return new Promise(((t,n)=>{const s=this.indexedDB.open(tr,1);s.onupgradeneeded=()=>rr(s),s.onsuccess=()=>{const r=s.result;if(null==e){const e=r.transaction(er,"readonly"),s=e.objectStore(er).get(this.modelPath);s.onsuccess=()=>{if(null==s.result)return r.close(),n(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));t(s.result.modelArtifacts)},s.onerror=t=>(r.close(),n(s.error)),e.oncomplete=()=>r.close()}else{const s=Js(e),a=r.transaction(nr,"readwrite");let i=a.objectStore(nr);const o=i.put({modelPath:this.modelPath,modelArtifactsInfo:s});let l;o.onsuccess=()=>{l=r.transaction(er,"readwrite");const o=l.objectStore(er).put({modelPath:this.modelPath,modelArtifacts:e,modelArtifactsInfo:s});o.onsuccess=()=>t({modelArtifactsInfo:s}),o.onerror=t=>{i=a.objectStore(nr);const e=i.delete(this.modelPath);e.onsuccess=()=>(r.close(),n(o.error)),e.onerror=t=>(r.close(),n(o.error))}},o.onerror=t=>(r.close(),n(o.error)),a.oncomplete=()=>{null==l?r.close():l.oncomplete=()=>r.close()}}},s.onerror=t=>n(s.error)}))}}ar.URL_SCHEME="indexeddb://";const ir=t=>{return Z().getBool("IS_BROWSER")&&!Array.isArray(t)&&t.startsWith(ar.URL_SCHEME)?(e=t.slice(ar.URL_SCHEME.length),new ar(e)):null;var e};Ys.registerSaveRouter(ir),Ys.registerLoadRouter(ir);class or{constructor(){this.indexedDB=sr()}async listModels(){return new Promise(((t,e)=>{const n=this.indexedDB.open(tr,1);n.onupgradeneeded=()=>rr(n),n.onsuccess=()=>{const s=n.result,r=s.transaction(nr,"readonly"),a=r.objectStore(nr).getAll();a.onsuccess=()=>{const e={};for(const t of a.result)e[t.modelPath]=t.modelArtifactsInfo;t(e)},a.onerror=t=>(s.close(),e(a.error)),r.oncomplete=()=>s.close()},n.onerror=t=>e(n.error)}))}async removeModel(t){var e;return t=(e=t).startsWith(ar.URL_SCHEME)?e.slice(ar.URL_SCHEME.length):e,new Promise(((e,n)=>{const s=this.indexedDB.open(tr,1);s.onupgradeneeded=()=>rr(s),s.onsuccess=()=>{const r=s.result,a=r.transaction(nr,"readwrite"),i=a.objectStore(nr),o=i.get(t);let l;o.onsuccess=()=>{if(null==o.result)return r.close(),n(new Error(`Cannot find model with path '${t}' in IndexedDB.`));{const s=i.delete(t),a=()=>{l=r.transaction(er,"readwrite");const s=l.objectStore(er).delete(t);s.onsuccess=()=>e(o.result.modelArtifactsInfo),s.onerror=t=>n(o.error)};s.onsuccess=a,s.onerror=t=>(a(),r.close(),n(o.error))}},o.onerror=t=>(r.close(),n(o.error)),a.oncomplete=()=>{null==l?r.close():l.oncomplete=()=>r.close()}},s.onerror=t=>n(s.error)}))}}const lr="/",ur="tensorflowjs_models",hr="info",cr="model_topology",pr="weight_specs",dr="weight_data",fr="model_metadata";function mr(t){return{info:[ur,t,hr].join(lr),topology:[ur,t,cr].join(lr),weightSpecs:[ur,t,pr].join(lr),weightData:[ur,t,dr].join(lr),modelMetadata:[ur,t,fr].join(lr)}}function gr(t){const e=t.split(lr);if(e.length<3)throw new Error(`Invalid key format: ${t}`);return e.slice(1,e.length-1).join(lr)}class yr{constructor(t){if(!Z().getBool("IS_BROWSER")||"undefined"==typeof window||void 0===window.localStorage)throw new Error("The current environment does not support local storage.");if(this.LS=window.localStorage,null==t||!t)throw new Error("For local storage, modelPath must not be null, undefined or empty.");this.modelPath=t,this.keys=mr(this.modelPath)}async save(t){if(t.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");{const e=JSON.stringify(t.modelTopology),n=JSON.stringify(t.weightSpecs),s=Js(t);try{this.LS.setItem(this.keys.info,JSON.stringify(s)),this.LS.setItem(this.keys.topology,e),this.LS.setItem(this.keys.weightSpecs,n),this.LS.setItem(this.keys.weightData,function(t){if(qs)return Buffer.from(t).toString("base64");const e=new Uint8Array(t);let n="";for(let t=0,s=e.length;t<s;t++)n+=String.fromCharCode(e[t]);return btoa(n)}(t.weightData));const r={format:t.format,generatedBy:t.generatedBy,convertedBy:t.convertedBy};return null!=t.signature&&(r.signature=t.signature),null!=t.userDefinedMetadata&&(r.userDefinedMetadata=t.userDefinedMetadata),null!=t.modelInitializer&&(r.modelInitializer=t.modelInitializer),this.LS.setItem(this.keys.modelMetadata,JSON.stringify(r)),{modelArtifactsInfo:s}}catch(t){throw this.LS.removeItem(this.keys.info),this.LS.removeItem(this.keys.topology),this.LS.removeItem(this.keys.weightSpecs),this.LS.removeItem(this.keys.weightData),this.LS.removeItem(this.keys.modelMetadata),new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${s.modelTopologyBytes}, weightSpecsBytes=${s.weightSpecsBytes}, weightDataBytes=${s.weightDataBytes}.`)}}}async load(){const t=JSON.parse(this.LS.getItem(this.keys.info));if(null==t)throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);if("JSON"!==t.modelTopologyType)throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");const e={},n=JSON.parse(this.LS.getItem(this.keys.topology));if(null==n)throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);e.modelTopology=n;const s=JSON.parse(this.LS.getItem(this.keys.weightSpecs));if(null==s)throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);e.weightSpecs=s;const r=this.LS.getItem(this.keys.modelMetadata);if(null!=r){const t=JSON.parse(r);e.format=t.format,e.generatedBy=t.generatedBy,e.convertedBy=t.convertedBy,null!=t.signature&&(e.signature=t.signature),null!=t.userDefinedMetadata&&(e.userDefinedMetadata=t.userDefinedMetadata),null!=t.modelInitializer&&(e.modelInitializer=t.modelInitializer)}const a=this.LS.getItem(this.keys.weightData);if(null==a)throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);return e.weightData=function(t){if(qs){const e=Buffer.from(t,"base64");return e.buffer.slice(e.byteOffset,e.byteOffset+e.byteLength)}const e=atob(t),n=new Uint8Array(e.length);for(let t=0;t<e.length;++t)n.set([e.charCodeAt(t)],t);return n.buffer}(a),e}}yr.URL_SCHEME="localstorage://";const br=t=>{return Z().getBool("IS_BROWSER")&&!Array.isArray(t)&&t.startsWith(yr.URL_SCHEME)?(e=t.slice(yr.URL_SCHEME.length),new yr(e)):null;var e};Ys.registerSaveRouter(br),Ys.registerLoadRouter(br);class kr{constructor(){v(Z().getBool("IS_BROWSER"),(()=>"Current environment is not a web browser")),v("undefined"==typeof window||void 0!==window.localStorage,(()=>"Current browser does not appear to support localStorage")),this.LS=window.localStorage}async listModels(){const t={},e=ur+lr,n=lr+hr;for(let s=0;s<this.LS.length;++s){const r=this.LS.key(s);r.startsWith(e)&&r.endsWith(n)&&(t[gr(r)]=JSON.parse(this.LS.getItem(r)))}return t}async removeModel(t){var e;const n=mr(t=(e=t).startsWith(yr.URL_SCHEME)?e.slice(yr.URL_SCHEME.length):e);if(null==this.LS.getItem(n.info))throw new Error(`Cannot find model at path '${t}'`);const s=JSON.parse(this.LS.getItem(n.info));return this.LS.removeItem(n.info),this.LS.removeItem(n.topology),this.LS.removeItem(n.weightSpecs),this.LS.removeItem(n.weightData),s}}class wr{constructor(){this.managers={}}static getInstance(){return null==wr.instance&&(wr.instance=new wr),wr.instance}static registerManager(t,e){v(null!=t,(()=>"scheme must not be undefined or null.")),t.endsWith("://")&&(t=t.slice(0,t.indexOf("://"))),v(t.length>0,(()=>"scheme must not be an empty string."));const n=wr.getInstance();v(null==n.managers[t],(()=>`A model store manager is already registered for scheme '${t}'.`)),n.managers[t]=e}static getManager(t){const e=this.getInstance().managers[t];if(null==e)throw new Error(`Cannot find model manager for scheme '${t}'`);return e}static getSchemes(){return Object.keys(this.getInstance().managers)}}class xr{fetch(t,e){return fetch(t,e)}now(){return performance.now()}encode(t,e){if("utf-8"!==e&&"utf8"!==e)throw new Error(`Browser's encoder only supports utf-8, but got ${e}`);return null==this.textEncoder&&(this.textEncoder=new TextEncoder),this.textEncoder.encode(t)}decode(t,e){return new TextDecoder(e).decode(t)}}if(Z().get("IS_BROWSER")){Z().setPlatform("browser",new xr);try{wr.registerManager(yr.URL_SCHEME,new kr)}catch(t){}try{wr.registerManager(ar.URL_SCHEME,new or)}catch(t){}}let Nr;function vr(t,e="float32",n){return e=e||"float32",j(t),new cs(t,e,n)}Z().get("IS_NODE")&&Z().setPlatform("node",new class{constructor(){this.util=n(758),this.textEncoder=new this.util.TextEncoder}fetch(t,e){return null!=Z().global.fetch?Z().global.fetch(t,e):(null==Nr&&(Nr=n(352)),Nr(t,e))}now(){const t=process.hrtime();return 1e3*t[0]+t[1]/1e6}encode(t,e){if("utf-8"!==e&&"utf8"!==e)throw new Error(`Node built-in encoder only supports utf-8, but got ${e}`);return this.textEncoder.encode(t)}decode(t,e){return 0===t.length?"":new this.util.TextDecoder(e).decode(t)}});const Ir=Rs({cast_:function(t,e){const n=Os(t,"x","cast");if(!function(t){return"bool"===t||"complex64"===t||"float32"===t||"int32"===t||"string"===t}(e))throw new Error(`Failed to cast to unknown dtype ${e}`);if("string"===e&&"string"!==n.dtype||"string"!==e&&"string"===n.dtype)throw new Error("Only strings can be casted to strings");const s={x:n},r={dtype:e};return $s.runKernel(wt,s,r)}}),Sr=Rs({clone_:function(t){const e={x:Os(t,"x","clone","string_or_numeric")};return $s.runKernel(oe,e)}});function Tr(t){return new Promise((t=>setTimeout(t))).then(t)}Ds(),ds={buffer:vr,cast:Ir,clone:Sr,print:function(t,e=!1){console.log(t.toString(e))}};class Er{constructor(t){if(!Z().getBool("IS_BROWSER"))throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");t.startsWith(Er.URL_SCHEME)&&(t=t.slice(Er.URL_SCHEME.length)),null!=t&&0!==t.length||(t="model"),this.modelTopologyFileName=t+".json",this.weightDataFileName=t+".weights.bin"}async save(t){if("undefined"==typeof document)throw new Error("Browser downloads are not supported in this environment since `document` is not present");const e=window.URL.createObjectURL(new Blob([t.weightData],{type:"application/octet-stream"}));if(t.modelTopology instanceof ArrayBuffer)throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");{const n=[{paths:["./"+this.weightDataFileName],weights:t.weightSpecs}],s={modelTopology:t.modelTopology,format:t.format,generatedBy:t.generatedBy,convertedBy:t.convertedBy,weightsManifest:n};null!=t.signature&&(s.signature=t.signature),null!=t.userDefinedMetadata&&(s.userDefinedMetadata=t.userDefinedMetadata),null!=t.modelInitializer&&(s.modelInitializer=t.modelInitializer);const r=window.URL.createObjectURL(new Blob([JSON.stringify(s)],{type:"application/json"})),a=null==this.jsonAnchor?document.createElement("a"):this.jsonAnchor;if(a.download=this.modelTopologyFileName,a.href=r,await Tr((()=>a.dispatchEvent(new MouseEvent("click")))),null!=t.weightData){const t=null==this.weightDataAnchor?document.createElement("a"):this.weightDataAnchor;t.download=this.weightDataFileName,t.href=e,await Tr((()=>t.dispatchEvent(new MouseEvent("click"))))}return{modelArtifactsInfo:Js(t)}}}}function Ar(t,e,n,s){!function(t){v(null!=t&&Array.isArray(t)&&t.length>0,(()=>"promises must be a none empty array"))}(t),function(t,e){v(t>=0&&t<=1,(()=>`Progress fraction must be in range [0, 1], but got startFraction ${t}`)),v(e>=0&&e<=1,(()=>`Progress fraction must be in range [0, 1], but got endFraction ${e}`)),v(e>=t,(()=>`startFraction must be no more than endFraction, but got startFraction ${t} and endFraction ${e}`))}(n=null==n?0:n,s=null==s?1:s);let r=0;return Promise.all(t.map((a=>(a.then((a=>{const i=n+ ++r/t.length*(s-n);return e(i),a})),a))))}async function Dr(t,e){null==e&&(e={});const n=null==e.fetchFunc?Z().platform.fetch:e.fetchFunc,s=t.map((t=>n(t,e.requestInit,{isBinary:!0}))),r=(null==e.onProgress?await Promise.all(s):await Ar(s,e.onProgress,0,.5)).map((t=>t.arrayBuffer()));return null==e.onProgress?await Promise.all(r):await Ar(r,e.onProgress,.5,1)}Er.URL_SCHEME="downloads://",Ys.registerSaveRouter((t=>Z().getBool("IS_BROWSER")&&!Array.isArray(t)&&t.startsWith(Er.URL_SCHEME)?function(t="model"){return new Er(t)}(t.slice(Er.URL_SCHEME.length)):null));class $r{constructor(t,e){if(this.DEFAULT_METHOD="POST",null==e&&(e={}),this.weightPathPrefix=e.weightPathPrefix,this.onProgress=e.onProgress,this.weightUrlConverter=e.weightUrlConverter,null!=e.fetchFunc?(v("function"==typeof e.fetchFunc,(()=>"Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)")),this.fetch=e.fetchFunc):this.fetch=Z().platform.fetch,v(null!=t&&t.length>0,(()=>"URL path for http must not be null, undefined or empty.")),Array.isArray(t)&&v(2===t.length,(()=>`URL paths for http must have a length of 2, (actual length is ${t.length}).`)),this.path=t,null!=e.requestInit&&null!=e.requestInit.body)throw new Error("requestInit is expected to have no pre-existing body, but has one.");this.requestInit=e.requestInit||{}}async save(t){if(t.modelTopology instanceof ArrayBuffer)throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");const e=Object.assign({method:this.DEFAULT_METHOD},this.requestInit);e.body=new FormData;const n=[{paths:["./model.weights.bin"],weights:t.weightSpecs}],s={modelTopology:t.modelTopology,format:t.format,generatedBy:t.generatedBy,convertedBy:t.convertedBy,weightsManifest:n};null!=t.signature&&(s.signature=t.signature),null!=t.userDefinedMetadata&&(s.userDefinedMetadata=t.userDefinedMetadata),null!=t.modelInitializer&&(s.modelInitializer=t.modelInitializer),e.body.append("model.json",new Blob([JSON.stringify(s)],{type:"application/json"}),"model.json"),null!=t.weightData&&e.body.append("model.weights.bin",new Blob([t.weightData],{type:"application/octet-stream"}),"model.weights.bin");const r=await this.fetch(this.path,e);if(r.ok)return{modelArtifactsInfo:Js(t),responses:[r]};throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${r.status}.`)}async load(){const t=await this.fetch(this.path,this.requestInit);if(!t.ok)throw new Error(`Request to ${this.path} failed with status code ${t.status}. Please verify this URL points to the model JSON of the model to load.`);let e;try{e=await t.json()}catch(t){let e=`Failed to parse model JSON of response from ${this.path}.`;throw this.path.endsWith(".pb")?e+=" Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.":e+=" Please make sure the server is serving valid JSON for this request.",new Error(e)}const n=e.modelTopology,s=e.weightsManifest,r=e.generatedBy,a=e.convertedBy,i=e.format,o=e.signature,l=e.userDefinedMetadata;if(null==n&&null==s)throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);let u,h;if(null!=s){const t=await this.loadWeights(s);[u,h]=t}const c={modelTopology:n,weightSpecs:u,weightData:h,generatedBy:r,convertedBy:a,format:i};null!=o&&(c.signature=o),null!=l&&(c.userDefinedMetadata=l);const p=e.modelInitializer;return p&&(c.modelInitializer=p),c}async loadWeights(t){const e=Array.isArray(this.path)?this.path[1]:this.path,[n,s]=function(t){const e=t.lastIndexOf("/"),n=t.lastIndexOf("?");return[t.substring(0,e)+"/",n>e?t.substring(n):""]}(e),r=this.weightPathPrefix||n,a=[];for(const e of t)a.push(...e.weights);const i=[],o=[];for(const e of t)for(const t of e.paths)null!=this.weightUrlConverter?o.push(this.weightUrlConverter(t)):i.push(r+t+s);return this.weightUrlConverter&&i.push(...await Promise.all(o)),[a,Ks(await Dr(i,{requestInit:this.requestInit,fetchFunc:this.fetch,onProgress:this.onProgress}))]}}function Mr(t){return null!=t.match($r.URL_SCHEME_REGEX)}$r.URL_SCHEME_REGEX=/^https?:\/\//;const Fr=(t,e)=>{if("undefined"==typeof fetch&&(null==e||null==e.fetchFunc))return null;{let n=!0;if(n=Array.isArray(t)?t.every((t=>Mr(t))):Mr(t),n)return _r(t,e)}return null};function _r(t,e){return new $r(t,e)}function zr(t,e){return _r(t,e)}let Cr;async function Or(t,e){let n=Os(t,"img","toPixels");if(!(t instanceof ms)){const t=n;n=Ir(t,"int32"),t.dispose()}if(2!==n.rank&&3!==n.rank)throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${n.rank}.`);const[s,r]=n.shape.slice(0,2),a=2===n.rank?1:n.shape[2];if(a>4||2===a)throw new Error(`toPixels only supports depth of size 1, 3 or 4 but got ${a}`);if("float32"!==n.dtype&&"int32"!==n.dtype)throw new Error(`Unsupported type for toPixels: ${n.dtype}. Please use float32 or int32 tensors.`);const i=await n.data(),o="float32"===n.dtype?255:1,l=new Uint8ClampedArray(r*s*4);for(let t=0;t<s*r;++t){const e=[0,0,0,255];for(let s=0;s<a;s++){const r=i[t*a+s];if("float32"===n.dtype){if(r<0||r>1)throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${r}.`)}else if("int32"===n.dtype&&(r<0||r>255))throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${r}.`);1===a?(e[0]=r*o,e[1]=r*o,e[2]=r*o):e[s]=r*o}const s=4*t;l[s+0]=Math.round(e[0]),l[s+1]=Math.round(e[1]),l[s+2]=Math.round(e[2]),l[s+3]=Math.round(e[3])}if(null!=e){e.width=r,e.height=s;const t=e.getContext("2d"),n=new ImageData(l,r,s);t.putImageData(n,0,0)}return n!==t&&n.dispose(),l}Ys.registerSaveRouter(Fr),Ys.registerLoadRouter(Fr);const Lr=Rs({fromPixels_:function(t,e=3){if(e>4)throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");if(null==t)throw new Error("pixels passed to tf.browser.fromPixels() can not be null");let n=!1,s=!1,r=!1,a=!1,i=!1,o=!1;if(t.data instanceof Uint8Array)n=!0;else if("undefined"!=typeof ImageData&&t instanceof ImageData)s=!0;else if("undefined"!=typeof HTMLVideoElement&&t instanceof HTMLVideoElement)r=!0;else if("undefined"!=typeof HTMLImageElement&&t instanceof HTMLImageElement)a=!0;else if(null!=t.getContext)i=!0;else{if(!("undefined"!=typeof ImageBitmap&&t instanceof ImageBitmap))throw new Error(`pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ${t.constructor.name}`);o=!0}if(r){const e=2;if(r&&t.readyState<e)throw new Error("The video element has not loaded data yet. Please wait for `loadeddata` event on the <video> element.")}if(null!=qn(Bn,$s.backendName)){const n={pixels:t},s={numChannels:e};return $s.runKernel(Bn,n,s)}const[l,u]=r?[t.videoWidth,t.videoHeight]:[t.width,t.height];let h,c;if(i?h=t.getContext("2d").getImageData(0,0,l,u).data:s||n?h=t.data:(a||r||o)&&(null==Cr&&(Cr=document.createElement("canvas").getContext("2d")),Cr.canvas.width=l,Cr.canvas.height=u,Cr.drawImage(t,0,0,l,u),h=Cr.getImageData(0,0,l,u).data),4===e)c=new Int32Array(h);else{const t=l*u;c=new Int32Array(t*e);for(let n=0;n<t;n++)for(let t=0;t<e;++t)c[n*e+t]=h[4*n+t]}return function(t,e,n){if(S(t),null!=e&&3!==e.length)throw new Error("tensor3d() requires shape to have three numbers");const s=_s(t,n);if(3!==s.length&&1!==s.length)throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");if(1===s.length&&null==e)throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");return Ws(t,e,s,n)}(c,[u,l,e],"int32")}});function Rr(t){const e=[];let n=0;for(;t>0;)1&t&&e.push(n),t/=2,n++;return e}function Br(t,e,n){return n<=t?n:n-(e-1)}function Wr(t,e){const n=[];for(let s=0;s<t;s++)n.push(e+s);return n}function Pr(t,e,n){let s=t[e];return(n&1<<e||null==s)&&(s=1),s}function Vr(t,e,n,s,r,a){let i=e[r];const o=n[r]||1;(t&1<<r||a&1<<r||null==i)&&(i=o>0?Number.MIN_SAFE_INTEGER:Number.MAX_SAFE_INTEGER);const l=s[r];return i<0&&(i+=l),i=N(0,i,l-1),i}function Ur(t,e,n,s,r,a){let i=e[r];const o=n[r]||1;(t&1<<r||a&1<<r||null==i)&&(i=o>0?Number.MAX_SAFE_INTEGER:Number.MIN_SAFE_INTEGER);const l=s[r];return i<0&&(i+=l),i=o>0?N(0,i,l):N(-1,i,l-1),i}function Hr(t,e,n){let s;const r=t.shape.length;let a;return s="number"==typeof e?[e,...new Array(r-1).fill(0)]:e.length<r?e.concat(new Array(r-e.length).fill(0)):e.slice(),s.forEach((t=>{v(-1!==t,(()=>"slice() does not support negative begin indexing."))})),a=null==n?new Array(r).fill(-1):"number"==typeof n?[n,...new Array(r-1).fill(-1)]:n.length<r?n.concat(new Array(r-n.length).fill(-1)):n,a=a.map(((e,n)=>e>=0?e:(v(-1===e,(()=>`Negative size values should be exactly -1 but got ${e} for the slice() size at index ${n}.`)),t.shape[n]-s[n]))),[s,a]}function jr(t,e,n,s,r,a,i,o,l){let u=e.slice(),h=n.slice(),c=s;null==s&&(c=new Array(u.length));const p=Rr(i);if(p.length>1)throw new Error("Multiple ellipses in slice is not allowed.");if(0!==i&&0!==o)throw new Error("Using both ellipsisMask and newAxisMask is not yet supported.");if(0!==i&&0!==l)throw new Error("Using both ellipsisMask and shrinkAxisMask is not yet supported.");const d=t.length-u.length,f=Rr(o),m=t.slice();f.forEach((t=>{u[t]=0,h[t]=1,m.splice(t,0,1)}));const{begin:g,end:y,strides:b}=function(t,e,n,s,r,a,i,o,l){const u=t.length;let h=new Array(u),c=new Array(u),p=new Array(u);if(e.length&&n>0){const l=e[0],u=n+1;h=function(t,e,n,s,r){const a=[...r],i=Wr(n,e);for(let r=0;r<a.length;r++)if(i.indexOf(r)>-1)a[r]=0;else{const i=Br(e,n,r);let o=s[i];t&1<<i&&(o=0),a[r]=o}return a}(i,l,u,s,t),c=function(t,e,n,s,r){const a=[...r],i=Wr(n,e);for(let r=0;r<a.length;r++)if(i.indexOf(r)>-1)a[r]=Number.MAX_SAFE_INTEGER;else{const i=Br(e,n,r);let o=s[i];t&1<<i&&(o=Number.MAX_SAFE_INTEGER),a[r]=o}for(let t=0;t<a.length;t++){const e=r[t];a[t]<0&&(a[t]+=e),a[t]=N(0,a[t],r[t])}return a}(o,l,u,r,t),p=function(t,e,n,s){const r=[...t];for(let t=r.length;t<s.length;t++)r.push(1);for(let t=0;t<n;t++)0===t?r[e]=1:(r.splice(e,0,1),r.pop());return r}(a,l,u,t)}else for(let e=0;e<u;e++)h[e]=Vr(i,s,a,t,e,l),c[e]=Ur(o,r,a,t,e,l),p[e]=Pr(a,e,l);return{begin:h,end:c,strides:p}}(m,p,d,u,h,c,r,a,i);u=g,h=y,c=b;const k=Rr(l);k.forEach((t=>{h[t]=u[t]+1,c[t]=1}));const w=function(t,e,n){const s=[];for(let r=0;r<t.length;r++)s[r]=Math.ceil((e[r]-t[r])/n[r]);return s}(u,h,c),x=w.filter(((t,e)=>-1===k.indexOf(e)));return{nonStrided:c.every((t=>1===t)),$begin:u,$end:h,$strides:c,size:w,newShape:m,outShape:x}}class qr{getClassName(){return this.constructor.className}static fromConfig(t,e){return new t(e)}}class Gr{constructor(){this.classNameMap={}}static getMap(){return null==Gr.instance&&(Gr.instance=new Gr),Gr.instance}static register(t){Gr.getMap().classNameMap[t.className]=[t,t.fromConfig]}}function Kr(t){v(null!=t.className,(()=>"Class being registered does not have the static className property defined.")),v("string"==typeof t.className,(()=>"className is required to be a string, but got type "+typeof t.className)),v(t.className.length>0,(()=>"Class being registered has an empty-string as its className, which is disallowed.")),Gr.register(t)}function Jr(t){Z().getBool("DEPRECATION_WARNINGS_ENABLED")&&console.warn(t+" You can disable deprecation warnings with tf.disableDeprecationWarnings().")}function Zr(){return $s}function Yr(){return $s.memory()}function Xr(t,e){return $s.tidy(t,e)}function Qr(t){Ss(t).forEach((t=>t.dispose()))}function ta(t){return $s.keep(t)}function ea(t){return $s.customGrad(t)}function na(t,e){if((z(t)&&"string"!==e||Array.isArray(t))&&"complex64"!==e)throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");if("string"===e&&z(t)&&!(t instanceof Uint8Array))throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");return Ws(t,[],[],e)}fs=Jr;class sa extends qr{minimize(t,e=!1,n){const{value:s,grads:r}=this.computeGradients(t,n);if(null!=n){const t=n.map((t=>({name:t.name,tensor:r[t.name]})));this.applyGradients(t)}else this.applyGradients(r);return Qr(r),e?s:(s.dispose(),null)}get iterations(){return null==this.iterations_&&(this.iterations_=0),this.iterations_}incrementIterations(){this.iterations_=this.iterations+1}computeGradients(t,e){return function(t,e){v(R(t),(()=>"The f passed in variableGrads(f) must be a function")),v(null==e||Array.isArray(e)&&e.every((t=>t instanceof gs)),(()=>"The varList passed in variableGrads(f, varList) must be an array of variables"));const n=null!=e;if(!n){e=[];for(const t in $s.registeredVariables)e.push($s.registeredVariables[t])}const s=n?e.filter((t=>!t.trainable)):null,r=e.length;v((e=e.filter((t=>t.trainable))).length>0,(()=>`variableGrads() expects at least one of the input variables to be trainable, but none of the ${r} variables is trainable.`));const{value:a,grads:i}=$s.gradients(t,e,null,!0);v(i.some((t=>null!=t)),(()=>"Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize().")),v(0===a.rank,(()=>`The f passed in variableGrads(f) must return a scalar, but it returned a rank-${a.rank} tensor`));const o={};return e.forEach(((t,e)=>{null!=i[e]&&(o[t.name]=i[e])})),null!=s&&s.forEach((t=>o[t.name]=null)),{value:a,grads:o}}(t,e)}dispose(){null!=this.iterations_&&Qr(this.iterations_)}async saveIterations(){return null==this.iterations_&&(this.iterations_=0),{name:"iter",tensor:na(this.iterations_,"int32")}}async getWeights(){throw new Error("getWeights() is not implemented for this optimizer yet.")}async setWeights(t){throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`)}async extractIterations(t){return this.iterations_=(await t[0].tensor.data())[0],t.slice(1)}}Object.defineProperty(sa,Symbol.hasInstance,{value:t=>null!=t.minimize&&null!=t.computeGradients&&null!=t.applyGradients});const ra=Rs({abs_:function(t){const e=Os(t,"x","abs");if("complex64"===e.dtype){const t={x:e};return $s.runKernel(It,t)}{const t={x:e};return $s.runKernel(et,t)}}}),aa=Rs({add_:function(t,e){let n=Os(t,"a","add"),s=Os(e,"b","add");[n,s]=Is(n,s);const r={a:n,b:s};return $s.runKernel(rt,r)}}),ia=Rs({all_:function(t,e=null,n=!1){const s={x:Os(t,"x","all","bool")},r={axis:e,keepDims:n};return $s.runKernel("All",s,r)}}),oa=Rs({any_:function(t,e=null,n=!1){const s={x:Os(t,"x","any","bool")},r={axis:e,keepDims:n};return $s.runKernel("Any",s,r)}}),la=Rs({argMax_:function(t,e=0){const n={x:Os(t,"x","argMax")},s={axis:e};return $s.runKernel(it,n,s)}});function ua(t,e,n,s,r="NHWC",a){return pa(t,[...e,t[3]],n,a,s,null,null,xa(r))}function ha(t,e,n,s,r,a,i="channelsLast"){const[o,l]=ma(e);let u;if("channelsLast"===i)u=[o,l,t[3],t[3]];else{if("channelsFirst"!==i)throw new Error(`Unknown dataFormat ${i}`);u=[o,l,t[1],t[1]]}return pa(t,u,n,s,r,a,!1,i)}function ca(t,e,n,s,r,a,i="NDHWC"){const[o,l,u]=ga(e);let h,c;if("NDHWC"===i)c="channelsLast",h=[o,l,u,t[4],t[4]];else{if("NCDHW"!==i)throw new Error(`Unknown dataFormat ${i}`);c="channelsFirst",h=[o,l,u,t[1],t[1]]}return da(t,h,n,s,r,!1,c,a)}function pa(t,e,n,s,r,a,i=!1,o="channelsLast"){let[l,u,h,c]=[-1,-1,-1,-1];if("channelsLast"===o)[l,u,h,c]=t;else{if("channelsFirst"!==o)throw new Error(`Unknown dataFormat ${o}`);[l,c,u,h]=t}const[p,d,,f]=e,[m,g]=ma(n),[y,b]=ma(s),k=ya(p,y),w=ya(d,b),{padInfo:x,outHeight:N,outWidth:v}=function(t,e,n,s,r,a,i,o,l){let u,h,c;if("number"==typeof t){u={top:t,bottom:t,left:t,right:t,type:0===t?"VALID":"NUMBER"};const r=function(t,e,n,s,r){null==s&&(s=fa(t,e,n));const a=t[1];return[ba((t[0]-e+2*s)/n+1,r),ba((a-e+2*s)/n+1,r)]}([e,n],a,s,t,o);h=r[0],c=r[1]}else if("same"===t){h=Math.ceil(e/s),c=Math.ceil(n/r);const t=Math.max(0,(h-1)*s+a-e),o=Math.max(0,(c-1)*r+i-n),l=Math.floor(t/2),p=t-l,d=Math.floor(o/2);u={top:l,bottom:p,left:d,right:o-d,type:"SAME"}}else if("valid"===t)u={top:0,bottom:0,left:0,right:0,type:"VALID"},h=Math.ceil((e-a+1)/s),c=Math.ceil((n-i+1)/r);else{if("object"!=typeof t)throw Error(`Unknown padding parameter: ${t}`);{const p="channelsLast"===l?t[1][0]:t[2][0],d="channelsLast"===l?t[1][1]:t[2][1],f="channelsLast"===l?t[2][0]:t[3][0],m="channelsLast"===l?t[2][1]:t[3][1];u={top:p,bottom:d,left:f,right:m,type:0===p&&0===d&&0===f&&0===m?"VALID":"EXPLICIT"},h=ba((e-a+p+d)/s+1,o),c=ba((n-i+f+m)/r+1,o)}}return{padInfo:u,outHeight:h,outWidth:c}}(r,u,h,m,g,k,w,a,o),I=i?f*c:f;let S;return"channelsFirst"===o?S=[l,I,N,v]:"channelsLast"===o&&(S=[l,N,v,I]),{batchSize:l,dataFormat:o,inHeight:u,inWidth:h,inChannels:c,outHeight:N,outWidth:v,outChannels:I,padInfo:x,strideHeight:m,strideWidth:g,filterHeight:p,filterWidth:d,effectiveFilterHeight:k,effectiveFilterWidth:w,dilationHeight:y,dilationWidth:b,inShape:t,outShape:S,filterShape:e}}function da(t,e,n,s,r,a=!1,i="channelsLast",o){let[l,u,h,c,p]=[-1,-1,-1,-1,-1];if("channelsLast"===i)[l,u,h,c,p]=t;else{if("channelsFirst"!==i)throw new Error(`Unknown dataFormat ${i}`);[l,p,u,h,c]=t}const[d,f,m,,g]=e,[y,b,k]=ga(n),[w,x,N]=ga(s),v=ya(d,w),I=ya(f,x),S=ya(m,N),{padInfo:T,outDepth:E,outHeight:A,outWidth:D}=function(t,e,n,s,r,a,i,o,l,u,h){let c,p,d,f;if("number"==typeof t){c={top:t,bottom:t,left:t,right:t,front:t,back:t,type:0===t?"VALID":"NUMBER"};const a=function(t,e,n,s,r,a){null==r&&(r=fa(t,e,s));const i=t[1],o=t[2];return[ba((t[0]-e+2*r)/s+1,a),ba((i-e+2*r)/s+1,a),ba((o-e+2*r)/s+1,a),1]}([e,n,s,1],o,0,r,t,h);p=a[0],d=a[1],f=a[2]}else if("same"===t){p=Math.ceil(e/r),d=Math.ceil(n/a),f=Math.ceil(s/i);const t=(p-1)*r+o-e,h=(d-1)*a+l-n,m=(f-1)*i+u-s,g=Math.floor(t/2),y=t-g,b=Math.floor(h/2),k=h-b,w=Math.floor(m/2);c={top:b,bottom:k,left:w,right:m-w,front:g,back:y,type:"SAME"}}else{if("valid"!==t)throw Error(`Unknown padding parameter: ${t}`);c={top:0,bottom:0,left:0,right:0,front:0,back:0,type:"VALID"},p=Math.ceil((e-o+1)/r),d=Math.ceil((n-l+1)/a),f=Math.ceil((s-u+1)/i)}return{padInfo:c,outDepth:p,outHeight:d,outWidth:f}}(r,u,h,c,y,b,k,v,I,S,o),$=a?g*p:g;let M;return"channelsFirst"===i?M=[l,$,E,A,D]:"channelsLast"===i&&(M=[l,E,A,D,$]),{batchSize:l,dataFormat:i,inDepth:u,inHeight:h,inWidth:c,inChannels:p,outDepth:E,outHeight:A,outWidth:D,outChannels:$,padInfo:T,strideDepth:y,strideHeight:b,strideWidth:k,filterDepth:d,filterHeight:f,filterWidth:m,effectiveFilterDepth:v,effectiveFilterHeight:I,effectiveFilterWidth:S,dilationDepth:w,dilationHeight:x,dilationWidth:N,inShape:t,outShape:M,filterShape:e}}function fa(t,e,n,s=1){const r=ya(e,s);return Math.floor((t[0]*(n-1)-n+r)/2)}function ma(t){return"number"==typeof t?[t,t,t]:2===t.length?[t[0],t[1],1]:t}function ga(t){return"number"==typeof t?[t,t,t]:t}function ya(t,e){return e<=1?t:t+(t-1)*(e-1)}function ba(t,e){if(!e)return Math.trunc(t);switch(e){case"round":return Math.round(t);case"ceil":return Math.ceil(t);case"floor":return Math.floor(t);default:throw new Error(`Unknown roundingMode ${e}`)}}function ka(t){const[e,n,s]=ma(t);return 1===e&&1===n&&1===s}function wa(t,e){return ka(t)||ka(e)}function xa(t){if("NHWC"===t)return"channelsLast";if("NCHW"===t)return"channelsFirst";throw new Error(`Unknown dataFormat ${t}`)}const Na=Rs({reshape_:function(t,e){const n={x:Os(t,"x","reshape","string_or_numeric")},s={shape:e};return $s.runKernel(tn,n,s)}}),va=Rs({avgPool_:function(t,e,n,s,r){const a=Os(t,"x","avgPool","float32");v(wa(n,1),(()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`));let i=a,o=!1;3===a.rank&&(o=!0,i=Na(a,[1,a.shape[0],a.shape[1],a.shape[2]])),v(4===i.rank,(()=>`Error in avgPool: x must be rank 4 but got rank ${i.rank}.`)),null!=r&&v(D(s),(()=>`Error in avgPool: pad must be an integer when using, dimRoundingMode ${r} but got pad ${s}.`));const l={x:i},u={filterSize:e,strides:n,pad:s,dimRoundingMode:r};let h=$s.runKernel(dt,l,u);return h=Ir(h,a.dtype),o?Na(h,[h.shape[1],h.shape[2],h.shape[3]]):h}}),Ia=Rs({avgPool3d_:function(t,e,n,s,r,a="NDHWC",i){null==i?i=[1,1,1]:Jr("dilations is deprecated, this field will be gone in v3.0.0.");const o=Os(t,"x","avgPool3d","float32");let l=o,u=!1;4===o.rank&&(u=!0,l=Na(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),v(5===l.rank,(()=>`Error in avgPool3d: x must be rank 5 but got rank ${l.rank}.`)),v("NDHWC"===a,(()=>`Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${a}`)),v(wa(n,i),(()=>`Error in avgPool3d: Either strides or dilations must be 1. Got strides ${n} and dilations '${i}'`)),null!=r&&v(D(s),(()=>`Error in avgPool3d: pad must be an integer when using, dimRoundingMode ${r} but got pad ${s}.`));const h={x:l},c={filterSize:e,strides:n,pad:s,dimRoundingMode:r,dataFormat:a,dilations:i};let p=$s.runKernel(mt,h,c);return p=Ir(p,l.dtype),u?Na(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}}),Sa=Rs({batchNorm_:function(t,e,n,s,r,a){null==a&&(a=.001);const i=Os(t,"x","batchNorm"),o=Os(e,"mean","batchNorm"),l=Os(n,"variance","batchNorm");let u,h;null!=r&&(u=Os(r,"scale","batchNorm")),null!=s&&(h=Os(s,"offset","batchNorm")),v(o.rank===l.rank,(()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),v(null==h||o.rank===h.rank,(()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),v(null==u||o.rank===u.rank,(()=>"Batch normalization gradient requires mean and scale to have equal ranks."));const c={x:function(t){let e;return e=0===t.rank||1===t.rank?Na(t,[1,1,1,t.size]):2===t.rank?Na(t,[1,1,t.shape[0],t.shape[1]]):3===t.rank?Na(t,[1,t.shape[0],t.shape[1],t.shape[2]]):t,e}(i),scale:u,offset:h,mean:o,variance:l},p={varianceEpsilon:a},d=$s.runKernel(ne,c,p);return Na(d,i.shape)}}),Ta=Rs({batchNorm2d_:function(t,e,n,s,r,a){const i=Os(t,"x","batchNorm"),o=Os(e,"mean","batchNorm"),l=Os(n,"variance","batchNorm");let u,h;return null!=r&&(u=Os(r,"scale","batchNorm")),null!=s&&(h=Os(s,"offset","batchNorm")),v(2===i.rank,(()=>`Error in batchNorm2D: x must be rank 2 but got rank ${i.rank}.`)),v(2===o.rank||1===o.rank,(()=>`Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${o.rank}.`)),v(2===l.rank||1===l.rank,(()=>`Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${l.rank}.`)),null!=u&&v(2===u.rank||1===u.rank,(()=>`Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${u.rank}.`)),null!=h&&v(2===h.rank||1===h.rank,(()=>`Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${h.rank}.`)),Sa(i,o,l,h,u,a)}}),Ea=Rs({batchNorm3d_:function(t,e,n,s,r,a){const i=Os(t,"x","batchNorm"),o=Os(e,"mean","batchNorm"),l=Os(n,"variance","batchNorm");let u,h;return null!=r&&(u=Os(r,"scale","batchNorm")),null!=s&&(h=Os(s,"offset","batchNorm")),v(3===i.rank,(()=>`Error in batchNorm3D: x must be rank 3 but got rank ${i.rank}.`)),v(3===o.rank||1===o.rank,(()=>`Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${o.rank}.`)),v(3===l.rank||1===l.rank,(()=>`Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${l.rank}.`)),null!=u&&v(3===u.rank||1===u.rank,(()=>`Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${u.rank}.`)),null!=h&&v(3===h.rank||1===h.rank,(()=>`Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${h.rank}.`)),Sa(i,o,l,h,u,a)}}),Aa=Rs({batchNorm4d_:function(t,e,n,s,r,a){const i=Os(t,"x","batchNorm"),o=Os(e,"mean","batchNorm"),l=Os(n,"variance","batchNorm");let u,h;return null!=r&&(u=Os(r,"scale","batchNorm")),null!=s&&(h=Os(s,"offset","batchNorm")),v(4===i.rank,(()=>`Error in batchNorm4D: x must be rank 4 but got rank ${i.rank}.`)),v(4===o.rank||1===o.rank,(()=>`Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${o.rank}.`)),v(4===l.rank||1===l.rank,(()=>`Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${l.rank}.`)),null!=u&&v(4===u.rank||1===u.rank,(()=>`Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${u.rank}.`)),null!=h&&v(4===h.rank||1===h.rank,(()=>`Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${h.rank}.`)),Sa(i,o,l,h,u,a)}}),Da=Rs({clipByValue_:function(t,e,n){const s=Os(t,"x","clipByValue");v(e<=n,(()=>`Error in clip: min (${e}) must be less than or equal to max (${n}).`));const r={x:s},a={clipValueMin:e,clipValueMax:n};return $s.runKernel(Nt,r,a)}}),$a=Rs({concat_:function(t,e=0){v(t.length>=1,(()=>"Pass at least one tensor to concat"));const n=Ls(t,"tensors","concat","string_or_numeric");if("complex64"===n[0].dtype&&n.forEach((t=>{if("complex64"!==t.dtype)throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${t.dtype}. `)})),1===n.length)return Sr(n[0]);const s=n,r={axis:e};return $s.runKernel(St,s,r)}}),Ma=Rs({concat1d_:function(t){return $a(t,0)}}),Fa=Rs({concat2d_:function(t,e){return $a(t,e)}}),_a=Rs({concat3d_:function(t,e){return $a(t,e)}}),za=Rs({concat4d_:function(t,e){return $a(t,e)}}),Ca=Rs({conv2d_:function(t,e,n,s,r="NHWC",a=[1,1],i){const o=Os(t,"x","conv2d"),l=Os(e,"filter","conv2d");let u=o,h=!1;3===o.rank&&(h=!0,u=Na(o,[1,o.shape[0],o.shape[1],o.shape[2]])),v(4===u.rank,(()=>`Error in conv2d: input must be rank 4, but got rank ${u.rank}.`)),v(4===l.rank,(()=>`Error in conv2d: filter must be rank 4, but got rank ${l.rank}.`)),null!=i&&v(D(s),(()=>`Error in conv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${s}.`));const c="NHWC"===r?u.shape[3]:u.shape[1];v(c===l.shape[2],(()=>`Error in conv2d: depth of input (${c}) must match input depth for filter ${l.shape[2]}.`)),v(wa(n,a),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`));const p={x:u,filter:l},d={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i},f=$s.runKernel(Tt,p,d);return h?Na(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),Oa=Rs({conv1d_:function(t,e,n,s,r="NWC",a=1,i){const o=Os(t,"x","conv1d"),l=Os(e,"filter","conv1d");let u=o,h=!1;2===o.rank&&(h=!0,u=Na(o,[1,o.shape[0],o.shape[1]])),v(3===u.rank,(()=>`Error in conv1d: input must be rank 3, but got rank ${u.rank}.`)),v(3===l.rank,(()=>`Error in conv1d: filter must be rank 3, but got rank ${l.rank}.`)),null!=i&&v(D(s),(()=>`Error in conv1d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${s}.`)),v(u.shape[2]===l.shape[1],(()=>`Error in conv1d: depth of input (${u.shape[2]}) must match input depth for filter ${l.shape[1]}.`)),v(wa(n,a),(()=>`Error in conv1D: Either stride or dilation must be 1. Got stride ${n} and dilation '${a}'`)),v("NWC"===r,(()=>`Error in conv1d: got dataFormat of ${r} but only NWC is currently supported.`));const c=Na(l,[1,l.shape[0],l.shape[1],l.shape[2]]),p=Na(u,[u.shape[0],1,u.shape[1],u.shape[2]]),d=Ca(p,c,[1,n],s,"NHWC",[1,a],i);return Na(d,h?[d.shape[2],d.shape[3]]:[d.shape[0],d.shape[2],d.shape[3]])}}),La=Rs({conv2DBackpropInput_:function(t,e,n,s,r,a="NHWC",i){v(t.length===e.rank,(()=>`Length of inShape (${t.length}) and rank of dy (${e.rank}) must match`));let o=t,l=e,u=!1;3===e.rank&&(u=!0,l=Na(e,[1,e.shape[0],e.shape[1],e.shape[2]]),o=[1,t[0],t[1],t[2]]),v(4===o.length,(()=>`Error in conv2dDerInput: inShape must be length 4, but got length ${o.length}.`)),v(4===l.rank,(()=>`Error in conv2dDerInput: dy must be rank 4, but got rank ${l.rank}`)),v(4===n.rank,(()=>`Error in conv2dDerInput: filter must be rank 4, but got rank ${n.rank}`));const h="NHWC"===a?o[3]:o[1],c="NHWC"===a?l.shape[3]:l.shape[1];v(h===n.shape[2],(()=>`Error in conv2dDerInput: depth of input (${h}) must match input depth for filter ${n.shape[2]}.`)),v(c===n.shape[3],(()=>`Error in conv2dDerInput: depth of output (${c}) must match output depth for filter ${n.shape[3]}.`)),null!=i&&v(D(r),(()=>`Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode ${i} but got pad ${r}.`));const p={dy:l,filter:n},d={strides:s,pad:r,dataFormat:a,dimRoundingMode:i,inputShape:o},f=$s.runKernel(At,p,d);return u?Na(f,[f.shape[1],f.shape[2],f.shape[3]]):f}}),Ra=Rs({conv2dTranspose_:function(t,e,n,s,r,a){const i=Os(t,"x","conv2dTranspose"),o=Os(e,"filter","conv2dTranspose");return La(n,i,o,s,r,"NHWC",a)}}),Ba=Rs({conv3d_:function(t,e,n,s,r="NDHWC",a=[1,1,1]){const i=Os(t,"x","conv3d"),o=Os(e,"filter","conv3d");let l=i,u=!1;4===i.rank&&(u=!0,l=Na(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),v(5===l.rank,(()=>`Error in conv3d: input must be rank 5, but got rank ${l.rank}.`)),v(5===o.rank,(()=>`Error in conv3d: filter must be rank 5, but got rank ${o.rank}.`)),v(l.shape[4]===o.shape[3],(()=>`Error in conv3d: depth of input (${l.shape[4]}) must match input depth for filter ${o.shape[3]}.`)),v(wa(n,a),(()=>`Error in conv3D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`)),v("NDHWC"===r,(()=>`Error in conv3d: got dataFormat of ${r} but only NDHWC is currently supported.`));const h={x:l,filter:o},c={strides:n,pad:s,dataFormat:r,dilations:a},p=$s.runKernel(Dt,h,c);return u?Na(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}}),Wa=Rs({depthwiseConv2d_:function(t,e,n,s,r="NHWC",a=[1,1],i){const o=Os(t,"x","depthwiseConv2d"),l=Os(e,"filter","depthwiseConv2d");let u=o,h=!1;3===o.rank&&(h=!0,u=Na(o,[1,o.shape[0],o.shape[1],o.shape[2]])),v(4===u.rank,(()=>`Error in depthwiseConv2d: input must be rank 4, but got rank ${u.rank}.`)),v(4===l.rank,(()=>`Error in depthwiseConv2d: filter must be rank 4, but got rank ${l.rank}.`)),v(u.shape[3]===l.shape[2],(()=>`Error in depthwiseConv2d: number of input channels (${u.shape[3]}) must match the inChannels dimension in filter ${l.shape[2]}.`)),null!=i&&v(D(s),(()=>`Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${s}.`));const c={x:u,filter:l},p={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i},d=$s.runKernel(Rt,c,p);return h?Na(d,[d.shape[1],d.shape[2],d.shape[3]]):d}}),Pa=Rs({floorDiv_:function(t,e){let n=Os(t,"a","floorDiv"),s=Os(e,"b","floorDiv");[n,s]=Is(n,s);const r={a:n,b:s};return $s.runKernel(ee,r)}}),Va=Rs({div_:function(t,e){let n=Os(t,"a","div"),s=Os(e,"b","div");if([n,s]=Is(n,s),"int32"===n.dtype&&"int32"===s.dtype)return Pa(n,s);const r={a:n,b:s};return $s.runKernel(Ht,r,{})}}),Ua=Rs({elu_:function(t){const e={x:Os(t,"x","elu")};return $s.runKernel(jt,e)}});function Ha(t,e){const n=t.length,s=[];for(let r=0;r<n;r++){const a=n-1-r,i=t[a]||1;(e[e.length-1-r]||1)>1&&1===i&&s.unshift(a)}return s}function ja(t,e){const n=[];for(let s=0;s<e.length;s++){const r=t[t.length-s-1],a=e.length-s-1,i=e[a];(null==r||1===r&&i>1)&&n.unshift(a)}return n}function qa(t,e){const n=[],s=Math.max(t.length,e.length);for(let r=0;r<s;r++){let s=t[t.length-r-1];null==s&&(s=1);let a=e[e.length-r-1];if(null==a&&(a=1),1===s)n.unshift(a);else if(1===a)n.unshift(s);else{if(s!==a)throw Error(`Operands could not be broadcast together with shapes ${t} and ${e}.`);n.unshift(s)}}return n}const Ga=Rs({equal_:function(t,e){let n=Os(t,"a","equal"),s=Os(e,"b","equal");[n,s]=Is(n,s),qa(n.shape,s.shape);const r={a:n,b:s};return $s.runKernel(Kt,r)}}),Ka=Rs({expandDims_:function(t,e=0){const n=Os(t,"x","expandDims","string_or_numeric");v(e<=n.rank,(()=>"Axis must be <= rank of the tensor"));const s={input:n},r={dim:e};return $s.runKernel(Zt,s,r)}}),Ja=Rs({tile_:function(t,e){const n=Os(t,"x","tile","string_or_numeric");v(n.rank===e.length,(()=>`Error in transpose: rank of input ${n.rank} must match length of reps ${e}.`));const s={x:n},r={reps:e};return $s.runKernel(Mn,s,r)}}),Za=Rs({eye_:function(t,e,n,s="float32"){null==e&&(e=t);const r=vr([t,e],s),a=t<=e?t:e;for(let t=0;t<a;++t)r.set(1,t,t);const i=Na(r.toTensor(),[t,e]);if(null==n)return i;if(1===n.length)return Ja(Ka(i,0),[n[0],1,1]);if(2===n.length)return Ja(Ka(Ka(i,0),0),[n[0],n[1],1,1]);if(3===n.length)return Ja(Ka(Ka(Ka(i,0),0),0),[n[0],n[1],n[2],1,1]);throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${n.length}D.`)}});function Ya(t,e,n){const s={shape:t,value:e,dtype:n};return $s.runKernel(Xt,{},s)}const Xa=Rs({floor_:function(t){const e={x:Os(t,"x","floor")};return $s.runKernel(te,e)}}),Qa=Rs({gather_:function(t,e,n=0,s=0){const r={x:Os(t,"x","gather"),indices:Os(e,"indices","gather","int32")},a={axis:n,batchDims:s};return $s.runKernel(se,r,a)}}),ti=Rs({greater_:function(t,e){let n=Os(t,"a","greater"),s=Os(e,"b","greater");[n,s]=Is(n,s),qa(n.shape,s.shape);const r={a:n,b:s};return $s.runKernel(ae,r)}}),ei=Rs({greaterEqual_:function(t,e){let n=Os(t,"a","greaterEqual"),s=Os(e,"b","greaterEqual");[n,s]=Is(n,s),qa(n.shape,s.shape);const r={a:n,b:s};return $s.runKernel(ie,r)}}),ni=Rs({leakyRelu_:function(t,e=.2){const n={x:Os(t,"x","leakyRelu")},s={alpha:e};return $s.runKernel(de,n,s)}}),si=Rs({log_:function(t){const e={x:Os(t,"x","log")};return $s.runKernel(ye,e)}}),ri=Rs({exp_:function(t){const e={x:Os(t,"x","exp")};return $s.runKernel(Jt,e)}}),ai=Rs({max_:function(t,e=null,n=!1){const s={x:Os(t,"x","max")},r={reductionIndices:e,keepDims:n};return $s.runKernel(Ie,s,r)}}),ii=Rs({mul_:function(t,e){let n=Os(t,"a","mul"),s=Os(e,"b","mul");[n,s]=Is(n,s);const r={a:n,b:s};return $s.runKernel(Le,r)}}),oi=Rs({sub_:function(t,e){let n=Os(t,"a","sub"),s=Os(e,"b","sub");[n,s]=Is(n,s);const r={a:n,b:s};return $s.runKernel(Tn,r)}}),li=Rs({sum_:function(t,e=null,n=!1){let s=Os(t,"x","sum");"bool"===s.dtype&&(s=Ir(s,"int32"));const r={x:s},a={axis:e,keepDims:n};return $s.runKernel(wn,r,a)}}),ui=Rs({logSoftmax_:function(t,e=-1){const n=Os(t,"logits","logSoftmax");if(-1===e&&(e=n.rank-1),e!==n.rank-1)throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and axis was ${e}`);return ea(((t,n)=>{const s=ai(t,e,!0),r=oi(t,s),a=oi(Ir(r,"float32"),si(li(ri(r),e,!0)));return n([a]),{value:a,gradFunc:(t,n)=>{const[s]=n,r=ri(s);return oi(t,ii(li(t,e,!0),r))}}}))(n)}}),hi=Rs({logicalAnd_:function(t,e){const n=Os(t,"a","logicalAnd","bool"),s=Os(e,"b","logicalAnd","bool");qa(n.shape,s.shape);const r={a:n,b:s};return $s.runKernel(ke,r)}}),ci=Rs({maxPool_:function(t,e,n,s,r){const a=Os(t,"x","maxPool");let i=a,o=!1;3===a.rank&&(o=!0,i=Na(a,[1,a.shape[0],a.shape[1],a.shape[2]])),v(4===i.rank,(()=>`Error in maxPool: input must be rank 4 but got rank ${i.rank}.`)),v(wa(n,1),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`)),null!=r&&v(D(s),(()=>`Error in maxPool: pad must be an integer when using, dimRoundingMode ${r} but got pad ${s}.`));const l={x:i},u={filterSize:e,strides:n,pad:s,dimRoundingMode:r},h=$s.runKernel(Te,l,u);return o?Na(h,[h.shape[1],h.shape[2],h.shape[3]]):h}}),pi=Rs({maxPool3d_:function(t,e=[1,1,1],n,s,r,a="NDHWC",i){null==i?i=[1,1,1]:Jr("dilations is deprecated, this field will be gone in v3.0.0.");const o=Os(t,"x","maxPool3d");let l=o,u=!1;4===o.rank&&(u=!0,l=Na(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),v(5===l.rank,(()=>`Error in maxPool3d: x must be rank 5 but got rank ${l.rank}.`)),v("NDHWC"===a,(()=>`Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${a}`)),v(wa(n,i),(()=>`Error in maxPool3d: Either strides or dilations must be 1. Got strides ${n} and dilations '${i}'`)),null!=r&&v(D(s),(()=>`Error in maxPool3d: pad must be an integer when using, dimRoundingMode ${r} but got pad ${s}.`));const h={x:l},c={filterSize:e,strides:n,pad:s,dimRoundingMode:r,dataFormat:a,dilations:i},p=$s.runKernel(Ae,h,c);return u?Na(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}}),di=Rs({maximum_:function(t,e){let n=Os(t,"a","maximum"),s=Os(e,"b","maximum");[n,s]=Is(n,s),"bool"===n.dtype&&(n=Ir(n,"int32"),s=Ir(s,"int32")),qa(n.shape,s.shape);const r={a:n,b:s};return $s.runKernel(Se,r)}}),fi=Rs({mean_:function(t,e=null,n=!1){const s={x:Os(t,"x","mean")},r={axis:e,keepDims:n};return $s.runKernel(Me,s,r)}}),mi=Rs({min_:function(t,e=null,n=!1){const s={x:Os(t,"x","min")},r={axis:e,keepDims:n};return $s.runKernel(Fe,s,r)}}),gi=Rs({minimum_:function(t,e){let n=Os(t,"a","minimum"),s=Os(e,"b","minimum");[n,s]=Is(n,s),"bool"===n.dtype&&(n=Ir(n,"int32"),s=Ir(s,"int32")),qa(n.shape,s.shape);const r={a:n,b:s};return $s.runKernel(_e,r)}});function yi(t,e){for(let n=0;n<t.length;++n)if(t[t.length-n-1]!==e-1-n)return!1;return!0}function bi(t,e){const n=[],s=t.length;for(let r=0;r<s;r++)-1===e.indexOf(r)&&n.push(t[r]);return[n,e.map((e=>t[e]))]}function ki(t,e){return function(t,e,n){const s=t.length+e.length,r=[];let a=0,i=0;for(let o=0;o<s;o++)-1===n.indexOf(o)?r.push(t[a++]):r.push(e[i++]);return r}(t,e.map((t=>1)),e)}function wi(t,e,n){v(yi(e,n),(()=>`${t} supports only inner-most axes for now. Got axes ${e} and rank-${n} input.`))}function xi(t,e){if(yi(t,e))return null;const n=[];for(let s=0;s<e;++s)-1===t.indexOf(s)&&n.push(s);return t.forEach((t=>n.push(t))),n}function Ni(t){return t.map(((t,e)=>[e,t])).sort(((t,e)=>t[1]-e[1])).map((t=>t[0]))}function vi(t,e){const n=[];for(let s=e-t;s<e;++s)n.push(s);return n}const Ii=Rs({square_:function(t){const e=Os(t,"x","square");return $s.runKernel("Square",{x:e},{})}}),Si=Rs({moments_:function(t,e=null,n=!1){const s=M(e,(t=Os(t,"x","moments")).shape),r=fi(t,s,n);let a=r.shape;n||(a=ki(r.shape,s));const i=Ii(oi(Ir(t,"float32"),Na(r,a)));return{mean:r,variance:fi(i,s,n)}}}),Ti=Rs({neg_:function(t){const e={x:Os(t,"x","neg")};return $s.runKernel(Re,e)}}),Ei=Rs({notEqual_:function(t,e){let n=Os(t,"a","notEqual"),s=Os(e,"b","notEqual");[n,s]=Is(n,s),qa(n.shape,s.shape);const r={a:n,b:s};return $s.runKernel(Be,r)}}),Ai=Rs({oneHot_:function(t,e,n=1,s=0){if(e<2)throw new Error(`Error in oneHot: depth must be >=2, but it is ${e}`);const r={indices:Os(t,"indices","oneHot","int32")},a={depth:e,onValue:n,offValue:s};return $s.runKernel(He,r,a)}});function Di(t,e="float32"){if("complex64"===e){const e=Di(t,"float32"),n=Di(t,"float32");return Bs(e,n)}const n=U(E(t),e);return $s.makeTensor(n,t,e)}function $i(t,e="float32"){if("complex64"===e){const e=$i(t,"float32"),n=Di(t,"float32");return Bs(e,n)}const n=V(E(t),e);return $s.makeTensor(n,t,e)}const Mi=Rs({onesLike_:function(t){const e={x:Os(t,"x","onesLike")};return $s.runKernel(Ue,e)}}),Fi=Rs({pad_:function(t,e,n=0){const s=Os(t,"x","pad");if(0===s.rank)throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");const r={paddings:e,constantValue:n},a={x:s};return $s.runKernel(qe,a,r)}}),_i=Rs({prelu_:function(t,e){const n={x:Os(t,"x","prelu"),alpha:Os(e,"alpha","prelu")};return $s.runKernel(Ke,n)}});var zi=n(377);class Ci{constructor(t,e,n,s,r){this.mean=t,this.stdDev=e,this.dtype=n,this.nextVal=NaN,this.truncated=s,this.truncated&&(this.upper=this.mean+2*this.stdDev,this.lower=this.mean-2*this.stdDev);const a=r||Math.random();this.random=zi.alea(a.toString())}nextValue(){if(!isNaN(this.nextVal)){const t=this.nextVal;return this.nextVal=NaN,t}let t,e,n=!1;for(;!n;){let s,r,a;do{s=2*this.random()-1,r=2*this.random()-1,a=s*s+r*r}while(a>=1||0===a);const i=Math.sqrt(-2*Math.log(a)/a);t=this.mean+this.stdDev*s*i,e=this.mean+this.stdDev*r*i,this.truncated&&!this.isValidTruncated(t)||(n=!0)}return this.truncated&&!this.isValidTruncated(e)||(this.nextVal=this.convertValue(e)),this.convertValue(t)}convertValue(t){return null==this.dtype||"float32"===this.dtype?t:Math.round(t)}isValidTruncated(t){return t<=this.upper&&t>=this.lower}}class Oi{constructor(t=0,e=1,n,s){if(this.canReturnFloat=()=>null==this.dtype||"float32"===this.dtype,this.min=t,this.range=e-t,this.dtype=n,null==s&&(s=Math.random()),"number"==typeof s&&(s=s.toString()),!this.canReturnFloat()&&this.range<=1)throw new Error(`The difference between ${t} - ${e} <= 1 and dtype is not float`);this.random=zi.alea(s)}convertValue(t){return this.canReturnFloat()?t:Math.round(t)}nextValue(){return this.convertValue(this.min+this.range*this.random())}}const Li=Rs({randomNormal_:function(t,e=0,n=1,s,r){if(null!=s&&"bool"===s)throw new Error(`Unsupported data type ${s}`);const a=new Ci(e,n,s,!1,r),i=vr(t,s);for(let t=0;t<i.values.length;t++)i.values[t]=a.nextValue();return i.toTensor()}}),Ri=Rs({randomUniform_:function(t,e=0,n=1,s="float32",r){const a=vr(t,s),i=new Oi(e,n,null,r);for(let t=0;t<a.values.length;t++)a.values[t]=i.nextValue();return a.toTensor()}}),Bi=Rs({relu_:function(t){const e={x:Os(t,"x","relu")};return $s.runKernel(Qe,e)}}),Wi=Rs({reverse_:function(t,e){const n={x:Os(t,"x","reverse")},s={dims:e};return $s.runKernel(on,n,s)}}),Pi=Rs({selu_:function(t){const e={x:Os(t,"x","selu")};return $s.runKernel(pn,e)}}),Vi=Rs({separableConv2d_:function(t,e,n,s,r,a=[1,1],i="NHWC"){const o=Os(t,"x","separableConv2d"),l=Os(e,"depthwiseFilter","separableConv2d"),u=Os(n,"pointwiseFilter","separableConv2d");let h=o,c=!1;if(3===o.rank&&(c=!0,h=Na(o,[1,o.shape[0],o.shape[1],o.shape[2]])),"NCHW"===i)throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");v(4===h.rank,(()=>`Error in separableConv2d: input must be rank 4, but got rank ${h.rank}.`)),v(4===l.rank,(()=>`Error in separableConv2d: depthwise filter must be rank 4, but got rank ${l.rank}.`)),v(4===u.rank,(()=>`Error in separableConv2d: pointwise filter must be rank 4, but got rank ${l.rank}.`)),v(1===u.shape[0],(()=>`Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${u.shape[0]}.`)),v(1===u.shape[1],(()=>`Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${u.shape[1]}.`));const p=l.shape[2],d=l.shape[3];v(u.shape[2]===p*d,(()=>`Error in separableConv2d: the third dimension of pointwise filter must be ${p*d}, but got ${u.shape[2]}.`));const f=Wa(h,l,s,r,i,a),m=Ca(f,u,1,"valid",i);return c?Na(m,[m.shape[1],m.shape[2],m.shape[3]]):m}}),Ui=Rs({sigmoid_:function(t){const e={x:Os(t,"x","sigmoid")};return $s.runKernel(yn,e)}}),Hi=Rs({slice_:function(t,e,n){const s=Os(t,"x","slice","string_or_numeric");if(0===s.rank)throw new Error("Slicing scalar is not possible");const r={x:s},a={begin:e,size:n};return $s.runKernel(dn,r,a)}}),ji=Rs({slice1d_:function(t,e,n){const s=Os(t,"x","slice1d");return v(1===s.rank,(()=>`slice1d expects a rank-1 tensor, but got a rank-${s.rank} tensor`)),Hi(s,[e],[n])}}),qi=Rs({slice2d_:function(t,e,n){const s=Os(t,"x","slice2d");return v(2===s.rank,(()=>`slice2d expects a rank-2 tensor, but got a rank-${s.rank} tensor`)),Hi(s,e,n)}}),Gi=Rs({slice3d_:function(t,e,n){const s=Os(t,"x","slice3d");return v(3===s.rank,(()=>`slice3d expects a rank-3 tensor, but got a rank-${s.rank} tensor`)),Hi(s,e,n)}}),Ki=Rs({slice4d_:function(t,e,n){const s=Os(t,"x","slice4d");return v(4===s.rank,(()=>`slice4d expects a rank-4 tensor, but got a rank-${s.rank} tensor`)),Hi(s,e,n)}}),Ji=Rs({softmax_:function(t,e=-1){const n=Os(t,"logits","softmax","float32");if(-1===e&&(e=n.rank-1),e!==n.rank-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and dim was ${e}`);const s={logits:n},r={dim:e};return $s.runKernel(vn,s,r)}}),Zi=Rs({softplus_:function(t){const e={x:Os(t,"x","softplus")};return $s.runKernel(bn,e)}}),Yi=Rs({split_:function(t,e,n=0){const s={x:Os(t,"x","split")},r={numOrSizeSplits:e,axis:n};return $s.runKernel(Nn,s,r)}}),Xi=Rs({sqrt_:function(t){const e={x:Os(t,"x","sqrt")};return $s.runKernel(kn,e)}}),Qi=Rs({squeeze_:function(t,e){const n=Os(t,"x","squeeze");return Na(n,function(t,e){const n=[],s=[],r=null!=e&&Array.isArray(e)&&0===e.length,a=null==e||r?null:M(e,t).sort();let i=0;for(let e=0;e<t.length;++e){if(null!=a){if(a[i]===e&&1!==t[e])throw new Error(`Can't squeeze axis ${e} since its dim '${t[e]}' is not 1`);(null==a[i]||a[i]>e)&&1===t[e]&&(n.push(t[e]),s.push(e)),a[i]<=e&&i++}1!==t[e]&&(n.push(t[e]),s.push(e))}return{newShape:n,keptDims:s}}(n.shape,e).newShape)}}),to=Rs({stack_:function(t,e=0){const n=Ls(t,"tensors","stack","string_or_numeric");v(n.length>=1,(()=>"Pass at least one tensor to tf.stack")),n.length>0&&v(e<=n[0].rank,(()=>"Axis must be <= rank of the tensor"));const s=n,r={axis:e};return $s.runKernel(je,s,r)}}),eo=Rs({tanh_:function(t){const e={x:Os(t,"x","tanh")};return $s.runKernel($n,e)}});function no(t,e){S(t);const n=_s(t,e);if(1!==n.length)throw new Error("tensor1d() requires values to be a flat/TypedArray");return Ws(t,null,n,e)}function so(t,e,n){if(S(t),null!=e&&2!==e.length)throw new Error("tensor2d() requires shape to have two numbers");const s=_s(t,n);if(2!==s.length&&1!==s.length)throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");if(1===s.length&&null==e)throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");return Ws(t,e,s,n)}const ro=Rs({truncatedNormal_:function(t,e=0,n=1,s,r){if(null!=s&&"bool"===s)throw new Error("Unsupported data type $ { dtype }");const a=new Ci(e,n,s,!0,r),i=vr(t,s);for(let t=0;t<i.values.length;t++)i.values[t]=a.nextValue();return i.toTensor()}}),ao=Rs({unstack_:function(t,e=0){const n=Os(t,"x","unstack","string_or_numeric");v(e>=-n.shape.length&&e<n.shape.length,(()=>`Axis = ${e} is not in [-${n.shape.length}, ${n.shape.length})`));const s={value:n},r={axis:e};return $s.runKernel(Cn,s,r)}}),io=Rs({broadcastTo_:function(t,e){let n=Os(t,"broadcastTo","x");const s=n.shape;if(e.some((t=>!(t>0)||t%1!=0)))throw new Error(`broadcastTo(): Invalid broadcast shape [${e}].`);if(e.length<n.rank)throw new Error(`broadcastTo(): shape.length=${e.length} < input.rank=${n.rank}.`);if(e.length>n.rank){const t=n.shape.slice();for(;t.length<e.length;)t.unshift(1);n=Na(n,t)}const r=n.shape,a=Array.from(e);for(let t=e.length-1;t>=0;t--)if(r[t]===e[t])a[t]=1;else if(1!==n.shape[t])throw new Error(`broadcastTo(): [${s}] cannot be broadcast to [${e}].`);if(0===a.map(((t,e)=>t>1?e:-1)).filter((t=>t>=0)).length)return Sr(n);const i={x:n},o={reps:a};return $s.runKernel(Mn,i,o)}}),oo=Rs({where_:function(t,e,n){const s=Os(e,"a","where"),r=Os(n,"b","where"),a=Os(t,"condition","where","bool"),i=qa(s.shape,r.shape),o=io(s,i),l=io(r,i);1===a.rank&&v(a.shape[0]===s.shape[0],(()=>"The first dimension of `a` must match the size of `condition`.")),1!==a.rank&&I(a.shape,l.shape,"Error in where: ");const u={condition:a,t:o,e:l};return $s.runKernel(cn,u)}}),lo=Rs({zerosLike_:function(t){const e={x:Os(t,"x","zerosLike")};return $s.runKernel(Ln,e)}}),uo=Rs({transpose_:function(t,e){const n=Os(t,"x","transpose");if(null==e&&(e=n.shape.map(((t,e)=>e)).reverse()),v(n.rank===e.length,(()=>`Error in transpose: rank of input ${n.rank} must match length of perm ${e}.`)),e.forEach((t=>{v(t>=0&&t<n.rank,(()=>"All entries in 'perm' must be between 0 and "+(n.rank-1)+` but got ${e}`))})),n.rank<=1)return n.clone();const s={x:n},r={perm:e};return $s.runKernel(_n,s,r)}}),ho=Rs({dropout_:function(t,e,n,s){const r=Os(t,"x","dropout");if(v("float32"===r.dtype,(()=>`x has to be a floating point tensor since it's going to be scaled, but got a ${r.dtype} tensor instead.`)),v(e>=0&&e<1,(()=>`rate must be a float in the range [0, 1), but got ${e}.`)),0===e)return t instanceof ms?r.clone():r;const a=function(t,e){if(null==e)return t.shape.slice();if(A(t.shape,e))return e;if(t.shape.length===e.length){const n=[];for(let s=0;s<t.shape.length;s++)null==e[s]&&null!=t.shape[s]?n.push(t.shape[s]):n.push(e[s]);return n}return e}(r,n),i=1-e,o=Va(Xa(aa(Ri(a,0,1,"float32",s),i)),i);return ii(r,o)}}),co=Rs({imag_:function(t){const e={input:Os(t,"input","imag")};return $s.runKernel(ue,e)}}),po=Rs({real_:function(t){const e={input:Os(t,"input","real")};return $s.runKernel(Ye,e)}}),fo=Rs({fft_:function(t){v("complex64"===t.dtype,(()=>`The dtype for tf.spectral.fft() must be complex64 but got ${t.dtype}.`));const e={input:t};return $s.runKernel("FFT",e)}}),mo=Rs({rfft_:function(t,e){v("float32"===t.dtype,(()=>`The dtype for rfft() must be real value but got ${t.dtype}`));let n=t.shape[t.shape.length-1];const s=t.size/n;let r;if(null!=e&&e<n){const s=t.shape.map((t=>0)),a=t.shape.map((t=>t));a[t.shape.length-1]=e,r=Hi(t,s,a),n=e}else if(null!=e&&e>n){const s=t.shape.map((t=>t));s[t.shape.length-1]=e-n,r=$a([t,Di(s)],t.shape.length-1),n=e}else r=t;const a=lo(r),i=Na(Bs(r,a),[s,n]),o=fo(i),l=Math.floor(n/2)+1,u=po(o),h=co(o),c=Yi(u,[l,n-l],u.shape.length-1),p=Yi(h,[l,n-l],h.shape.length-1),d=r.shape.slice();return d[r.shape.length-1]=l,Na(Bs(c[0],p[0]),d)}}),go=Rs({ifft_:function(t){v("complex64"===t.dtype,(()=>`The dtype for tf.spectral.ifft() must be complex64 but got ${t.dtype}.`));const e={input:t};return $s.runKernel(le,e)}}),yo=Rs({irfft_:function(t){const e=t.shape[t.shape.length-1],n=t.size/e;let s;if(e<=2){const r=Na(t,[n,e]);s=go(r)}else{const r=[n,2*(e-1)],a=Na(po(t),[n,e]),i=Na(co(t),[n,e]),o=Wi(Hi(a,[0,1],[n,e-2]),1),l=ii(Wi(Hi(i,[0,1],[n,e-2]),1),na(-1)),u=$a([a,o],1),h=$a([i,l],1),c=Na(Bs(u,h),[r[0],r[1]]);s=go(c)}if(s=po(s),3===t.rank&&0!==t.shape[0]){const e=s,n=t.shape[0];s=Na(s,[n,s.shape[0]/n,s.shape[1]]),e.dispose()}return s}}),bo=Rs({conv2DBackpropFilter_:function(t,e,n,s,r,a="NHWC",i){let o=t;3===t.rank&&(o=Na(t,[1,t.shape[0],t.shape[1],t.shape[2]]));let l=e;3===l.rank&&(l=Na(e,[1,e.shape[0],e.shape[1],e.shape[2]])),v(4===o.rank,(()=>`Error in conv2dDerFilter: input must be rank 4, but got shape ${o.shape}.`)),v(4===l.rank,(()=>`Error in conv2dDerFilter: dy must be rank 4, but got shape ${l.shape}.`)),v(4===n.length,(()=>`Error in conv2dDerFilter: filterShape must be length 4, but got ${n}.`));const u="NHWC"===a?o.shape[3]:o.shape[1],h="NHWC"===a?l.shape[3]:l.shape[1];v(u===n[2],(()=>`Error in conv2dDerFilter: depth of input ${u}) must match input depth in filter (${n[2]}.`)),v(h===n[3],(()=>`Error in conv2dDerFilter: depth of dy (${h}) must match output depth for filter (${n[3]}).`)),null!=i&&v(D(r),(()=>`Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode ${i} but got pad ${r}.`));const c={x:o,dy:l},p={strides:s,pad:r,dataFormat:a,dimRoundingMode:i,filterShape:n};return $s.runKernel(Et,c,p)}}),ko=Rs({relu6_:function(t){const e={x:Os(t,"x","relu6")};return $s.runKernel(an,e)}}),wo=Rs({step_:function(t,e=0){const n={x:Os(t,"x","step")},s={alpha:e};return $s.runKernel(Rn,n,s)}});function xo(t,e,n){if(null==n||"linear"===n)return t;if("relu"===n)return ii(t,wo(e));throw new Error(`Cannot compute gradient for fused activation ${n}.`)}function No(t,e){let n=e;const s=ja(t.shape,e.shape);return s.length>0&&(n=li(n,s)),Na(n,t.shape)}function vo(t,e,n,s){if("linear"===e)return t;if("relu"===e)return Bi(t);if("elu"===e)return Ua(t);if("relu6"===e)return ko(t);if("prelu"===e)return _i(t,n);if("leakyrelu"===e)return ni(t,s);throw new Error(`Unknown fused activation ${e}.`)}const Io=(t,e)=>!(t>0)||"linear"===e,So=Rs({fusedConv2d_:function({x:t,filter:e,strides:n,pad:s,dataFormat:r="NHWC",dilations:a=[1,1],dimRoundingMode:i,bias:o,activation:l="linear",preluActivationWeights:u,leakyreluAlpha:h}){if(l=l||"linear",!1===Io($s.state.gradientDepth,l)){let c=Ca(t,e,n,s,r,a,i);return null!=o&&(c=aa(c,o)),vo(c,l,u,h)}const c=Os(t,"x","conv2d"),p=Os(e,"filter","conv2d");let d=c,f=!1;3===c.rank&&(f=!0,d=Na(c,[1,c.shape[0],c.shape[1],c.shape[2]])),v(4===d.rank,(()=>`Error in fused conv2d: input must be rank 4, but got rank ${d.rank}.`)),v(4===p.rank,(()=>`Error in fused conv2d: filter must be rank 4, but got rank ${p.rank}.`)),null!=i&&v(D(s),(()=>`Error in fused conv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${s}.`)),v(d.shape[3]===p.shape[2],(()=>`Error in conv2d: depth of input (${d.shape[3]}) must match input depth for filter ${p.shape[2]}.`)),v(wa(n,a),(()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`)),v("NHWC"===r,(()=>`Error in conv2d: got dataFormat of ${r} but only NHWC is currently supported.`));const m=pa(d.shape,p.shape,n,a,s,i);let g,y;null!=o&&(g=Os(o,"bias","fused conv2d"),[g]=Is(g,c),qa(m.outShape,g.shape)),null!=u&&(y=Os(u,"prelu weights","fused conv2d"));const b=(t,e)=>{const[r,i,o,u]=e,h=xo(t,o,l);v(ka(a),(()=>`Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${a}'`));const c=[La(i.shape,h,r,n,s),bo(i,h,r.shape,n,s)];if(null!=u){const t=No(u,h);c.push(t)}return c},k={x:d,filter:p,bias:g,preluActivationWeights:y},w={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i,activation:l,leakyreluAlpha:h};return null==o?ea(((t,e,n)=>{let s=$s.runKernel(Vn,k,w);return n([e,t,s]),f&&(s=Na(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:b}}))(d,p):ea(((t,e,n,s)=>{let r=$s.runKernel(Vn,k,w);return s([e,t,r,n]),f&&(r=Na(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:b}}))(d,p,g)}}),To=Rs({depthwiseConv2dNativeBackpropFilter_:function(t,e,n,s,r,a=[1,1],i){let o=t;3===t.rank&&(o=Na(t,[1,t.shape[0],t.shape[1],t.shape[2]]));let l=e;3===l.rank&&(l=Na(e,[1,e.shape[0],e.shape[1],e.shape[2]]));const u={x:o,dy:l},h={strides:s,pad:r,dimRoundingMode:i,dilations:a,filterShape:n};return $s.runKernel(Bt,u,h)}}),Eo=Rs({depthwiseConv2dNativeBackpropInput_:function(t,e,n,s,r,a=[1,1],i){let o=e,l=!1;3===e.rank&&(l=!0,o=Na(e,[1,e.shape[0],e.shape[1],e.shape[2]]));const u={dy:o,filter:n},h={strides:s,pad:r,dimRoundingMode:i,dilations:a,inputShape:t},c=$s.runKernel(Wt,u,h);return l?Na(c,[c.shape[1],c.shape[2],c.shape[3]]):c}}),Ao=Rs({fusedDepthwiseConv2d_:function({x:t,filter:e,strides:n,pad:s,dataFormat:r="NHWC",dilations:a=[1,1],dimRoundingMode:i,bias:o,activation:l="linear",preluActivationWeights:u,leakyreluAlpha:h}){if(!1===Io($s.state.gradientDepth,l)){let c=Wa(t,e,n,s,r,a,i);return null!=o&&(c=aa(c,o)),vo(c,l,u,h)}const c=Os(t,"x","depthwiseConv2d"),p=Os(e,"filter","depthwiseConv2d");let d=c,f=!1;3===c.rank&&(f=!0,d=Na(c,[1,c.shape[0],c.shape[1],c.shape[2]])),v(4===d.rank,(()=>`Error in fused depthwiseConv2d: input must be rank 4, but got rank ${d.rank}.`)),v(4===p.rank,(()=>`Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${p.rank}.`)),v(d.shape[3]===p.shape[2],(()=>`Error in fused depthwiseConv2d: number of input channels (${d.shape[3]}) must match the inChannels dimension in filter ${p.shape[2]}.`)),null==a&&(a=[1,1]),v(wa(n,a),(()=>`Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${n} and dilations '${a}'`)),null!=i&&v(D(s),(()=>`Error in fused depthwiseConv2d: pad must be an integer when using dimRoundingMode ${i} but got pad ${s}.`));const m=pa(d.shape,p.shape,n,a,s,i,!0);let g,y;null!=o&&(g=Os(o,"bias","fused conv2d"),[g]=Is(g,c),qa(m.outShape,g.shape)),null!=u&&(y=Os(u,"prelu weights","fused depthwiseConv2d"));const b=(t,e)=>{v(ka(a),(()=>`Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${a}'`));const[r,o,u,h]=e,c=xo(t,u,l),p=Eo(o.shape,c,r,n,s,a,i),d=To(o,c,r.shape,n,s,a,i);return null!=h?[p,d,No(g,c)]:[p,d]},k={x:d,filter:p,bias:g,preluActivationWeights:y},w={strides:n,pad:s,dataFormat:r,dilations:a,dimRoundingMode:i,activation:l,leakyreluAlpha:h};return null==o?ea(((t,e,n)=>{let s=$s.runKernel(Un,k,w);return n([e,t,s]),f&&(s=Na(s,[s.shape[1],s.shape[2],s.shape[3]])),{value:s,gradFunc:b}}))(d,p):ea(((t,e,n,s)=>{let r=$s.runKernel(Un,k,w);return s([e,t,r,n]),f&&(r=Na(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:b}}))(d,p,g)}}),Do=Rs({matMul_:function(t,e,n=!1,s=!1){let r=Os(t,"a","matMul"),a=Os(e,"b","matMul");[r,a]=Is(r,a);const i={a:r,b:a},o={transposeA:n,transposeB:s};return $s.runKernel(yt,i,o)}}),$o=Rs({fusedMatMul_:function({a:t,b:e,transposeA:n=!1,transposeB:s=!1,bias:r,activation:a="linear",preluActivationWeights:i,leakyreluAlpha:o}){if(!1===Io($s.state.gradientDepth,a)){let l=Do(t,e,n,s);return null!=r&&(l=aa(l,r)),vo(l,a,i,o)}let l=Os(t,"a","fused matMul"),u=Os(e,"b","fused matMul");[l,u]=Is(l,u);const h=n?l.shape[l.rank-2]:l.shape[l.rank-1],c=s?u.shape[u.rank-1]:u.shape[u.rank-2],p=n?l.shape[l.rank-1]:l.shape[l.rank-2],d=s?u.shape[u.rank-2]:u.shape[u.rank-1],f=l.shape.slice(0,-2),m=u.shape.slice(0,-2),g=E(f),y=E(m);v(l.rank>=2&&u.rank>=2&&l.rank===u.rank,(()=>`Error in fused matMul: inputs must have the same rank of at least 2, got ranks ${l.rank} and ${u.rank}.`)),v(A(f,m),(()=>`Error in fused matMul: outer dimensions (${f}) and (${m}) of Tensors with shapes ${l.shape} and ${u.shape} must match.`)),v(h===c,(()=>`Error in fused matMul: inner shapes (${h}) and (${c}) of Tensors with shapes ${l.shape} and ${u.shape} and transposeA=${n} and transposeB=${s} must match.`));const b=l.shape.slice(0,-2).concat([p,d]),k=Na(l,n?[g,h,p]:[g,p,h]),w=Na(u,s?[y,d,c]:[y,c,d]);let x,N;null!=r&&(x=Os(r,"bias","fused matMul"),[x]=Is(x,l),qa(b,x.shape)),null!=i&&(N=Os(i,"prelu weights","fused matMul"));const I=(t,e)=>{const[i,o,l,u]=e,h=xo(Na(t,l.shape),l,a);let c,p;return n||s?!n&&s?(c=Do(h,o,!1,!1),p=Do(h,i,!0,!1)):n&&!s?(c=Do(o,h,!1,!0),p=Do(i,h,!1,!1)):(c=Do(o,h,!0,!0),p=Do(h,i,!0,!0)):(c=Do(h,o,!1,!0),p=Do(i,h,!0,!1)),null!=r?[c,p,No(u,h)]:[c,p]},S={a:k,b:w,bias:x,preluActivationWeights:N},T={transposeA:n,transposeB:s,activation:a,leakyreluAlpha:o};return null==r?ea(((t,e,n)=>{const s=$s.runKernel(Pn,S,T);return n([t,e,s]),{value:Na(s,b),gradFunc:I}}))(k,w):ea(((t,e,n,s)=>{const r=$s.runKernel(Pn,S,T);return s([t,e,r,n]),{value:Na(r,b),gradFunc:I}}))(k,w,x)}});function Mo(t,e,n){const s=1-t%2,r=new Float32Array(t);for(let a=0;a<t;++a){const i=2*Math.PI*a/(t+s-1);r[a]=e-n*Math.cos(i)}return no(r,"float32")}Rs({hammingWindow_:function(t){return Mo(t,.54,.46)}});const Fo=Rs({hannWindow_:function(t){return Mo(t,.5,.5)}}),_o=Rs({frame_:function(t,e,n,s=!1,r=0){let a=0;const i=[];for(;a+e<=t.size;)i.push(Hi(t,a,e)),a+=n;if(s)for(;a<t.size;){const s=a+e-t.size,o=$a([Hi(t,a,e-s),Ya([s],r)]);i.push(o),a+=n}return 0===i.length?so([],[0,e]):Na($a(i),[i.length,e])}});Rs({stft_:function(t,e,n,s,r=Fo){var a;null==s&&(a=e,s=Math.floor(Math.pow(2,Math.ceil(Math.log(a)/Math.log(2)))));const i=_o(t,e,n),o=ii(i,r(e)),l=[];for(let t=0;t<i.shape[0];t++)l.push(mo(Hi(o,[t,0],[1,e]),s));return $a(l)}});const zo=Rs({cropAndResize_:function(t,e,n,s,r="bilinear",a=0){const i=Os(t,"image","cropAndResize"),o=Os(e,"boxes","cropAndResize","float32"),l=Os(n,"boxInd","cropAndResize","int32"),u=o.shape[0];v(4===i.rank,(()=>`Error in cropAndResize: image must be rank 4,but got rank ${i.rank}.`)),v(2===o.rank&&4===o.shape[1],(()=>`Error in cropAndResize: boxes must be have size [${u},4] but had shape ${o.shape}.`)),v(1===l.rank&&l.shape[0]===u,(()=>`Error in cropAndResize: boxInd must be have size [${u}] but had shape ${o.shape}.`)),v(2===s.length,(()=>`Error in cropAndResize: cropSize must be of length 2, but got length ${s.length}.`)),v(s[0]>=1&&s[1]>=1,(()=>`cropSize must be atleast [1,1], but was ${s}`)),v("bilinear"===r||"nearest"===r,(()=>`method must be bilinear or nearest, but was ${r}`));const h={image:i,boxes:o,boxInd:l},c={method:r,extrapolationValue:a,cropSize:s};return $s.runKernel(Ct,h,c)}}),Co=Rs({flipLeftRight_:function(t){const e=Os(t,"image","flipLeftRight","float32");v(4===e.rank,(()=>`Error in flipLeftRight: image must be rank 4,but got rank ${e.rank}.`));const n={image:e};return $s.runKernel(Qt,n,{})}}),Oo=Rs({rotateWithOffset_:function(t,e,n=0,s=.5){const r=Os(t,"image","rotateWithOffset","float32");v(4===r.rank,(()=>`Error in rotateWithOffset: image must be rank 4,but got rank ${r.rank}.`));const a={image:r},i={radians:e,fillValue:n,center:s};return $s.runKernel(Wn,a,i)}});function Lo(t,e,n,s,r,a){null==s&&(s=.5),null==r&&(r=Number.NEGATIVE_INFINITY),null==a&&(a=0);const i=t.shape[0];return n=Math.min(n,i),v(0<=s&&s<=1,(()=>`iouThreshold must be in [0, 1], but was '${s}'`)),v(2===t.rank,(()=>`boxes must be a 2D tensor, but was of rank '${t.rank}'`)),v(4===t.shape[1],(()=>`boxes must have 4 columns, but 2nd dimension was ${t.shape[1]}`)),v(1===e.rank,(()=>"scores must be a 1D tensor")),v(e.shape[0]===i,(()=>`scores has incompatible shape with boxes. Expected ${i}, but was ${e.shape[0]}`)),v(0<=a&&a<=1,(()=>`softNmsSigma must be in [0, 1], but was '${a}'`)),{maxOutputSize:n,iouThreshold:s,scoreThreshold:r,softNmsSigma:a}}const Ro=Rs({nonMaxSuppression_:function(t,e,n,s=.5,r=Number.NEGATIVE_INFINITY){const a=Os(t,"boxes","nonMaxSuppression"),i=Os(e,"scores","nonMaxSuppression"),o=Lo(a,i,n,s,r),l={maxOutputSize:n=o.maxOutputSize,iouThreshold:s=o.iouThreshold,scoreThreshold:r=o.scoreThreshold};return $s.runKernel(We,{boxes:a,scores:i},l)}});function Bo(t,e,n){const s=function(t,e,n){return function(t,e,n){let s=0,r=t.length,a=0,i=!1;for(;s<r;){a=s+(r-s>>>1);const o=n(e,t[a]);o>0?s=a+1:(r=a,i=!o)}return i?s:-s-1}(t,e,n||Wo)}(t,e,n),r=s<0?-(s+1):s;t.splice(r,0,e)}function Wo(t,e){return t>e?1:t<e?-1:0}function Po(t,e,n,s,r){return Ho(t,e,n,s,r,0)}function Vo(t,e,n,s,r,a){return Ho(t,e,n,s,r,0,!1,a,!0)}function Uo(t,e,n,s,r,a){return Ho(t,e,n,s,r,a,!0)}function Ho(t,e,n,s,r,a,i=!1,o=!1,l=!1){const u=[];for(let t=0;t<e.length;t++)e[t]>r&&u.push({score:e[t],boxIndex:t,suppressBeginIndex:0});u.sort(Go);const h=a>0?-.5/a:0,c=[],p=[];for(;c.length<n&&u.length>0;){const e=u.pop(),{score:n,boxIndex:a,suppressBeginIndex:i}=e;if(n<r)break;let o=!1;for(let n=c.length-1;n>=i;--n){const i=jo(t,a,c[n]);if(i>=s){o=!0;break}if(e.score=e.score*qo(s,h,i),e.score<=r)break}e.suppressBeginIndex=c.length,o||(e.score===n?(c.push(a),p.push(e.score)):e.score>r&&Bo(u,e,Go))}const d=c.length,f=n-d;o&&f>0&&(c.push(...new Array(f).fill(0)),p.push(...new Array(f).fill(0)));const m={selectedIndices:c};return i&&(m.selectedScores=p),l&&(m.validOutputs=d),m}function jo(t,e,n){const s=t.subarray(4*e,4*e+4),r=t.subarray(4*n,4*n+4),a=Math.min(s[0],s[2]),i=Math.min(s[1],s[3]),o=Math.max(s[0],s[2]),l=Math.max(s[1],s[3]),u=Math.min(r[0],r[2]),h=Math.min(r[1],r[3]),c=Math.max(r[0],r[2]),p=Math.max(r[1],r[3]),d=(o-a)*(l-i),f=(c-u)*(p-h);if(d<=0||f<=0)return 0;const m=Math.max(a,u),g=Math.max(i,h),y=Math.min(o,c),b=Math.min(l,p),k=Math.max(y-m,0)*Math.max(b-g,0);return k/(d+f-k)}function qo(t,e,n){const s=Math.exp(e*n*n);return n<=t?s:0}function Go(t,e){return t.score-e.score||t.score===e.score&&e.boxIndex-t.boxIndex}const Ko=Rs({nonMaxSuppressionWithScore_:function(t,e,n,s=.5,r=Number.NEGATIVE_INFINITY,a=0){const i=Os(t,"boxes","nonMaxSuppression"),o=Os(e,"scores","nonMaxSuppression"),l=Lo(i,o,n,s,r,a),u={boxes:i,scores:o},h={maxOutputSize:n=l.maxOutputSize,iouThreshold:s=l.iouThreshold,scoreThreshold:r=l.scoreThreshold,softNmsSigma:a=l.softNmsSigma},c=$s.runKernel(Ve,u,h);return{selectedIndices:c[0],selectedScores:c[1]}}}),Jo=Rs({nonMaxSuppressionPadded_:function(t,e,n,s=.5,r=Number.NEGATIVE_INFINITY,a=!1){const i=Os(t,"boxes","nonMaxSuppression"),o=Os(e,"scores","nonMaxSuppression"),l=Lo(i,o,n,s,r,null),u={boxes:i,scores:o},h={maxOutputSize:l.maxOutputSize,iouThreshold:l.iouThreshold,scoreThreshold:l.scoreThreshold,padToMaxOutputSize:a},c=$s.runKernel(Pe,u,h);return{selectedIndices:c[0],validOutputs:c[1]}}}),Zo=Rs({resizeBilinear_:function(t,e,n=!1,s=!1){const r=Os(t,"images","resizeBilinear");v(3===r.rank||4===r.rank,(()=>`Error in resizeBilinear: x must be rank 3 or 4, but got rank ${r.rank}.`)),v(2===e.length,(()=>`Error in resizeBilinear: new shape must 2D, but got shape ${e}.`)),v(!1===s||!1===n,(()=>"Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false."));let a=r,i=!1;3===r.rank&&(i=!0,a=Na(r,[1,r.shape[0],r.shape[1],r.shape[2]]));const[]=e,o={images:a},l={alignCorners:n,halfPixelCenters:s,size:e},u=$s.runKernel(sn,o,l);return i?Na(u,[u.shape[1],u.shape[2],u.shape[3]]):u}}),Yo=Rs({resizeNearestNeighbor_:function(t,e,n=!1,s=!1){const r=Os(t,"images","resizeNearestNeighbor");v(3===r.rank||4===r.rank,(()=>`Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${r.rank}.`)),v(2===e.length,(()=>`Error in resizeNearestNeighbor: new shape must 2D, but got shape ${e}.`)),v("float32"===r.dtype||"int32"===r.dtype,(()=>"`images` must have `int32` or `float32` as dtype")),v(!1===s||!1===n,(()=>"Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false."));let a=r,i=!1;3===r.rank&&(i=!0,a=Na(r,[1,r.shape[0],r.shape[1],r.shape[2]]));const[]=e,o={images:a},l={alignCorners:n,halfPixelCenters:s,size:e},u=$s.runKernel(en,o,l);return i?Na(u,[u.shape[1],u.shape[2],u.shape[3]]):u}}),Xo=Rs({lessEqual_:function(t,e){let n=Os(t,"a","lessEqual"),s=Os(e,"b","lessEqual");[n,s]=Is(n,s),qa(n.shape,s.shape);const r={a:n,b:s};return $s.runKernel(me,r)}});function Qo(t,e,n=1,s="float32"){if(0===n)throw new Error("Cannot have a step of zero");const r={start:t,stop:e,step:n,dtype:s};return $s.runKernel(Ze,{},r)}const tl=Rs({bandPart_:function(t,e,n){v(e%1==0,(()=>`bandPart(): numLower must be an integer, got ${e}.`)),v(n%1==0,(()=>`bandPart(): numUpper must be an integer, got ${n}.`));const s=Os(t,"a","bandPart");v(s.rank>=2,(()=>`bandPart(): Rank must be at least 2, got ${s.rank}.`));const r=s.shape,[a,i]=s.shape.slice(-2);if(!(e<=a))throw new Error(`bandPart(): numLower (${e}) must not be greater than the number of rows (${a}).`);if(!(n<=i))throw new Error(`bandPart(): numUpper (${n}) must not be greater than the number of columns (${i}).`);e<0&&(e=a),n<0&&(n=i);const o=Na(Qo(0,a,1,"int32"),[-1,1]),l=Qo(0,i,1,"int32"),u=oi(o,l),h=hi(Xo(u,na(+e,"int32")),ei(u,na(-n,"int32"))),c=Di([a,i],s.dtype);return Na(to(ao(Na(s,[-1,a,i])).map((t=>oo(h,t,c)))),r)}}),el=Rs({pow_:function(t,e){let n=Os(t,"base","pow"),s=Os(e,"exp","pow");[n,s]=Is(n,s);const r={a:n,b:s};return $s.runKernel(Ge,r)}});function nl(t,e,n=null){if(0===t.rank)return ra(t);if(1!==t.rank&&null===n)return nl(Na(t,[-1]),e,n);if(1===t.rank||"number"==typeof n||Array.isArray(n)&&1===n.length){if(1===e)return li(ra(t),n);if(e===1/0)return ai(ra(t),n);if(e===-1/0)return mi(ra(t),n);if("euclidean"===e||2===e)return Xi(li(el(ra(t),na(2,"int32")),n));throw new Error(`Error in norm: invalid ord value: ${e}`)}if(Array.isArray(n)&&2===n.length){if(1===e)return ai(li(ra(t),n[0]),n[1]-1);if(e===1/0)return ai(li(ra(t),n[1]),n[0]);if(e===-1/0)return mi(li(ra(t),n[1]),n[0]);if("fro"===e||"euclidean"===e)return Xi(li(Ii(t),n));throw new Error(`Error in norm: invalid ord value: ${e}`)}throw new Error(`Error in norm: invalid axis: ${n}`)}const sl=Rs({norm_:function(t,e="euclidean",n=null,s=!1){const r=nl(t=Os(t,"x","norm"),e,n);let a=r.shape;if(s){const e=M(n,t.shape);a=ki(r.shape,e)}return Na(r,a)}}),rl=Rs({gramSchmidt_:function(t){let e;if(Array.isArray(t)){e=!1,v(null!=t&&t.length>0,(()=>"Gram-Schmidt process: input must not be null, undefined, or empty"));const n=t[0].shape[0];for(let e=1;e<t.length;++e)v(t[e].shape[0]===n,(()=>`Gram-Schmidt: Non-unique lengths found in the input vectors: (${t[e].shape[0]} vs. ${n})`))}else e=!0,t=Yi(t,t.shape[0],0).map((t=>Qi(t,[0])));v(t.length<=t[0].shape[0],(()=>`Gram-Schmidt: Number of vectors (${t.length}) exceeds number of dimensions (${t[0].shape[0]}).`));const n=[],s=t;for(let e=0;e<t.length;++e)n.push($s.tidy((()=>{let t=s[e];if(e>0)for(let s=0;s<e;++s){const e=ii(li(ii(n[s],t)),n[s]);t=oi(t,e)}return Va(t,sl(t,"euclidean"))})));return e?to(n,0):n}});function al(t,e=!1){return $s.tidy((()=>{v(2===t.shape.length,(()=>`qr2d() requires a 2D Tensor, but got a ${t.shape.length}D Tensor.`));const n=t.shape[0],s=t.shape[1];let r=Za(n),a=Sr(t);const i=so([[1]],[1,1]);let o=Sr(i);const l=n>=s?s:n;for(let t=0;t<l;++t){const e=a,l=o,u=r;[o,a,r]=$s.tidy((()=>{const e=Hi(a,[t,t],[n-t,1]),l=sl(e),u=Hi(a,[t,t],[1,1]),h=oo(ti(u,0),so([[-1]]),so([[1]])),c=oi(u,ii(h,l)),p=Va(e,c);o=1===p.shape[0]?Sr(i):$a([i,Hi(p,[1,0],[p.shape[0]-1,p.shape[1]])],0);const d=Ti(Va(Do(h,c),l)),f=Hi(a,[t,0],[n-t,s]),m=ii(d,o),g=uo(o);if(0===t)a=oi(f,Do(m,Do(g,f)));else{const e=oi(f,Do(m,Do(g,f)));a=$a([Hi(a,[0,0],[t,s]),e],0)}const y=uo(m),b=Hi(r,[0,t],[n,r.shape[1]-t]);if(0===t)r=oi(b,Do(Do(b,o),y));else{const e=oi(b,Do(Do(b,o),y));r=$a([Hi(r,[0,0],[n,t]),e],1)}return[o,a,r]})),Qr([e,l,u])}return!e&&n>s&&(r=Hi(r,[0,0],[n,s]),a=Hi(a,[0,0],[s,s])),[r,a]}))}const il=Rs({qr_:function(t,e=!1){if(v(t.rank>=2,(()=>`qr() requires input tensor to have a rank >= 2, but got rank ${t.rank}`)),2===t.rank)return al(t,e);{const n=t.shape.slice(0,t.shape.length-2).reduce(((t,e)=>t*e)),s=ao(Na(t,[n,t.shape[t.shape.length-2],t.shape[t.shape.length-1]]),0),r=[],a=[];return s.forEach((t=>{const[n,s]=al(t,e);r.push(n),a.push(s)})),[Na(to(r,0),t.shape),Na(to(a,0),t.shape)]}}});var ol;!function(t){t[t.NONE=0]="NONE",t[t.MEAN=1]="MEAN",t[t.SUM=2]="SUM",t[t.SUM_BY_NONZERO_WEIGHTS=3]="SUM_BY_NONZERO_WEIGHTS"}(ol||(ol={}));const ll=Rs({computeWeightedLoss_:function(t,e,n=ol.SUM_BY_NONZERO_WEIGHTS){const s=Os(t,"losses","computeWeightedLoss");let r=null;null!=e&&(r=Os(e,"weights","computeWeightedLoss"));const a=null==r?s:ii(s,r);if(n===ol.NONE)return a;if(n===ol.SUM)return li(a);if(n===ol.MEAN){if(null==r)return fi(a);{const t=s.size/r.size,e=Va(li(a),li(r));return t>1?Va(e,na(t)):e}}if(n===ol.SUM_BY_NONZERO_WEIGHTS){if(null==r)return Va(li(a),na(s.size));{const t=ii(r,$i(s.shape)),e=Ir(li(Ei(t,na(0))),"float32");return Va(li(a),e)}}throw Error(`Unknown reduction: ${n}`)}});Rs({absoluteDifference_:function(t,e,n,s=ol.SUM_BY_NONZERO_WEIGHTS){const r=Os(t,"labels","absoluteDifference"),a=Os(e,"predictions","absoluteDifference");let i=null;null!=n&&(i=Os(n,"weights","absoluteDifference")),I(r.shape,a.shape,"Error in absoluteDifference: ");const o=ra(oi(r,a));return ll(o,i,s)}}),Rs({cosineDistance_:function(t,e,n,s,r=ol.SUM_BY_NONZERO_WEIGHTS){const a=Os(t,"labels","cosineDistance"),i=Os(e,"predictions","cosineDistance");let o=null;null!=s&&(o=Os(s,"weights","cosineDistance")),I(a.shape,i.shape,"Error in cosineDistance: ");const l=na(1),u=oi(l,li(ii(a,i),n,!0));return ll(u,o,r)}}),Rs({hingeLoss_:function(t,e,n,s=ol.SUM_BY_NONZERO_WEIGHTS){let r=Os(t,"labels","hingeLoss");const a=Os(e,"predictions","hingeLoss");let i=null;null!=n&&(i=Os(n,"weights","hingeLoss")),I(r.shape,a.shape,"Error in hingeLoss: ");const o=na(1);r=oi(ii(na(2),r),o);const l=Bi(oi(o,ii(r,a)));return ll(l,i,s)}}),Rs({huberLoss_:function(t,e,n,s=1,r=ol.SUM_BY_NONZERO_WEIGHTS){const a=Os(t,"labels","huberLoss"),i=Os(e,"predictions","huberLoss");let o=null;null!=n&&(o=Os(n,"weights","huberLoss")),I(a.shape,i.shape,"Error in huberLoss: ");const l=na(s),u=ra(oi(i,a)),h=gi(u,l),c=oi(u,h),p=aa(ii(na(.5),Ii(h)),ii(l,c));return ll(p,o,r)}}),Rs({logLoss_:function(t,e,n,s=1e-7,r=ol.SUM_BY_NONZERO_WEIGHTS){const a=Os(t,"labels","logLoss"),i=Os(e,"predictions","logLoss");let o=null;null!=n&&(o=Os(n,"weights","logLoss")),I(a.shape,i.shape,"Error in logLoss: ");const l=na(1),u=na(s),h=Ti(ii(a,si(aa(i,u)))),c=ii(oi(l,a),si(aa(oi(l,i),u))),p=oi(h,c);return ll(p,o,r)}});const ul=Rs({squaredDifference_:function(t,e){let n=Os(t,"a","squaredDifference"),s=Os(e,"b","squaredDifference");[n,s]=Is(n,s),qa(n.shape,s.shape);const r={a:n,b:s};return $s.runKernel(In,r,{})}});Rs({meanSquaredError_:function(t,e,n,s=ol.SUM_BY_NONZERO_WEIGHTS){const r=Os(t,"labels","meanSquaredError"),a=Os(e,"predictions","meanSquaredError");let i=null;null!=n&&(i=Os(n,"weights","meanSquaredError")),I(r.shape,a.shape,"Error in meanSquaredError: ");const o=ul(r,a);return ll(o,i,s)}});const hl=Rs({log1p_:function(t){const e={x:Os(t,"x","log1p")};return $s.runKernel(be,e)}});Rs({sigmoidCrossEntropy_:function(t,e,n,s=0,r=ol.SUM_BY_NONZERO_WEIGHTS){let a=Os(t,"multiClassLabels","sigmoidCrossEntropy");const i=Os(e,"logits","sigmoidCrossEntropy");let o=null;if(null!=n&&(o=Os(n,"weights","sigmoidCrossEntropy")),I(a.shape,i.shape,"Error in sigmoidCrossEntropy: "),s>0){const t=na(s),e=na(1),n=na(.5);a=aa(ii(a,oi(e,t)),ii(n,t))}const l=function(t,e){const n=Os(t,"labels","sigmoidCrossEntropyWithLogits"),s=Os(e,"logits","sigmoidCrossEntropyWithLogits");I(n.shape,s.shape,"Error in sigmoidCrossEntropyWithLogits: ");const r=Bi(s),a=ii(s,n),i=hl(ri(Ti(ra(s))));return aa(oi(r,a),i)}(a,i);return ll(l,o,r)}});const cl=Rs({logSumExp_:function(t,e=null,n=!1){const s=Os(t,"x","logSumExp"),r=M(e,s.shape),a=ai(s,r,!0),i=oi(s,a),o=ri(i),l=li(o,r),u=si(l),h=aa(Na(a,u.shape),u);if(n){const t=ki(h.shape,r);return Na(h,t)}return h}});Rs({softmaxCrossEntropy_:function(t,e,n,s=0,r=ol.SUM_BY_NONZERO_WEIGHTS){let a=Os(t,"onehotLabels","softmaxCrossEntropy");const i=Os(e,"logits","softmaxCrossEntropy");let o=null;if(null!=n&&(o=Os(n,"weights","softmaxCrossEntropy")),I(a.shape,i.shape,"Error in softmaxCrossEntropy: "),s>0){const t=na(s),e=na(1),n=na(a.shape[1]);a=aa(ii(a,oi(e,t)),Va(t,n))}const l=function(t,e,n=-1){if(-1===n&&(n=e.rank-1),n!==e.rank-1)throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${e.rank} and dim was ${n}`);return ea(((t,e,s)=>{const r=cl(e,[n],!0),a=oi(Ir(e,"float32"),r);s([t,a]);const i=Ti(ii(a,t));return{value:li(i,[n]),gradFunc:(t,e)=>{const[s,r]=e,a=ki(t.shape,[n]);return[ii(Na(t,a),oi(Ir(s,"float32"),ri(r))),ii(Na(t,a),oi(ri(r),Ir(s,"float32")))]}}}))(t,e)}(a,i);return ll(l,o,r)}});const pl={flipLeftRight:Co,resizeNearestNeighbor:Yo,resizeBilinear:Zo,rotateWithOffset:Oo,cropAndResize:zo,nonMaxSuppression:Ro,nonMaxSuppressionAsync:async function(t,e,n,s=.5,r=Number.NEGATIVE_INFINITY){const a=Os(t,"boxes","nonMaxSuppressionAsync"),i=Os(e,"scores","nonMaxSuppressionAsync"),o=Lo(a,i,n,s,r);n=o.maxOutputSize,s=o.iouThreshold,r=o.scoreThreshold;const l=await Promise.all([a.data(),i.data()]),u=l[0],h=l[1],{selectedIndices:c}=Po(u,h,n,s,r);return a!==t&&a.dispose(),i!==e&&i.dispose(),no(c,"int32")},nonMaxSuppressionWithScore:Ko,nonMaxSuppressionWithScoreAsync:async function(t,e,n,s=.5,r=Number.NEGATIVE_INFINITY,a=0){const i=Os(t,"boxes","nonMaxSuppressionAsync"),o=Os(e,"scores","nonMaxSuppressionAsync"),l=Lo(i,o,n,s,r,a);n=l.maxOutputSize,s=l.iouThreshold,r=l.scoreThreshold,a=l.softNmsSigma;const u=await Promise.all([i.data(),o.data()]),h=u[0],c=u[1],{selectedIndices:p,selectedScores:d}=Uo(h,c,n,s,r,a);return i!==t&&i.dispose(),o!==e&&o.dispose(),{selectedIndices:no(p,"int32"),selectedScores:no(d)}},nonMaxSuppressionPadded:Jo,nonMaxSuppressionPaddedAsync:async function(t,e,n,s=.5,r=Number.NEGATIVE_INFINITY,a=!1){const i=Os(t,"boxes","nonMaxSuppressionAsync"),o=Os(e,"scores","nonMaxSuppressionAsync"),l=Lo(i,o,n,s,r,null),u=l.maxOutputSize,h=l.iouThreshold,c=l.scoreThreshold,[p,d]=await Promise.all([i.data(),o.data()]),{selectedIndices:f,validOutputs:m}=Vo(p,d,u,h,c,a);return i!==t&&i.dispose(),o!==e&&o.dispose(),{selectedIndices:no(f,"int32"),validOutputs:na(m,"int32")}}},dl={bandPart:tl,gramSchmidt:rl,qr:il};class fl extends sa{constructor(t,e,n=null){super(),this.learningRate=t,this.rho=e,this.epsilon=n,this.accumulatedGrads=[],this.accumulatedUpdates=[],null==n&&(this.epsilon=$s.backend.epsilon())}applyGradients(t){(Array.isArray(t)?t.map((t=>t.name)):Object.keys(t)).forEach(((e,n)=>{const s=$s.registeredVariables[e];null==this.accumulatedGrads[n]&&(this.accumulatedGrads[n]={originalName:`${e}/accum_grad`,variable:Xr((()=>lo(s).variable(!1)))}),null==this.accumulatedUpdates[n]&&(this.accumulatedUpdates[n]={originalName:`${e}/accum_var`,variable:Xr((()=>lo(s).variable(!1)))});const r=Array.isArray(t)?t[n].tensor:t[e];if(null==r)return;const a=this.accumulatedGrads[n].variable,i=this.accumulatedUpdates[n].variable;Xr((()=>{const t=aa(ii(a,this.rho),ii(Ii(r),1-this.rho)),e=ii(Va(Xi(aa(i,this.epsilon)),Xi(aa(a,this.epsilon))),r),n=aa(ii(i,this.rho),ii(Ii(e),1-this.rho));a.assign(t),i.assign(n);const o=aa(ii(e,-this.learningRate),s);s.assign(o)}))})),this.incrementIterations()}dispose(){null!=this.accumulatedUpdates&&(Qr(this.accumulatedGrads.map((t=>t.variable))),Qr(this.accumulatedUpdates.map((t=>t.variable))))}async getWeights(){const t=[...this.accumulatedGrads,...this.accumulatedUpdates];return[await this.saveIterations()].concat(t.map((t=>({name:t.originalName,tensor:t.variable}))))}async setWeights(t){const e=(t=await this.extractIterations(t)).length/2;this.accumulatedGrads=t.slice(0,e).map((t=>({originalName:t.name,variable:t.tensor.variable(!1)}))),this.accumulatedUpdates=t.slice(e,2*e).map((t=>({originalName:t.name,variable:t.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,rho:this.rho,epsilon:this.epsilon}}static fromConfig(t,e){return new t(e.learningRate,e.rho,e.epsilon)}}fl.className="Adadelta",Kr(fl);class ml extends sa{constructor(t,e=.1){super(),this.learningRate=t,this.initialAccumulatorValue=e,this.accumulatedGrads=[]}applyGradients(t){(Array.isArray(t)?t.map((t=>t.name)):Object.keys(t)).forEach(((e,n)=>{const s=$s.registeredVariables[e];if(null==this.accumulatedGrads[n]){const t=!1;this.accumulatedGrads[n]={originalName:`${e}/accumulator`,variable:Xr((()=>Ya(s.shape,this.initialAccumulatorValue).variable(t)))}}const r=Array.isArray(t)?t[n].tensor:t[e];if(null==r)return;const a=this.accumulatedGrads[n].variable;Xr((()=>{const t=aa(a,Ii(r));a.assign(t);const e=aa(ii(Va(r,Xi(aa(t,$s.backend.epsilon()))),-this.learningRate),s);s.assign(e)}))})),this.incrementIterations()}dispose(){null!=this.accumulatedGrads&&Qr(this.accumulatedGrads.map((t=>t.variable)))}async getWeights(){return[await this.saveIterations()].concat(this.accumulatedGrads.map((t=>({name:t.originalName,tensor:t.variable}))))}async setWeights(t){t=await this.extractIterations(t),this.accumulatedGrads=t.map((t=>({originalName:t.name,variable:t.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,initialAccumulatorValue:this.initialAccumulatorValue}}static fromConfig(t,e){return new t(e.learningRate,e.initialAccumulatorValue)}}ml.className="Adagrad",Kr(ml);class gl extends sa{constructor(t,e,n,s=null){super(),this.learningRate=t,this.beta1=e,this.beta2=n,this.epsilon=s,this.accumulatedFirstMoment=[],this.accumulatedSecondMoment=[],Xr((()=>{this.accBeta1=na(e).variable(),this.accBeta2=na(n).variable()})),null==s&&(this.epsilon=$s.backend.epsilon())}applyGradients(t){const e=Array.isArray(t)?t.map((t=>t.name)):Object.keys(t);Xr((()=>{const n=oi(1,this.accBeta1),s=oi(1,this.accBeta2);e.forEach(((e,r)=>{const a=$s.registeredVariables[e];null==this.accumulatedFirstMoment[r]&&(this.accumulatedFirstMoment[r]={originalName:`${e}/m`,variable:Xr((()=>lo(a).variable(!1)))}),null==this.accumulatedSecondMoment[r]&&(this.accumulatedSecondMoment[r]={originalName:`${e}/v`,variable:Xr((()=>lo(a).variable(!1)))});const i=Array.isArray(t)?t[r].tensor:t[e];if(null==i)return;const o=this.accumulatedFirstMoment[r].variable,l=this.accumulatedSecondMoment[r].variable,u=aa(ii(o,this.beta1),ii(i,1-this.beta1)),h=aa(ii(l,this.beta2),ii(Ii(i),1-this.beta2)),c=Va(u,n),p=Va(h,s);o.assign(u),l.assign(h);const d=aa(ii(Va(c,aa(Xi(p),this.epsilon)),-this.learningRate),a);a.assign(d)})),this.accBeta1.assign(ii(this.accBeta1,this.beta1)),this.accBeta2.assign(ii(this.accBeta2,this.beta2))})),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.accBeta2.dispose(),null!=this.accumulatedFirstMoment&&Qr(this.accumulatedFirstMoment.map((t=>t.variable))),null!=this.accumulatedSecondMoment&&Qr(this.accumulatedSecondMoment.map((t=>t.variable)))}async getWeights(){const t=[...this.accumulatedFirstMoment,...this.accumulatedSecondMoment];return[await this.saveIterations()].concat(t.map((t=>({name:t.originalName,tensor:t.variable}))))}async setWeights(t){t=await this.extractIterations(t),Xr((()=>{this.accBeta1.assign(el(this.beta1,this.iterations_+1)),this.accBeta2.assign(el(this.beta2,this.iterations_+1))}));const e=t.length/2;this.accumulatedFirstMoment=t.slice(0,e).map((t=>({originalName:t.name,variable:t.tensor.variable(!1)}))),this.accumulatedSecondMoment=t.slice(e,2*e).map((t=>({originalName:t.name,variable:t.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon}}static fromConfig(t,e){return new t(e.learningRate,e.beta1,e.beta2,e.epsilon)}}gl.className="Adam",Kr(gl);class yl extends sa{constructor(t,e,n,s=null,r=0){super(),this.learningRate=t,this.beta1=e,this.beta2=n,this.epsilon=s,this.decay=r,this.accumulatedFirstMoment=[],this.accumulatedWeightedInfNorm=[],Xr((()=>{this.iteration=na(0).variable(),this.accBeta1=na(e).variable()})),null==s&&(this.epsilon=$s.backend.epsilon())}applyGradients(t){const e=Array.isArray(t)?t.map((t=>t.name)):Object.keys(t);Xr((()=>{const n=oi(1,this.accBeta1),s=Va(-this.learningRate,aa(ii(this.iteration,this.decay),1));e.forEach(((e,r)=>{const a=$s.registeredVariables[e];null==this.accumulatedFirstMoment[r]&&(this.accumulatedFirstMoment[r]={originalName:`${e}/m`,variable:lo(a).variable(!1)}),null==this.accumulatedWeightedInfNorm[r]&&(this.accumulatedWeightedInfNorm[r]={originalName:`${e}/v`,variable:lo(a).variable(!1)});const i=Array.isArray(t)?t[r].tensor:t[e];if(null==i)return;const o=this.accumulatedFirstMoment[r].variable,l=this.accumulatedWeightedInfNorm[r].variable,u=aa(ii(o,this.beta1),ii(i,1-this.beta1)),h=ii(l,this.beta2),c=ra(i),p=di(h,c);o.assign(u),l.assign(p);const d=aa(ii(Va(s,n),Va(u,aa(p,this.epsilon))),a);a.assign(d)})),this.iteration.assign(aa(this.iteration,1)),this.accBeta1.assign(ii(this.accBeta1,this.beta1))})),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.iteration.dispose(),null!=this.accumulatedFirstMoment&&Qr(this.accumulatedFirstMoment.map((t=>t.variable))),null!=this.accumulatedWeightedInfNorm&&Qr(this.accumulatedWeightedInfNorm.map((t=>t.variable)))}async getWeights(){throw new Error("getWeights() is not implemented for Adamax yet.")}async setWeights(t){throw new Error("setWeights() is not implemented for Adamax yet.")}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon,decay:this.decay}}static fromConfig(t,e){return new t(e.learningRate,e.beta1,e.beta2,e.epsilon,e.decay)}}yl.className="Adamax",Kr(yl);class bl extends sa{constructor(t){super(),this.learningRate=t,this.setLearningRate(t)}applyGradients(t){(Array.isArray(t)?t.map((t=>t.name)):Object.keys(t)).forEach(((e,n)=>{const s=Array.isArray(t)?t[n].tensor:t[e];if(null==s)return;const r=$s.registeredVariables[e];Xr((()=>{const t=aa(ii(this.c,s),r);r.assign(t)}))})),this.incrementIterations()}setLearningRate(t){this.learningRate=t,null!=this.c&&this.c.dispose(),this.c=ta(na(-t))}dispose(){this.c.dispose()}async getWeights(){return[await this.saveIterations()]}async setWeights(t){if(0!==(t=await this.extractIterations(t)).length)throw new Error("SGD optimizer does not have settable weights.")}getConfig(){return{learningRate:this.learningRate}}static fromConfig(t,e){return new t(e.learningRate)}}bl.className="SGD",Kr(bl);class kl extends bl{constructor(t,e,n=!1){super(t),this.learningRate=t,this.momentum=e,this.useNesterov=n,this.accumulations=[],this.m=na(this.momentum)}applyGradients(t){(Array.isArray(t)?t.map((t=>t.name)):Object.keys(t)).forEach(((e,n)=>{const s=$s.registeredVariables[e];if(null==this.accumulations[n]){const t=!1;this.accumulations[n]={originalName:`${e}/momentum`,variable:Xr((()=>lo(s).variable(t)))}}const r=this.accumulations[n].variable,a=Array.isArray(t)?t[n].tensor:t[e];null!=a&&Xr((()=>{let t;const e=aa(ii(this.m,r),a);t=this.useNesterov?aa(ii(this.c,aa(a,ii(e,this.m))),s):aa(ii(this.c,e),s),r.assign(e),s.assign(t)}))})),this.incrementIterations()}dispose(){this.m.dispose(),null!=this.accumulations&&Qr(this.accumulations.map((t=>t.variable)))}setMomentum(t){this.momentum=t}async getWeights(){return[await this.saveIterations()].concat(this.accumulations.map((t=>({name:t.originalName,tensor:t.variable}))))}async setWeights(t){t=await this.extractIterations(t),this.accumulations=t.map((t=>({originalName:t.name,variable:t.tensor.variable(!1)})))}getConfig(){return{learningRate:this.learningRate,momentum:this.momentum,useNesterov:this.useNesterov}}static fromConfig(t,e){return new t(e.learningRate,e.momentum,e.useNesterov)}}kl.className="Momentum",Kr(kl);class wl extends sa{constructor(t,e=.9,n=0,s=null,r=!1){if(super(),this.learningRate=t,this.decay=e,this.momentum=n,this.epsilon=s,this.accumulatedMeanSquares=[],this.accumulatedMoments=[],this.accumulatedMeanGrads=[],this.centered=r,null==s&&(this.epsilon=$s.backend.epsilon()),null==t)throw new Error("learningRate for RMSPropOptimizer must be defined.")}applyGradients(t){(Array.isArray(t)?t.map((t=>t.name)):Object.keys(t)).forEach(((e,n)=>{const s=$s.registeredVariables[e],r=!1;null==this.accumulatedMeanSquares[n]&&(this.accumulatedMeanSquares[n]={originalName:`${e}/rms`,variable:Xr((()=>lo(s).variable(r)))}),null==this.accumulatedMoments[n]&&(this.accumulatedMoments[n]={originalName:`${e}/momentum`,variable:Xr((()=>lo(s).variable(r)))}),null==this.accumulatedMeanGrads[n]&&this.centered&&(this.accumulatedMeanGrads[n]={originalName:`${e}/mg`,variable:Xr((()=>lo(s).variable(r)))});const a=Array.isArray(t)?t[n].tensor:t[e];if(null==a)return;const i=this.accumulatedMeanSquares[n].variable,o=this.accumulatedMoments[n].variable;Xr((()=>{const t=aa(ii(i,this.decay),ii(Ii(a),1-this.decay));if(this.centered){const e=this.accumulatedMeanGrads[n].variable,r=aa(ii(e,this.decay),ii(a,1-this.decay)),l=Va(ii(a,this.learningRate),Xi(oi(t,aa(Ii(r),this.epsilon)))),u=aa(ii(o,this.momentum),l);i.assign(t),e.assign(r),o.assign(u);const h=oi(s,u);s.assign(h)}else{const t=aa(ii(i,this.decay),ii(Ii(a),1-this.decay)),e=aa(ii(o,this.momentum),Va(ii(a,this.learningRate),Xi(aa(t,this.epsilon))));i.assign(t),o.assign(e);const n=oi(s,e);s.assign(n)}}))})),this.incrementIterations()}dispose(){null!=this.accumulatedMeanSquares&&Qr(this.accumulatedMeanSquares.map((t=>t.variable))),null!=this.accumulatedMeanGrads&&this.centered&&Qr(this.accumulatedMeanGrads.map((t=>t.variable))),null!=this.accumulatedMoments&&Qr(this.accumulatedMoments.map((t=>t.variable)))}async getWeights(){const t=[...this.accumulatedMeanSquares,...this.accumulatedMoments];return this.centered&&t.push(...this.accumulatedMeanGrads),[await this.saveIterations()].concat(t.map((t=>({name:t.originalName,tensor:t.variable}))))}async setWeights(t){t=await this.extractIterations(t);const e=this.centered?t.length/3:t.length/2,n=!1;this.accumulatedMeanSquares=t.slice(0,e).map((t=>({originalName:t.name,variable:t.tensor.variable(n)}))),this.accumulatedMoments=t.slice(e,2*e).map((t=>({originalName:t.name,variable:t.tensor.variable(n)}))),this.centered&&(this.accumulatedMeanGrads=t.slice(2*e,3*e).map((t=>({originalName:t.name,variable:t.tensor.variable(n)}))))}getConfig(){return{learningRate:this.learningRate,decay:this.decay,momentum:this.momentum,epsilon:this.epsilon,centered:this.centered}}static fromConfig(t,e){return new t(e.learningRate,e.decay,e.momentum,e.epsilon,e.centered)}}wl.className="RMSProp",Kr(wl);class xl{static sgd(t){return new bl(t)}static momentum(t,e,n=!1){return new kl(t,e,n)}static rmsprop(t,e=.9,n=0,s=null,r=!1){return new wl(t,e,n,s,r)}static adam(t=.001,e=.9,n=.999,s=null){return new gl(t,e,n,s)}static adadelta(t=.001,e=.95,n=null){return new fl(t,e,n)}static adamax(t=.002,e=.9,n=.999,s=null,r=0){return new yl(t,e,n,s,r)}static adagrad(t,e=.1){return new ml(t,e)}}const Nl={sgd:xl.sgd,momentum:xl.momentum,adadelta:xl.adadelta,adagrad:xl.adagrad,rmsprop:xl.rmsprop,adamax:xl.adamax,adam:xl.adam},vl="undefined"!=typeof requestAnimationFrame?requestAnimationFrame:"undefined"!=typeof setImmediate?setImmediate:t=>t();function Il(){return new Promise((t=>vl((()=>t()))))}function Sl(t,e){const n=t[0].slice();for(let s=1;s<t.length;s++)n[e]+=t[s][e];return n}function Tl(t,e,n,s=!0){let r=[];if(s)r=r.concat(e.slice(0)),r.push(t[0]/n),r=r.concat(t.slice(1));else{r=r.concat(t[0]);const n=e.length;for(let s=0;s<n;++s)r=r.concat([t[s+1]/e[s],e[s]]);r=r.concat(t.slice(n+1))}return r}function El(t,e,n=!0){const s=[];if(n){s.push(e);for(let n=e+1;n<t;++n)n<=2*e?(s.push(n),s.push(n-(e+1))):s.push(n)}else{const n=[],r=[];for(let s=1;s<t;++s)s>=2*e+1||s%2==1?r.push(s):n.push(s);s.push(...n),s.push(0),s.push(...r)}return s}function Al(t,e,n,s=!0){const r=[];s?r.push(t[0]/n):r.push(t[0]*n);for(let n=1;n<t.length;++n)n<=e.length?s?r.push(e[n-1]*t[n]):r.push(t[n]/e[n-1]):r.push(t[n]);return r}function Dl(t,e,n){const s=e.shape.length,r=s>1?e.shape[s-1]:1,a=n.length;let i=1;for(let t=r;t<a;++t)i*=n[t];const o=r<1?1:r;return{sliceRank:r,numUpdates:E(e.shape)/o,sliceSize:i,strides:[...B(n.slice(0,r)),1],outputSize:E(n)}}function $l(t,e){if(t.length!==e.length)throw new Error(`Cannot merge real and imag arrays of different lengths. real:${t.length}, imag: ${e.length}.`);const n=new Float32Array(2*t.length);for(let s=0;s<n.length;s+=2)n[s]=t[s/2],n[s+1]=e[s/2];return n}function Ml(t,e){return{real:t[2*e],imag:t[2*e+1]}}function Fl(t,e,n,s){t[2*s]=e,t[2*s+1]=n}function _l(t,e,n){const s=(n?2:-2)*Math.PI*(t/e);return{real:Math.cos(s),imag:Math.sin(s)}}function zl(t){try{return t.map((t=>hs(t)))}catch(t){throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${t}`)}}function Cl(t,e){const n=[];for(let t=0;t<e.length;t++)e[t]&&n.push(t);const s=vr(t,"int32"),r=vr([n.length,t.length],"int32");for(let e=0;e<n.length;e++){const a=s.indexToLoc(n[e]),i=e*t.length;r.values.set(a,i)}return r.toTensor()}const Ol={kernelName:et,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>ii(t,wo(Ir(n,"float32"),-1))}}},Ll={kernelName:nt,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>{const e=Ii(Ir(n,"float32")),s=Xi(oi(na(1),e));return Ti(Va(t,s))}}}},Rl={kernelName:st,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>{const e=Xi(oi(Ii(Ir(n,"float32")),1));return Va(t,e)}}}},Bl={kernelName:rt,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=qa(n.shape,s.shape);return{a:()=>{let e=t;const s=ja(n.shape,r);return s.length>0&&(e=li(e,s)),Na(e,n.shape)},b:()=>{let e=t;const n=ja(s.shape,r);return n.length>0&&(e=li(e,n)),Na(e,s.shape)}}}},Wl={kernelName:at,saveAllInputs:!0,gradFunc:(t,e)=>{const n={};return e.forEach(((e,s)=>{n[s]=()=>t.clone()})),n}},Pl={kernelName:it,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>lo(n)}}},Vl={kernelName:ot,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>lo(n)}}},Ul={kernelName:lt,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Va(t,Xi(oi(na(1),Ii(Ir(n,"float32")))))}}},Hl={kernelName:ut,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>{const e=Xi(aa(na(1),Ii(Ir(n,"float32"))));return Va(t,e)}}}},jl={kernelName:pt,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=qa(n.shape,s.shape);return{a:()=>{const e=aa(Ii(n),Ii(s));let a=ii(t,Va(s,e));const i=ja(n.shape,r);return i.length>0&&(a=li(a,i)),Na(a,n.shape)},b:()=>{const e=aa(Ii(n),Ii(s));let a=Ti(ii(t,Va(n,e)));const i=ja(s.shape,r);return i.length>0&&(a=li(a,i)),Na(a,s.shape)}}}},ql={kernelName:ht,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Va(t,aa(Ii(Ir(n,"float32")),1))}}},Gl={kernelName:ct,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Va(t,oi(na(1),Ii(Ir(n,"float32"))))}}},Kl=Rs({avgPool3dGrad_:function(t,e,n,s,r=[1,1,1],a,i){const o=Os(t,"dy","avgPool3dGrad"),l=Os(e,"input","avgPool3dGrad");let u=o,h=l,c=!1;4===l.rank&&(c=!0,u=Na(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]]),h=Na(l,[1,l.shape[0],l.shape[1],l.shape[2],l.shape[3]])),v(5===u.rank,(()=>`Error in avgPool3dGrad: dy must be rank 5 but got rank ${u.rank}.`)),v(5===h.rank,(()=>`Error in avgPool3dGrad: input must be rank 5 but got rank ${h.rank}.`)),v(wa(s,r),(()=>`Error in avgPool3dGrad: Either strides or dilations must be 1. Got strides ${s} and dilations '${r}'`)),null!=i&&v(D(a),(()=>`Error in avgPool3dGrad: pad must be an integer when using, dimRoundingMode ${i} but got pad ${a}.`));const p={dy:u,input:h},d={filterSize:n,strides:s,dilations:r,pad:a,dimRoundingMode:i},f=$s.runKernel(gt,p,d);return c?Na(f,[f.shape[1],f.shape[2],f.shape[3],f.shape[4]]):f}}),Jl={kernelName:mt,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{filterSize:r,strides:a,dilations:i,pad:o,dimRoundingMode:l}=n,u=null==i?[1,1,1]:i;return{x:()=>Kl(t,s,r,a,u,o,l)}}},Zl=Rs({avgPoolGrad_:function(t,e,n,s,r){const a=Os(t,"dy","avgPoolGrad"),i=Os(e,"input","avgPoolGrad");v(i.rank===a.rank,(()=>`Rank of input (${i.rank}) does not match rank of dy (${a.rank})`));let o=i,l=a,u=!1;3===i.rank&&(u=!0,o=Na(i,[1,i.shape[0],i.shape[1],i.shape[2]]),l=Na(a,[1,a.shape[0],a.shape[1],a.shape[2]])),v(4===l.rank,(()=>`Error in avgPoolGrad: dy must be rank 4 but got rank ${l.rank}.`)),v(4===o.rank,(()=>`Error in avgPoolGrad: input must be rank 4 but got rank ${o.rank}.`));const h={dy:l,input:o},c={filterSize:n,strides:s,pad:r},p=$s.runKernel(ft,h,c);return u?Na(p,[p.shape[1],p.shape[2],p.shape[3]]):p}}),Yl={kernelName:dt,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{filterSize:r,strides:a,pad:i}=n;return{x:()=>Zl(t,s,r,a,i)}}},Xl={kernelName:yt,inputsToSave:["a","b"],gradFunc:(t,e,n)=>{const[s,r]=e,{transposeA:a,transposeB:i}=n;return a||i?!a&&i?{a:()=>Do(t,r,!1,!1),b:()=>Do(t,s,!0,!1)}:a&&!i?{a:()=>Do(r,t,!1,!0),b:()=>Do(s,t,!1,!1)}:{a:()=>Do(r,t,!0,!0),b:()=>Do(t,s,!0,!0)}:{a:()=>Do(t,r,!1,!0),b:()=>Do(s,t,!0,!1)}}},Ql=Rs({spaceToBatchND_:function(t,e,n){const s=Os(t,"x","spaceToBatchND");v(s.rank>=1+e.length,(()=>`input rank ${s.rank} should be > than [blockShape] ${e.length}`)),v(n.length===e.length,(()=>`paddings.shape[0] ${n.length} must be equal to [blockShape] ${e.length}`)),v(s.shape.reduce(((t,s,r)=>r>0&&r<=e.length?t&&(s+n[r-1][0]+n[r-1][1])%e[r-1]==0:t),!0),(()=>`input spatial dimensions ${s.shape.slice(1)} with paddings ${n.toString()} must be divisible by blockShapes ${e.toString()}`));const r={x:s},a={blockShape:e,paddings:n};return $s.runKernel(xn,r,a)}}),tu={kernelName:bt,gradFunc:(t,e,n)=>{const{blockShape:s,crops:r}=n;return{x:()=>Ql(t,s,r)}}},eu={kernelName:"BroadcastTo",gradFunc:(t,e,n)=>{const s=n,r=s.inputShape,a=s.shape,i=Array.from(a);for(let t=r.length-1;t>=0;t--)if(r[t]===a[t])i[t]=1;else if(1!==r[t])throw new Error(`broadcastTo(): [${r}] cannot be broadcast to [${a}].`);const o=[];for(let t=0;t<i.length;t++)i[t]>1&&o.push(t);return{x:()=>li(t,o,!0)}}},nu={kernelName:wt,gradFunc:t=>({x:()=>t.clone()})},su={kernelName:xt,gradFunc:t=>({x:()=>lo(t)})},ru={kernelName:Nt,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{clipValueMin:r,clipValueMax:a}=n;return{x:()=>oo(hi(ei(s,r),Xo(s,a)),t,lo(t))}}},au={kernelName:It,inputsToSave:["x"],gradFunc:Ol.gradFunc},iu={kernelName:St,saveAllInputs:!0,gradFunc:(t,e,n)=>{const s=e.map((t=>t.shape)),{axis:r}=n,a=M(r,e[0].shape)[0],i=s.map((t=>t[a]));return Yi(t,i,a).map((t=>()=>t))}},ou={kernelName:Tt,inputsToSave:["x","filter"],gradFunc:(t,e,n)=>{const[s,r]=e,{dilations:a,strides:i,pad:o,dataFormat:l}=n;return v(ka(a),(()=>`Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${a}'`)),{x:()=>La(s.shape,t,r,i,o,l),filter:()=>bo(s,t,r.shape,i,o,l)}}},lu={kernelName:At,inputsToSave:["dy","filter"],gradFunc:(t,e,n)=>{const[s,r]=e,{strides:a,pad:i,dataFormat:o,dimRoundingMode:l}=n;return{dy:()=>Ca(t,r,a,i,o,1,l),filter:()=>bo(t,s,r.shape,a,i,o,l)}}},uu=Rs({conv3DBackpropFilter_:function(t,e,n,s,r){let a=t;4===t.rank&&(a=Na(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]]));let i=e;4===i.rank&&(i=Na(e,[1,e.shape[0],e.shape[1],e.shape[2],e.shape[3]])),v(5===a.rank,(()=>`Error in conv3dDerFilter: input must be rank 5, but got shape ${a.shape}.`)),v(5===i.rank,(()=>`Error in conv3dDerFilter: dy must be rank 5, but got shape ${i.shape}.`)),v(5===n.length,(()=>`Error in conv3dDerFilter: filterShape must be length 5, but got ${n}.`)),v(a.shape[4]===n[3],(()=>`Error in conv3dDerFilter: depth of input ${a.shape[4]}) must match input depth in filter (${n[3]}.`)),v(i.shape[4]===n[4],(()=>`Error in conv3dDerFilter: depth of dy (${i.shape[4]}) must match output depth for filter (${n[4]}).`));const o={x:a,dy:i},l={strides:s,pad:r,filterShape:n};return $s.runKernel($t,o,l)}}),hu=Rs({conv3DBackpropInput_:function(t,e,n,s,r){v(t.length===e.rank,(()=>`Length of inShape (${t.length}) and rank of dy (${e.rank}) must match`));let a=t,i=e,o=!1;4===e.rank&&(o=!0,i=Na(e,[1,e.shape[0],e.shape[1],e.shape[2],e.shape[3]]),a=[1,t[0],t[1],t[2],t[3]]);const l=a[4],u=i.shape[4];v(5===a.length,(()=>`Error in conv3dDerInput: inShape must be length 5, but got length ${a.length}.`)),v(5===i.rank,(()=>`Error in conv3dDerInput: dy must be rank 5, but got rank ${i.rank}`)),v(5===n.rank,(()=>`Error in conv3dDerInput: filter must be rank 5, but got rank ${n.rank}`)),v(l===n.shape[3],(()=>`Error in conv3dDerInput: depth of input (${l}) must match input depth for filter ${n.shape[3]}.`)),v(u===n.shape[4],(()=>`Error in conv3dDerInput: depth of output (${u}) must match output depth for filter ${n.shape[4]}.`));const h={dy:i,filter:n},c={pad:r,strides:s,inputShape:a},p=$s.runKernel(Mt,h,c);return o?Na(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}}),cu={kernelName:Dt,inputsToSave:["x","filter"],gradFunc:(t,e,n)=>{const{dilations:s,strides:r,pad:a}=n;v(ka(s),(()=>`Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${s}'`));const[i,o]=e;return{x:()=>hu(i.shape,t,o,r,a),filter:()=>uu(i,t,o.shape,r,a)}}},pu=Rs({sin_:function(t){const e={x:Os(t,"x","sin")};return $s.runKernel(fn,e)}}),du={kernelName:Ft,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>ii(Ti(pu(Ir(n,"float32"))),t)}}},fu=Rs({sinh_:function(t){const e={x:Os(t,"x","sinh")};return $s.runKernel(mn,e)}}),mu={kernelName:_t,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>ii(fu(Ir(n,"float32")),t)}}},gu=Rs({cumsum_:function(t,e=0,n=!1,s=!1){const r={x:Os(t,"x","cumsum")},a={axis:e,exclusive:n,reverse:s};return $s.runKernel(zt,r,a)}}),yu={kernelName:zt,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{axis:r,exclusive:a,reverse:i}=n;return{x:()=>{const e=xi([r],s.rank);let n=gu(t,r,a,!i);return null!=e&&(n=uo(n,e)),n}}}},bu={kernelName:Rt,inputsToSave:["x","filter"],gradFunc:(t,e,n)=>{const{dilations:s,strides:r,pad:a,dimRoundingMode:i}=n,o=null==s?[1,1]:s;v(ka(o),(()=>`Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${o}'`));const[l,u]=e;return v(4===l.rank,(()=>`Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${l.rank}.`)),v(4===u.rank,(()=>`Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${u.rank}.`)),v(l.shape[3]===u.shape[2],(()=>`Error in gradient of depthwiseConv2d: number of input channels (${l.shape[3]}) must match the inChannels dimension in filter ${u.shape[2]}.`)),v(wa(r,o),(()=>`Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${r} and dilations '${o}'.`)),null!=i&&v(D(a),(()=>`Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${i} but got pad ${a}.`)),{x:()=>Eo(l.shape,t,u,r,a,s,i),filter:()=>To(l,t,u.shape,r,a,s,i)}}},ku={kernelName:Pt,inputsToSave:["x","filter"],gradFunc:(t,e,n)=>{const[s,r]=e,a={x:s,filter:r,dy:t},i={x:s,filter:r,dy:t};return{x:()=>$s.runKernel(Vt,a,n),filter:()=>$s.runKernel(Ut,i,n)}}},wu={kernelName:jt,outputsToSave:[!0],gradFunc:(t,e)=>{const[n]=e,s={dy:t,y:n};return{x:()=>$s.runKernel(qt,s)}}},xu={kernelName:Gt,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e,s=ii(ri(Ti(Ii(n))),2/Math.sqrt(Math.PI));return{x:()=>ii(t,s)}}},Nu={kernelName:Jt,outputsToSave:[!0],gradFunc:(t,e)=>{const[n]=e;return{x:()=>ii(t,n)}}},vu={kernelName:Zt,inputsToSave:["input"],gradFunc:(t,e)=>{const[n]=e;return{input:()=>Na(t,n.shape)}}},Iu={kernelName:Yt,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>ii(t,ri(n))}}},Su={kernelName:te,gradFunc:t=>({x:()=>lo(t)})},Tu={kernelName:ee,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=qa(n.shape,s.shape);return{a:()=>{const e=Va(t,Ir(s,"float32")),a=ja(n.shape,r);return a.length>0?Na(li(e,a),n.shape):e},b:()=>{let e=ii(t,Ir(n,"float32"));const a=ja(s.shape,r);a.length>0&&(e=Na(li(e,a),s.shape));const i=Ii(s);return Ti(Va(e,Ir(i,"float32")))}}}},Eu=Rs({rsqrt_:function(t){const e={x:Os(t,"x","rsqrt")};return $s.runKernel(un,e)}}),Au={kernelName:ne,inputsToSave:["x","mean","variance","scale"],gradFunc:(t,e,n)=>{const{varianceEpsilon:s}=n,[r,a,i,o]=e,l=null==o?na(1):o,u=ja(a.shape,r.shape),h=[];if(1===a.rank){for(let t=0;t<r.shape.length-1;++t)h.push(r.shape[t]);h.push(1)}const c=oi(r,a),p=ii(t,l),d=Eu(aa(i,na(s))),f=ii(ii(ii(d,d),d),na(-.5));return{x:()=>1===a.rank?Na(ii(ii(t,Ja(Na(d,[1,1,1,a.shape[0]]),h)),l),r.shape):Na(ii(ii(t,d),l),r.shape),mean:()=>{let t=ii(ii(d,na(-1)),p);return 1===a.rank&&(t=li(t,u)),Na(t,a.shape)},variance:()=>{let t=ii(ii(f,c),p);return 1===a.rank&&(t=li(t,u)),Na(t,a.shape)},scale:()=>{const e=ii(c,d);let n=ii(t,e);return 1===a.rank&&(n=li(n,u)),Na(n,a.shape)},offset:()=>{let e=t;return 1===a.rank&&(e=li(e,u)),Na(e,a.shape)}}}},Du=Rs({unsortedSegmentSum_:function(t,e,n){const s=Os(t,"x","unsortedSegmentSum"),r=Os(e,"segmentIds","unsortedSegmentSum","int32");v(D(n),(()=>"numSegments must be of dtype int"));const a={x:s,segmentIds:r},i={numSegments:n};return $s.runKernel(On,a,i)}}),$u={kernelName:se,inputsToSave:["x","indices"],gradFunc:(t,e,n)=>{const[s,r]=e,{axis:a}=n,i=M(a,s.shape)[0];return{x:()=>{const e=s.shape,n=r.size,o=e.slice(0,i),l=o.length,u=e.slice(a,e.length).slice(1),h=u.length,c=Mu(0,l),p=Mu(l+1,l+1+h),d=Fu([o,[n],u]),f=Na(t,d),m=Na(r,[n]),g=Fu([[l],c,p]),y=uo(f,g);let b=Du(y,m,s.shape[i]);const k=Ni(g);return b=uo(b,k),b},indices:()=>r}}};function Mu(t,e){const n=[];for(let s=t;s<e;++s)n.push(s);return n}function Fu(t){const e=[];for(let n=0;n<t.length;++n)for(let s=0;s<t[n].length;++s)e.push(t[n][s]);return e}const _u={kernelName:ie,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e;return{a:()=>lo(n),b:()=>lo(s)}}},zu={kernelName:oe,gradFunc:t=>({x:()=>Ir(t,"float32")})},Cu={kernelName:he,gradFunc:t=>({x:()=>lo(t)})},Ou={kernelName:ce,gradFunc:t=>({x:()=>lo(t)})},Lu={kernelName:pe,gradFunc:t=>({x:()=>lo(t)})},Ru={kernelName:de,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{alpha:r}=n,a=ti(s,0);return{x:()=>oo(a,t,ii(t,r))}}},Bu={kernelName:be,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Va(t,aa(n,1))}}},Wu={kernelName:ye,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Va(t,Ir(n,"float32"))}}},Pu={kernelName:"LogSoftmax",inputsToSave:[],outputsToSave:[!0],gradFunc:(t,e,n)=>{const[s]=e,{axis:r}=n;return{logits:()=>{const e=ri(s);return oi(t,ii(li(t,r,!0),e))}}}},Vu=Rs({localResponseNormalizationBackprop_:function(t,e,n,s=5,r=1,a=1,i=.5){const o={x:t,y:e,dy:n},l={depthRadius:s,bias:r,alpha:a,beta:i};return $s.runKernel(ve,o,l)}}),Uu={kernelName:Ne,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const[s,r]=e,{depthRadius:a,bias:i,alpha:o,beta:l}=n;return{x:()=>Vu(s,r,t,a,i,o,l)}}};function Hu(t,e,n,s){return e.rank<n.rank&&(e=Na(e,ki(e.shape,s))),t.rank<n.rank&&(t=Na(t,ki(t.shape,s))),{x:()=>ii(t,Ir(Ga(n,e),t.dtype))}}const ju={kernelName:Ie,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const s=n,{reductionIndices:r}=s,a=e[0],i=Hu(t,e[1],a,M(r,a.shape));return{x:()=>i.x()}}},qu=Rs({less_:function(t,e){let n=Os(t,"a","less"),s=Os(e,"b","less");[n,s]=Is(n,s),qa(n.shape,s.shape);const r={a:n,b:s};return $s.runKernel(fe,r)}}),Gu={kernelName:Se,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e;return{a:()=>ii(t,Ir(ei(n,s),"float32")),b:()=>ii(t,Ir(qu(n,s),"float32"))}}},Ku=Rs({maxPool3dGrad_:function(t,e,n,s,r,a=[1,1,1],i,o){const l=Os(t,"dy","maxPool3dGrad"),u=Os(e,"input","maxPool3dGrad"),h=Os(n,"output","maxPool3dGrad");let c=l,p=u,d=h,f=!1;4===u.rank&&(f=!0,c=Na(l,[1,l.shape[0],l.shape[1],l.shape[2],l.shape[3]]),p=Na(u,[1,u.shape[0],u.shape[1],u.shape[2],u.shape[3]]),d=Na(h,[1,h.shape[0],h.shape[1],h.shape[2],h.shape[3]])),v(5===c.rank,(()=>`Error in maxPool3dGrad: dy must be rank 5 but got rank ${c.rank}.`)),v(5===p.rank,(()=>`Error in maxPool3dGrad: input must be rank 5 but got rank ${p.rank}.`)),v(5===d.rank,(()=>`Error in maxPool3dGrad: output must be rank 5 but got rank ${d.rank}.`)),v(wa(r,a),(()=>`Error in maxPool3dGrad: Either strides or dilations must be 1. Got strides ${r} and dilations '${a}'`)),null!=o&&v(D(i),(()=>`Error in maxPool3dGrad: pad must be an integer when using, dimRoundingMode ${o} but got pad ${i}.`));const m={dy:c,input:p,output:d},g={filterSize:s,strides:r,dilations:a,pad:i,dimRoundingMode:o},y=$s.runKernel(De,m,g);return f?Na(y,[y.shape[1],y.shape[2],y.shape[3],y.shape[4]]):y}}),Ju={kernelName:Ae,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const[s,r]=e,{filterSize:a,strides:i,dilations:o,pad:l,dimRoundingMode:u}=n,h=null==o?[1,1,1]:o;return{x:()=>Ku(t,s,r,a,i,h,l,u)}}},Zu=Rs({maxPoolGrad_:function(t,e,n,s,r,a,i){const o=Os(t,"dy","maxPoolGrad"),l=Os(e,"input","maxPoolGrad"),u=Os(n,"output","maxPoolGrad");v(l.rank===o.rank,(()=>`Rank of input (${l.rank}) does not match rank of dy (${o.rank})`)),v(4===o.rank,(()=>`Error in maxPoolGrad: dy must be rank 4 but got rank ${o.rank}.`)),v(4===l.rank,(()=>`Error in maxPoolGrad: input must be rank 4 but got rank ${l.rank}.`)),null!=i&&v(D(a),(()=>`Error in maxPoolGrad: pad must be an integer when using, dimRoundingMode ${i} but got pad ${a}.`));const h={dy:o,input:l,output:u},c={filterSize:s,strides:r,pad:a,dimRoundingMode:i};return $s.runKernel(Ee,h,c)}}),Yu={kernelName:Te,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const[s,r]=e,{filterSize:a,strides:i,pad:o}=n;return{x:()=>Zu(t,s,r,a,i,o)}}},Xu={kernelName:Me,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{axis:r}=n,a=M(r,s.shape),i=E(bi(s.shape,a)[1]);return{x:()=>{const e=s.shape.slice();a.forEach((t=>{e[t]=1}));const n=Na(t,e);return Va(ii(n,$i(s.shape,"float32")),i)}}}},Qu={kernelName:Fe,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(t,e,n)=>{const s=n,{axis:r}=s,[a,i]=e,o=Hu(t,i,a,M(r,a.shape));return{x:()=>o.x()}}},th={kernelName:_e,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e;return{a:()=>ii(t,Ir(Xo(n,s),"float32")),b:()=>ii(t,Ir(ti(n,s),"float32"))}}},eh={kernelName:ze,inputsToSave:["x"],gradFunc:(t,e,n)=>{const s=e[0],{paddings:r}=n,a=r.map((t=>t[0]));return{x:()=>Hi(t,a,s.shape)}}},nh={kernelName:Ce,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=qa(n.shape,s.shape);return{a:()=>{const e=ja(n.shape,r);return e.length>0?Na(li(t,e),n.shape):t},b:()=>{const e=ii(t,Ti(Xa(Va(n,s)))),a=ja(s.shape,r);return a.length>0?Na(li(e,a),s.shape):e}}}},sh={kernelName:Le,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=qa(n.shape,s.shape);return{a:()=>{const e=ii(t,Ir(s,"float32")),a=ja(n.shape,r);return a.length>0?Na(li(e,a),n.shape):e},b:()=>{const e=ii(t,Ir(n,"float32")),a=ja(s.shape,r);return a.length>0?Na(li(e,a),s.shape):e}}}},rh={kernelName:Re,gradFunc:t=>({x:()=>Ti(t)})},ah={kernelName:He,inputsToSave:["indices"],gradFunc:(t,e)=>{const n=e[0];return{indices:()=>Di(n.shape,"float32")}}},ih={kernelName:Ue,gradFunc:t=>({x:()=>lo(t)})},oh={kernelName:je,saveAllInputs:!0,gradFunc:(t,e,n)=>{const{axis:s}=n;return ao(t,s).map((t=>()=>t))}},lh={kernelName:qe,inputsToSave:["x"],gradFunc:(t,e,n)=>{const s=e[0],{paddings:r}=n,a=r.map((t=>t[0]));return{x:()=>Hi(t,a,s.shape)}}},uh={kernelName:Ge,inputsToSave:["a","b"],outputsToSave:[!0],gradFunc:(t,e)=>{const[n,s,r]=e,a=n,i=s,o=qa(a.shape,i.shape);return{a:()=>{const e=Ir(i,"float32");let n=ii(t,ii(e,el(a,oi(e,na(1)))));const s=ja(a.shape,o);return s.length>0&&(n=li(n,s)),Na(n,a.shape)},b:()=>{const e=ti(a,0),n=oo(e,si(a),lo(a));let s=ii(t,ii(r,n));const l=ja(i.shape,o);return l.length>0&&(s=li(s,l)),Na(s,i.shape)}}}},hh={kernelName:Ke,inputsToSave:["x","alpha"],gradFunc:(t,e)=>{const[n,s]=e,r=ti(n,0);return{x:()=>oo(r,t,ii(t,s)),alpha:()=>{let e=oo(r,lo(t),ii(t,n));const a=ja(s.shape,t.shape);return a.length>0&&(e=li(e,a)),Na(e,s.shape)}}}},ch={kernelName:Ht,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=qa(n.shape,s.shape);return{a:()=>{const e=Va(t,Ir(s,"float32")),a=ja(n.shape,r);return a.length>0?Na(li(e,a),n.shape):e},b:()=>{let e=ii(t,Ir(n,"float32"));const a=ja(s.shape,r);a.length>0&&(e=Na(li(e,a),s.shape));const i=Ii(s);return Ti(Va(e,Ir(i,"float32")))}}}},ph={kernelName:Xe,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Va(t,Ti(Ii(n)))}}},dh={kernelName:an,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e,s=ii(Xo(n,6),wo(n));return{x:()=>ii(t,Ir(s,"float32"))}}},fh={kernelName:Qe,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>ii(t,Ir(wo(n),"float32"))}}},mh={kernelName:tn,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Na(t,n.shape)}}},gh={kernelName:sn,inputsToSave:["images"],gradFunc:(t,e,n)=>{const[s]=e,r={dy:t,images:s};return{images:()=>$s.runKernel(rn,r,n)}}},yh={kernelName:en,inputsToSave:["images"],gradFunc:(t,e,n)=>{const[s]=e,r={dy:t,images:s};return{images:()=>$s.runKernel(nn,r,n)}}},bh={kernelName:on,gradFunc:(t,e,n)=>{const{dims:s}=n,r=M(s,t.shape);return{x:()=>Wi(t,r)}}},kh={kernelName:ln,gradFunc:t=>({x:()=>lo(t)})},wh={kernelName:un,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Ti(Va(t,ii(el(n,1.5),2)))}}},xh=Rs({logicalNot_:function(t){const e={x:Os(t,"x","logicalNot","bool")};return $s.runKernel(we,e)}}),Nh={kernelName:cn,inputsToSave:["condition"],gradFunc:(t,e)=>{const[n]=e;return{condition:()=>Ir(lo(n),"float32"),t:()=>ii(t,Ir(n,t.dtype)),e:()=>ii(t,Ir(xh(n),t.dtype))}}},vh={kernelName:pn,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>{const e=ti(n,na(0)),s=na(1.7580993408473768),r=na(1.0507009873554805),a=ii(t,r),i=ii(ii(t,s),ri(Ir(n,"float32")));return oo(e,a,i)}}}},Ih={kernelName:yn,outputsToSave:[!0],gradFunc:(t,e)=>{const[n]=e;return{x:()=>ii(t,ii(n,oi(na(1),n)))}}},Sh={kernelName:gn,gradFunc:t=>({x:()=>lo(t)})},Th=Rs({cos_:function(t){const e={x:Os(t,"x","cos")};return $s.runKernel(Ft,e)}}),Eh={kernelName:fn,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>ii(Th(Ir(n,"float32")),t)}}},Ah=Rs({cosh_:function(t){const e={x:Os(t,"x","cosh")};return $s.runKernel(_t,e)}}),Dh={kernelName:mn,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>ii(Ah(Ir(n,"float32")),t)}}},$h={kernelName:dn,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{begin:r,size:a}=n,i=s.shape,[o,l]=Hr(s,r,a),u=[];for(let e=0;e<t.rank;e++)u.push([o[e],i[e]-o[e]-l[e]]);return{x:()=>Fi(t,u)}}},Mh={kernelName:vn,outputsToSave:[!0],gradFunc:(t,e,n)=>{const[s]=e,{dim:r}=n,a=ii(t,s);return{logits:()=>oi(a,ii(li(a,[r],!0),s))}}},Fh={kernelName:bn,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>ii(t,Ui(n))}}},_h=Rs({batchToSpaceND_:function(t,e,n){const s=Os(t,"x","batchToSpaceND"),r=e.reduce(((t,e)=>t*e));v(s.rank>=1+e.length,(()=>`input rank is ${s.rank} but should be > than blockShape.length ${e.length}`)),v(n.length===e.length,(()=>`crops.length is ${n.length} but should be equal to blockShape.length  ${e.length}`)),v(s.shape[0]%r==0,(()=>`input tensor batch is ${s.shape[0]} but is not divisible by the product of the elements of blockShape ${e.join(" * ")} === ${r}`));const a={x:s},i={blockShape:e,crops:n};return $s.runKernel(bt,a,i)}}),zh={kernelName:xn,gradFunc:(t,e,n)=>{const{blockShape:s,paddings:r}=n;return{x:()=>_h(t,s,r)}}},Ch={kernelName:Nn,gradFunc:(t,e,n)=>{const{axis:s}=n;return{x:()=>$a(t,s)}}},Oh=[Ol,Ll,Rl,Bl,Wl,Pl,Vl,Ul,Hl,jl,ql,Gl,Jl,Yl,Xl,tu,eu,nu,su,ru,au,iu,lu,ou,cu,du,mu,yu,bu,ku,ch,wu,xu,Nu,vu,Iu,Tu,Su,Au,$u,_u,zu,Cu,Ou,Lu,Ru,Bu,Wu,Pu,Uu,ju,ju,Gu,Ju,Yu,Xu,Qu,th,eh,nh,sh,rh,ah,ih,oh,lh,lh,uh,hh,ph,dh,fh,mh,gh,yh,bh,kh,wh,Nh,vh,Ih,Sh,Eh,Dh,$h,Mh,Fh,zh,zh,Ch,Ch,{kernelName:kn,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Va(t,ii(Xi(Ir(n,"float32")),2))}}},{kernelName:In,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=na(2);return{a:()=>ii(t,ii(r,oi(n,s))),b:()=>ii(t,ii(r,oi(s,n)))}}},{kernelName:Sn,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>ii(t,ii(Ir(n,"float32"),2))}}},{kernelName:Rn,gradFunc:t=>({x:()=>lo(t)})},{kernelName:Tn,inputsToSave:["a","b"],gradFunc:(t,e)=>{const[n,s]=e,r=qa(n.shape,s.shape);return{a:()=>{let e=t;const s=ja(n.shape,r);return s.length>0&&(e=li(e,s)),Na(e,n.shape)},b:()=>{let e=t;const n=ja(s.shape,r);return n.length>0&&(e=li(e,n)),Na(Ti(e),s.shape)}}}},{kernelName:wn,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,r=s.shape.slice(),{axis:a}=n;M(a,s.shape).forEach((t=>{r[t]=1}));const i=Na(t,r),o=ii(i,$i(s.shape,"float32"));return{x:()=>o}}},{kernelName:Dn,inputsToSave:["x"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>Va(t,Ii(Th(n)))}}},{kernelName:$n,outputsToSave:[!0],gradFunc:(t,e)=>{const[n]=e;return{x:()=>ii(oi(na(1),Ii(n)),t)}}},{kernelName:Mn,inputsToSave:["x"],gradFunc:(t,e,n)=>{const[s]=e,{reps:r}=n;return{x:()=>{let e=lo(s);if(1===s.rank)for(let n=0;n<r[0];++n)e=aa(e,Hi(t,[n*s.shape[0]],[s.shape[0]]));else if(2===s.rank)for(let n=0;n<r[0];++n)for(let a=0;a<r[1];++a)e=aa(e,Hi(t,[n*s.shape[0],a*s.shape[1]],[s.shape[0],s.shape[1]]));else if(3===s.rank)for(let n=0;n<r[0];++n)for(let a=0;a<r[1];++a)for(let i=0;i<r[2];++i)e=aa(e,Hi(t,[n*s.shape[0],a*s.shape[1],i*s.shape[2]],[s.shape[0],s.shape[1],s.shape[2]]));else{if(4!==s.rank)throw new Error(`Gradient for tile operation is not implemented for rank-${s.rank} tensors yet.`);for(let n=0;n<r[0];++n)for(let a=0;a<r[1];++a)for(let i=0;i<r[2];++i)for(let o=0;o<r[3];++o)e=aa(e,Hi(t,[n*s.shape[0],a*s.shape[1],i*s.shape[2],o*s.shape[3]],[s.shape[0],s.shape[1],s.shape[2],s.shape[3]]))}return e}}}},{kernelName:_n,gradFunc:(t,e,n)=>{const s=n,{perm:r}=s,a=Ni(r);return{x:()=>uo(t,a)}}},{kernelName:Cn,gradFunc:(t,e,n)=>{const s=n,{axis:r}=s;return{value:()=>to(t,r)}}},{kernelName:On,inputsToSave:["segmentIds"],gradFunc:(t,e)=>{const[n]=e;return{x:()=>function(t,e){const n=di(e,lo(e)),s=Qa(t,n);let r=ei(e,na(0,"int32"));const a=s.rank-r.rank;for(let t=0;t<a;++t)r=Ka(r,t+1);r=hi(r,$i(s.shape,"bool"));const i=lo(s);return oo(r,s,i)}(t,n)}}},{kernelName:Ln,gradFunc:t=>({x:()=>lo(t)})}];for(const t of Oh)Zn(t);ms.prototype.abs=function(){return this.throwIfDisposed(),ra(this)};const Lh=Rs({acos_:function(t){const e={x:Os(t,"x","acos")};return $s.runKernel(nt,e)}});ms.prototype.acos=function(){return this.throwIfDisposed(),Lh(this)};const Rh=Rs({acosh_:function(t){const e={x:Os(t,"x","acosh")};return $s.runKernel(st,e)}});ms.prototype.acosh=function(){return this.throwIfDisposed(),Rh(this)};const Bh=Rs({mod_:function(t,e){let n=Os(t,"a","mod"),s=Os(e,"b","mod");[n,s]=Is(n,s);const r={a:n,b:s};return $s.runKernel(Ce,r)}}),Wh=Rs({addStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","addStrict"),s=Os(e,"b","addStrict");return I(n.shape,s.shape,"Error in addStrict: "),aa(n,s)}}),Ph=Rs({divStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","div"),s=Os(e,"b","div");return I(n.shape,s.shape,"Error in divideStrict: "),Va(n,s)}}),Vh=Rs({maximumStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","maximumStrict"),s=Os(e,"b","maximumStrict");return I(n.shape,s.shape,"Error in maximumStrict: "),di(n,s)}}),Uh=Rs({minimumStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","minimumStrict"),s=Os(e,"b","minimumStrict");return I(n.shape,s.shape,"Error in minimumStrict: "),gi(n,s)}}),Hh=Rs({modStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","modStrict"),s=Os(e,"b","modStrict");return I(n.shape,s.shape,"Error in modStrict: "),Bh(n,s)}}),jh=Rs({mulStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","mul"),s=Os(e,"b","mul");return I(n.shape,s.shape,"Error in multiplyStrict: "),ii(n,s)}}),qh=Rs({powStrict_:function(t,e){return Jr("strict variants of ops have been deprecated and will be removed in future"),I(t.shape,e.shape,"Error in powStrict: "),el(t,e)}}),Gh=Rs({squaredDifferenceStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","squaredDifferenceStrict"),s=Os(e,"b","squaredDifferenceStrict");return I(n.shape,s.shape,"Error in squaredDifferenceStrict: "),ul(n,s)}}),Kh=Rs({subStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","subStrict"),s=Os(e,"b","subStrict");return I(n.shape,s.shape,"Error in subStrict: "),oi(n,s)}});ms.prototype.addStrict=function(t){return this.throwIfDisposed(),Wh(this,t)},ms.prototype.add=function(t){return this.throwIfDisposed(),aa(this,t)},ms.prototype.all=function(t,e){return this.throwIfDisposed(),ia(this,t,e)},ms.prototype.any=function(t,e){return this.throwIfDisposed(),oa(this,t,e)},ms.prototype.argMax=function(t){return this.throwIfDisposed(),la(this,t)};const Jh=Rs({argMin_:function(t,e=0){const n={x:Os(t,"x","argMin")},s={axis:e};return $s.runKernel(ot,n,s)}});ms.prototype.argMin=function(t){return this.throwIfDisposed(),Jh(this,t)},ms.prototype.asScalar=function(){return this.throwIfDisposed(),v(1===this.size,(()=>"The array must have only 1 element.")),Na(this,[])},ms.prototype.asType=function(t){return this.throwIfDisposed(),Ir(this,t)},ms.prototype.as1D=function(){return this.throwIfDisposed(),Na(this,[this.size])},ms.prototype.as2D=function(t,e){return this.throwIfDisposed(),Na(this,[t,e])},ms.prototype.as3D=function(t,e,n){return this.throwIfDisposed(),Na(this,[t,e,n])},ms.prototype.as4D=function(t,e,n,s){return this.throwIfDisposed(),Na(this,[t,e,n,s])},ms.prototype.as5D=function(t,e,n,s,r){return this.throwIfDisposed(),Na(this,[t,e,n,s,r])};const Zh=Rs({asin_:function(t){const e={x:Os(t,"x","asin")};return $s.runKernel(lt,e)}});ms.prototype.asin=function(){return this.throwIfDisposed(),Zh(this)};const Yh=Rs({asinh_:function(t){const e={x:Os(t,"x","asinh")};return $s.runKernel(ut,e)}});ms.prototype.asinh=function(){return this.throwIfDisposed(),Yh(this)};const Xh=Rs({atan_:function(t){const e={x:Os(t,"x","atan")};return $s.runKernel(ht,e)}});ms.prototype.atan=function(){return this.throwIfDisposed(),Xh(this)};const Qh=Rs({atan2_:function(t,e){let n=Os(t,"a","atan2"),s=Os(e,"b","atan2");[n,s]=Is(n,s);const r={a:n,b:s};return $s.runKernel(pt,r)}});ms.prototype.atan2=function(t){return this.throwIfDisposed(),Qh(this,t)};const tc=Rs({atanh_:function(t){const e={x:Os(t,"x","atanh")};return $s.runKernel(ct,e)}});ms.prototype.atanh=function(){return this.throwIfDisposed(),tc(this)},ms.prototype.avgPool=function(t,e,n,s){return this.throwIfDisposed(),va(this,t,e,n,s)},ms.prototype.batchToSpaceND=function(t,e){return this.throwIfDisposed(),_h(this,t,e)},ms.prototype.batchNorm=function(t,e,n,s,r){return this.throwIfDisposed(),Sa(this,t,e,n,s,r)},ms.prototype.broadcastTo=function(t){return this.throwIfDisposed(),io(this,t)},ms.prototype.cast=function(t){return this.throwIfDisposed(),Ir(this,t)};const ec=Rs({ceil_:function(t){const e={x:Os(t,"x","ceil")};return $s.runKernel(xt,e)}});ms.prototype.ceil=function(){return this.throwIfDisposed(),ec(this)},ms.prototype.clipByValue=function(t,e){return this.throwIfDisposed(),Da(this,t,e)},ms.prototype.concat=function(t,e){return this.throwIfDisposed(),t instanceof ms&&(t=[t]),$a([this,...t],e)},ms.prototype.conv1d=function(t,e,n,s,r,a){return this.throwIfDisposed(),Oa(this,t,e,n,s,r,a)},ms.prototype.conv2dTranspose=function(t,e,n,s,r){return this.throwIfDisposed(),Ra(this,t,e,n,s,r)},ms.prototype.conv2d=function(t,e,n,s,r,a){return this.throwIfDisposed(),Ca(this,t,e,n,s,r,a)},ms.prototype.cos=function(){return this.throwIfDisposed(),Th(this)},ms.prototype.cosh=function(){return this.throwIfDisposed(),Ah(this)},ms.prototype.cumsum=function(t,e,n){return this.throwIfDisposed(),gu(this,t,e,n)};const nc=Rs({depthToSpace_:function(t,e,n="NHWC"){const s=Os(t,"x","depthToSpace"),r="NHWC"===n?s.shape[1]:s.shape[2],a="NHWC"===n?s.shape[2]:s.shape[3],i="NHWC"===n?s.shape[3]:s.shape[1];v(r*e>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${r} and ${e}  for depthToSpace with input shape\n    ${s.shape}`)),v(a*e>=0,(()=>`Negative dimension size caused by overflow when multiplying\n    ${a} and ${e} for depthToSpace with input shape\n        ${s.shape}`)),v(i%(e*e)==0,(()=>`Dimension size must be evenly divisible by ${e*e} but is ${i} for depthToSpace with input shape ${s.shape}`));const o={x:s},l={blockSize:e,dataFormat:n};return $s.runKernel(Lt,o,l)}});ms.prototype.depthToSpace=function(t,e){return this.throwIfDisposed(),nc(this,t,e)},ms.prototype.depthwiseConv2D=function(t,e,n,s,r,a){return Jr("depthwiseConv2D is deprecated, use depthwiseConv2d instead"),this.throwIfDisposed(),Wa(this,t,e,n,s,r,a)},ms.prototype.depthwiseConv2d=function(t,e,n,s,r,a){return this.throwIfDisposed(),Wa(this,t,e,n,s,r,a)};const sc=Rs({dilation2d_:function(t,e,n,s,r=[1,1],a="NHWC"){const i=Os(t,"x","dilation2d"),o=Os(e,"filter","dilation2d");v(3===i.rank||4===i.rank,(()=>`Error in dilation2d: input must be rank 3 or 4, but got rank ${i.rank}.`)),v(3===o.rank,(()=>`Error in dilation2d: filter must be rank 3, but got rank ${o.rank}.`)),v("NHWC"===a,(()=>`Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${a}`));let l=i,u=!1;3===i.rank&&(l=Na(i,[1,i.shape[0],i.shape[1],i.shape[2]]),u=!0);const h={x:l,filter:o},c={strides:n,pad:s,dilations:r},p=$s.runKernel(Pt,h,c);return u?Na(p,[p.shape[1],p.shape[2],p.shape[3]]):p}});ms.prototype.dilation2d=function(t,e,n,s,r){return this.throwIfDisposed(),sc(this,t,e,n,s,r)};const rc=Rs({divNoNan_:function(t,e){let n=Os(t,"a","div"),s=Os(e,"b","div");[n,s]=Is(n,s);const r=Va(n,s),a=lo(r),i=Ga(s,a);return oo(i,a,r)}});ms.prototype.divNoNan=function(t){return this.throwIfDisposed(),rc(this,t)},ms.prototype.divStrict=function(t){return this.throwIfDisposed(),Ph(this,t)},ms.prototype.div=function(t){return this.throwIfDisposed(),Va(this,t)};const ac=Rs({dot_:function(t,e){const n=Os(t,"t1","dot"),s=Os(e,"t2","dot");v(!(1!==n.rank&&2!==n.rank||1!==s.rank&&2!==s.rank),(()=>`Error in dot: inputs must all be rank 1 or 2, but got ranks ${n.rank} and ${s.rank}.`));const r=1===n.rank?n.size:n.shape[1],a=1===s.rank?s.size:s.shape[0];if(v(r===a,(()=>`Error in dot: inner dimensions of inputs must match, but got ${r} and ${a}.`)),1===n.rank&&1===s.rank){const t=Na(n,[1,-1]),e=Na(s,[-1,1]),r=Do(t,e);return Na(r,[])}if(1===n.rank&&2===s.rank){const t=Na(n,[1,-1]),e=Na(s,[s.shape[0],s.shape[1]]),r=Do(t,e);return Na(r,[r.size])}if(2===n.rank&&1===s.rank){const t=Na(s,[-1,1]),e=Do(n,t);return Na(e,[e.size])}{const t=Na(s,[s.shape[0],s.shape[1]]);return Do(n,t)}}});ms.prototype.dot=function(t){return this.throwIfDisposed(),ac(this,t)},ms.prototype.elu=function(){return this.throwIfDisposed(),Ua(this)};const ic=Rs({equalStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","equalStrict"),s=Os(e,"b","equalStrict");return I(n.shape,s.shape,"Error in equalStrict: "),Ga(n,s)}}),oc=Rs({greaterEqualStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","greaterEqualStrict"),s=Os(e,"b","greaterEqualStrict");return I(n.shape,s.shape,"Error in greaterEqualStrict: "),ei(n,s)}}),lc=Rs({greaterStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","greaterStrict"),s=Os(e,"b","greaterStrict");return I(n.shape,s.shape,"Error in greaterStrict: "),ti(n,s)}}),uc=Rs({lessEqualStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","lessEqualStrict"),s=Os(e,"b","lessEqualStrict");return I(n.shape,s.shape,"Error in lessEqualStrict: "),Xo(n,s)}}),hc=Rs({lessStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","lessStrict"),s=Os(e,"b","lessStrict");return I(n.shape,s.shape,"Error in lessStrict: "),qu(n,s)}}),cc=Rs({notEqualStrict_:function(t,e){Jr("strict variants of ops have been deprecated and will be removed in future");const n=Os(t,"a","notEqualStrict"),s=Os(e,"b","notEqualStrict");return I(n.shape,s.shape,"Error in notEqualStrict: "),Ei(n,s)}});ms.prototype.equalStrict=function(t){return this.throwIfDisposed(),ic(this,t)},ms.prototype.equal=function(t){return this.throwIfDisposed(),Ga(this,t)};const pc=Rs({erf_:function(t){let e=Os(t,"x","erf");v("int32"===e.dtype||"float32"===e.dtype,(()=>"Input dtype must be `int32` or `float32`.")),"int32"===e.dtype&&(e=Ir(e,"float32"));const n={x:e};return $s.runKernel(Gt,n)}});ms.prototype.erf=function(){return this.throwIfDisposed(),pc(this)},ms.prototype.exp=function(){return this.throwIfDisposed(),ri(this)},ms.prototype.expandDims=function(t){return this.throwIfDisposed(),Ka(this,t)};const dc=Rs({expm1_:function(t){const e={x:Os(t,"x","expm1")};return $s.runKernel(Yt,e)}});ms.prototype.expm1=function(){return this.throwIfDisposed(),dc(this)},ms.prototype.fft=function(){return this.throwIfDisposed(),fo(this)},ms.prototype.flatten=function(){return this.throwIfDisposed(),Na(this,[this.size])},ms.prototype.floor=function(){return this.throwIfDisposed(),Xa(this)},ms.prototype.floorDiv=function(t){return this.throwIfDisposed(),Pa(this,t)},ms.prototype.gather=function(t,e){return this.throwIfDisposed(),Qa(this,t,e)},ms.prototype.greaterEqualStrict=function(t){return this.throwIfDisposed(),oc(this,t)},ms.prototype.greaterEqual=function(t){return this.throwIfDisposed(),ei(this,t)},ms.prototype.greaterStrict=function(t){return this.throwIfDisposed(),lc(this,t)},ms.prototype.greater=function(t){return this.throwIfDisposed(),ti(this,t)},ms.prototype.ifft=function(){return this.throwIfDisposed(),go(this)},ms.prototype.irfft=function(){return this.throwIfDisposed(),yo(this)};const fc=Rs({isFinite_:function(t){const e={x:Os(t,"x","isFinite")};return $s.runKernel(he,e)}});ms.prototype.isFinite=function(){return this.throwIfDisposed(),fc(this)};const mc=Rs({isInf_:function(t){const e={x:Os(t,"x","isInf")};return $s.runKernel(ce,e)}});ms.prototype.isInf=function(){return this.throwIfDisposed(),mc(this)};const gc=Rs({isNaN_:function(t){const e={x:Os(t,"x","isNaN")};return $s.runKernel(pe,e)}});ms.prototype.isNaN=function(){return this.throwIfDisposed(),gc(this)},ms.prototype.leakyRelu=function(t){return this.throwIfDisposed(),ni(this,t)},ms.prototype.lessEqualStrict=function(t){return this.throwIfDisposed(),uc(this,t)},ms.prototype.lessEqual=function(t){return this.throwIfDisposed(),Xo(this,t)},ms.prototype.lessStrict=function(t){return this.throwIfDisposed(),hc(this,t)},ms.prototype.less=function(t){return this.throwIfDisposed(),qu(this,t)};const yc=Rs({localResponseNormalization_:function(t,e=5,n=1,s=1,r=.5){const a=Os(t,"x","localResponseNormalization");v(4===a.rank||3===a.rank,(()=>`Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ${a.rank}.`)),v(D(e),(()=>`Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${e}.`));let i=a,o=!1;3===a.rank&&(o=!0,i=Na(a,[1,a.shape[0],a.shape[1],a.shape[2]]));const l={x:i},u={depthRadius:e,bias:n,alpha:s,beta:r},h=$s.runKernel(Ne,l,u);return o?Na(h,[h.shape[1],h.shape[2],h.shape[3]]):h}});ms.prototype.localResponseNormalization=function(t,e,n,s){return this.throwIfDisposed(),yc(this,t,e,n,s)};const bc=Rs({logSigmoid_:function(t){const e=Os(t,"x","logSigmoid");return ea((t=>({value:Ti(Zi(Ti(t))),gradFunc:e=>ii(e,Ui(Ti(t)))})))(e)}});ms.prototype.logSigmoid=function(){return this.throwIfDisposed(),bc(this)},ms.prototype.logSoftmax=function(t){return this.throwIfDisposed(),ui(this,t)},ms.prototype.logSumExp=function(t,e){return this.throwIfDisposed(),cl(this,t,e)},ms.prototype.log=function(){return this.throwIfDisposed(),si(this)},ms.prototype.log1p=function(){return this.throwIfDisposed(),hl(this)},ms.prototype.logicalAnd=function(t){return this.throwIfDisposed(),hi(this,t)},ms.prototype.logicalNot=function(){return this.throwIfDisposed(),xh(this)};const kc=Rs({logicalOr_:function(t,e){const n=Os(t,"a","logicalOr","bool"),s=Os(e,"b","logicalOr","bool");qa(n.shape,s.shape);const r={a:n,b:s};return $s.runKernel(xe,r)}});ms.prototype.logicalOr=function(t){return this.throwIfDisposed(),kc(this,t)};const wc=Rs({logicalXor_:function(t,e){const n=Os(t,"a","logicalXor","bool"),s=Os(e,"b","logicalXor","bool");return qa(n.shape,s.shape),hi(kc(t,e),xh(hi(t,e)))}});ms.prototype.logicalXor=function(t){return this.throwIfDisposed(),wc(this,t)},ms.prototype.matMul=function(t,e,n){return this.throwIfDisposed(),Do(this,t,e,n)},ms.prototype.maxPool=function(t,e,n,s){return this.throwIfDisposed(),ci(this,t,e,n,s)},ms.prototype.max=function(t,e){return this.throwIfDisposed(),ai(this,t,e)},ms.prototype.maximumStrict=function(t){return this.throwIfDisposed(),Vh(this,t)},ms.prototype.maximum=function(t){return this.throwIfDisposed(),di(this,t)},ms.prototype.mean=function(t,e){return this.throwIfDisposed(),fi(this,t,e)},ms.prototype.min=function(t,e){return this.throwIfDisposed(),mi(this,t,e)},ms.prototype.minimumStrict=function(t){return this.throwIfDisposed(),Uh(this,t)},ms.prototype.minimum=function(t){return this.throwIfDisposed(),gi(this,t)};const xc=Rs({mirrorPad_:function(t,e,n){v("reflect"===n||"symmetric"===n,(()=>`Invalid mode. Mode must be either reflect or symmetric. Got ${n}.`));const s=Os(t,"x","mirrorPad");if(0===s.rank)throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");v(e.length===s.rank,(()=>`Padding doesn't match input. Must be ${s.rank}. Got ${e.length}.`));const r="reflect"===n?1:0;for(let t=0;t<s.rank;t++)v(2===e[t].length,(()=>"Invalid number of paddings. Must be length of 2 each.")),v(e[t][0]>=0&&e[t][0]<=s.shape[t]-r&&e[t][1]>=0&&e[t][1]<=s.shape[t]-r,(()=>`Padding in dimension ${t} cannot be greater than or equal to ${s.shape[t]-r} or less than 0 for input of shape ${s.shape}`));const a={paddings:e,mode:n},i={x:s};return $s.runKernel(ze,i,a)}});ms.prototype.mirrorPad=function(t,e){return this.throwIfDisposed(),xc(this,t,e)},ms.prototype.modStrict=function(t){return this.throwIfDisposed(),Hh(this,t)},ms.prototype.mod=function(t){return this.throwIfDisposed(),Bh(this,t)},ms.prototype.mulStrict=function(t){return this.throwIfDisposed(),jh(this,t)},ms.prototype.mul=function(t){return this.throwIfDisposed(),ii(this,t)},ms.prototype.neg=function(){return this.throwIfDisposed(),Ti(this)},ms.prototype.norm=function(t,e,n){return this.throwIfDisposed(),sl(this,t,e,n)},ms.prototype.notEqualStrict=function(t){return this.throwIfDisposed(),cc(this,t)},ms.prototype.notEqual=function(t){return this.throwIfDisposed(),Ei(this,t)},ms.prototype.oneHot=function(t,e=1,n=0){return this.throwIfDisposed(),Ai(this,t,e,n)},ms.prototype.onesLike=function(){return this.throwIfDisposed(),Mi(this)},ms.prototype.pad=function(t,e){return this.throwIfDisposed(),Fi(this,t,e)};const Nc=Rs({pool_:function(t,e,n,s,r,a){null==r&&(r=[1,1]),null==a&&(a=1),0===s&&(s="valid");const i=Os(t,"x","maxPool");let o=i,l=!1;3===i.rank&&(l=!0,o=Na(i,[1,i.shape[0],i.shape[1],i.shape[2]])),v(wa(a,r),(()=>`Error in pool: Either strides or dilations must be 1. Got strides ${a} and dilations '${r}'`));const u=ha(o.shape,e,a,r,s),h=[u.dilationHeight,u.dilationWidth];let c;c="same"===s?function(t,e){const n=t.map(((t,n)=>t+(t-1)*(e[n]-1))).map((t=>t-1)),s=n.map((t=>Math.floor(t/2))),r=n.map(((t,e)=>t-s[e]));return n.map(((t,e)=>[s[e],r[e]]))}([u.filterHeight,u.filterWidth],h):[[0,0],[0,0]];const p=1===h[0]&&1===h[1],[d,f]=function(t,e,n){const s=n.map((t=>t[0])),r=n.map((t=>t[1])),a=t.concat(s,r),i=e.map(((t,e)=>(t-a[e]%t)%t)),o=r.map(((t,e)=>t+i[e]));return[e.map(((t,e)=>[s[e],o[e]])),e.map(((t,e)=>[0,i[e]]))]}([u.inHeight,u.inWidth],h,c),m=p?s:"valid",g=p?o:Ql(o,h,d),y=("avg"===n?()=>va(g,e,a,m):()=>ci(g,e,a,m))(),b=p?y:_h(y,h,f);return l?Na(b,[b.shape[1],b.shape[2],b.shape[3]]):b}});ms.prototype.pool=function(t,e,n,s,r){return this.throwIfDisposed(),Nc(this,t,e,n,s,r)},ms.prototype.powStrict=function(t){return this.throwIfDisposed(),qh(this,t)},ms.prototype.pow=function(t){return this.throwIfDisposed(),el(this,t)},ms.prototype.prelu=function(t){return this.throwIfDisposed(),_i(this,t)};const vc=Rs({prod_:function(t,e=null,n=!1){let s=Os(t,"x","prod");"bool"===s.dtype&&(s=Ir(s,"int32"));const r={x:s},a={axis:e,keepDims:n};return $s.runKernel(Je,r,a)}});ms.prototype.prod=function(t,e){return this.throwIfDisposed(),vc(this,t,e)};const Ic=Rs({reciprocal_:function(t){const e={x:Os(t,"x","reciprocal")};return $s.runKernel(Xe,e)}});ms.prototype.reciprocal=function(){return this.throwIfDisposed(),Ic(this)},ms.prototype.relu=function(){return this.throwIfDisposed(),Bi(this)},ms.prototype.relu6=function(){return this.throwIfDisposed(),ko(this)},ms.prototype.reshapeAs=function(t){return this.throwIfDisposed(),Na(this,t.shape)},ms.prototype.reshape=function(t){return this.throwIfDisposed(),Na(this,t)},ms.prototype.resizeBilinear=function(t,e,n){return this.throwIfDisposed(),Zo(this,t,e,n)},ms.prototype.resizeNearestNeighbor=function(t,e,n){return this.throwIfDisposed(),Yo(this,t,e,n)},ms.prototype.reverse=function(t){return this.throwIfDisposed(),Wi(this,t)},ms.prototype.rfft=function(){return this.throwIfDisposed(),mo(this)};const Sc=Rs({round_:function(t){const e={x:Os(t,"x","round")};return $s.runKernel(ln,e)}});ms.prototype.round=function(){return this.throwIfDisposed(),Sc(this)},ms.prototype.rsqrt=function(){return this.throwIfDisposed(),Eu(this)},ms.prototype.selu=function(){return this.throwIfDisposed(),Pi(this)},ms.prototype.separableConv2d=function(t,e,n,s,r,a){return this.throwIfDisposed(),Vi(this,t,e,n,s,r,a)},ms.prototype.sigmoid=function(){return this.throwIfDisposed(),Ui(this)};const Tc=Rs({sign_:function(t){const e={x:Os(t,"x","sign")};return $s.runKernel(gn,e)}});ms.prototype.sign=function(){return this.throwIfDisposed(),Tc(this)},ms.prototype.sin=function(){return this.throwIfDisposed(),pu(this)},ms.prototype.sinh=function(){return this.throwIfDisposed(),fu(this)},ms.prototype.slice=function(t,e){return this.throwIfDisposed(),Hi(this,t,e)},ms.prototype.softmax=function(t){return this.throwIfDisposed(),Ji(this,t)},ms.prototype.softplus=function(){return this.throwIfDisposed(),Zi(this)},ms.prototype.spaceToBatchND=function(t,e){return this.throwIfDisposed(),Ql(this,t,e)},ms.prototype.split=function(t,e){return this.throwIfDisposed(),Yi(this,t,e)},ms.prototype.sqrt=function(){return this.throwIfDisposed(),Xi(this)},ms.prototype.square=function(){return this.throwIfDisposed(),Ii(this)},ms.prototype.squaredDifference=function(t){return this.throwIfDisposed(),ul(this,t)},ms.prototype.squaredDifferenceStrict=function(t){return this.throwIfDisposed(),Gh(this,t)},ms.prototype.squeeze=function(t){return this.throwIfDisposed(),Qi(this,t)},ms.prototype.stack=function(t,e){this.throwIfDisposed();const n=t instanceof ms?[this,t]:[this,...t];return to(n,e)},ms.prototype.step=function(t){return this.throwIfDisposed(),wo(this,t)};const Ec=Rs({stridedSlice_:function(t,e,n,s,r=0,a=0,i=0,o=0,l=0){const u={x:Os(t,"x","stridedSlice")},h={begin:e,end:n,strides:s,beginMask:r,endMask:a,ellipsisMask:i,newAxisMask:o,shrinkAxisMask:l};return $s.runKernel(An,u,h)}});ms.prototype.stridedSlice=function(t,e,n,s,r,a,i,o){return this.throwIfDisposed(),Ec(this,t,e,n,s,r,a,i,o)},ms.prototype.subStrict=function(t){return this.throwIfDisposed(),Kh(this,t)},ms.prototype.sub=function(t){return this.throwIfDisposed(),oi(this,t)},ms.prototype.sum=function(t,e){return this.throwIfDisposed(),li(this,t,e)};const Ac=Rs({tan_:function(t){const e={x:Os(t,"x","tan")};return $s.runKernel(Dn,e)}});ms.prototype.tan=function(){return this.throwIfDisposed(),Ac(this)},ms.prototype.tanh=function(){return this.throwIfDisposed(),eo(this)},ms.prototype.tile=function(t){return this.throwIfDisposed(),Ja(this,t)},ms.prototype.toBool=function(){return this.throwIfDisposed(),Ir(this,"bool")},ms.prototype.toFloat=function(){return this.throwIfDisposed(),Ir(this,"float32")},ms.prototype.toInt=function(){return this.throwIfDisposed(),Ir(this,"int32")};const Dc=Rs({topk_:function(t,e=1,n=!0){const s=Os(t,"x","topk");if(0===s.rank)throw new Error("topk() expects the input to be of rank 1 or higher");const r=s.shape[s.shape.length-1];if(e>r)throw new Error(`'k' passed to topk() must be <= the last dimension (${r}) but got ${e}`);const a={x:s},i={k:e,sorted:n},[o,l]=$s.runKernel(Fn,a,i);return{values:o,indices:l}}});ms.prototype.topk=function(t,e){return this.throwIfDisposed(),Dc(this,t,e)},ms.prototype.transpose=function(t){return this.throwIfDisposed(),uo(this,t)};const $c=Rs({unique_:function(t,e=0){const n=Os(t,"x","unique","string_or_numeric");v(n.rank>0,(()=>"The input tensor must be at least 1D"));const s={x:n},r={axis:e},[a,i]=$s.runKernel(zn,s,r);return{values:a,indices:i}}});let Mc;function Fc(){return null==Mc&&(Mc=$s.backend.epsilon()),Mc}ms.prototype.unique=function(t){return this.throwIfDisposed(),$c(this,t)},ms.prototype.unsortedSegmentSum=function(t,e){return this.throwIfDisposed(),Du(this,t,e)},ms.prototype.unstack=function(t){return this.throwIfDisposed(),ao(this,t)},ms.prototype.where=function(t,e){return this.throwIfDisposed(),oo(t,this,e)},ms.prototype.zerosLike=function(){return this.throwIfDisposed(),lo(this)};class _c extends Error{constructor(t){super(t),Object.setPrototypeOf(this,_c.prototype)}}class zc extends Error{constructor(t){super(t),Object.setPrototypeOf(this,zc.prototype)}}class Cc extends Error{constructor(t){super(t),Object.setPrototypeOf(this,Cc.prototype)}}class Oc extends Error{constructor(t){super(t),Object.setPrototypeOf(this,Oc.prototype)}}class Lc extends Error{constructor(t){super(t),Object.setPrototypeOf(this,Lc.prototype)}}function Rc(t,e){if(Array.isArray(t)){let n=[];for(let s=0;s<e;s++)n=n.concat(t);return n}{const n=new Array(e);return n.fill(t),n}}function Bc(t,e){if(!t)throw new Lc(e)}function Wc(t,e){let n=0;for(const s of t)s===e&&n++;return n}function Pc(t){return 1===t.length?t[0]:t}function Vc(t){return Array.isArray(t)?t:[t]}function Uc(t){const e=t.replace(/(.)([A-Z][a-z0-9]+)/g,"$1_$2").replace(/([a-z])([A-Z])/g,"$1_$2").toLowerCase();return"_"!==e[0]?e:"private"+e}function Hc(t){return t.length<=1||-1===t.indexOf("_")?t:t.replace(/[_]+(\w|$)/g,((t,e)=>e.toUpperCase()))}Error;let jc={};function qc(t){if(null==t)return null;const e={};return e.className=t.getClassName(),e.config=t.getConfig(),e}function Gc(t){if(null!=t&&"object"==typeof t)if(Array.isArray(t))t.forEach((t=>Gc(t)));else{const e=Object.keys(t);for(const n of e){const e=t[n];null!=e&&"object"==typeof e&&(Array.isArray(e)||"ndarray"!==e.type||"number"!=typeof e.value?Gc(e):t[n]=e.value)}}}function Kc(t,e={},n={},s="object",r=!1){if("string"==typeof t){const r=t;let a;if(r in n)a=n[r];else if(r in jc)a=jc[r];else if(a=e[r],null==a)throw new Cc(`Unknown ${s}: ${t}. This may be due to one of the following reasons:\n1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);return a}{const a=t;if(null==a.className||null==a.config)throw new Cc(`${s}: Improper config format: ${JSON.stringify(a)}.\n'className' and 'config' must set.`);const i=a.className;let o,l;if(i in n?[o,l]=n[i]:i in jc?[o,l]=jc.className:i in e&&([o,l]=e[i]),null==o)throw new Cc(`Unknown ${s}: ${i}. This may be due to one of the following reasons:\n1. The ${s} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${s} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);if(null!=l){const t={};for(const e of Object.keys(jc))t[e]=jc[e];for(const e of Object.keys(n))t[e]=n[e];a.config.customObjects=t;const e=Object.assign({},jc);for(const t of Object.keys(n))jc[t]=n[t];Gc(a.config);const s=l(o,a.config,n,r);return jc=Object.assign({},e),s}{const t=Object.assign({},jc);for(const t of Object.keys(n))jc[t]=n[t];const e=new o(a.config);return jc=Object.assign({},t),e}}}function Jc(t,e){return-1*function(t,e){return t<e?-1:t>e?1:0}(t,e)}function Zc(t){if(null==t)return t;const e=[];for(const n of t)-1===e.indexOf(n)&&e.push(n);return e}function Yc(t){if(null==t)throw new Cc(`Invalid value in obj: ${JSON.stringify(t)}`);for(const e in t)if(t.hasOwnProperty(e))return!1;return!0}function Xc(t,e,n){if(null!=n&&t.indexOf(n)<0)throw new Cc(`${n} is not a valid ${e}.  Valid values are ${t} or null/undefined.`)}function Qc(t,e,n=0,s=1/0){return Bc(n>=0),Bc(s>=n),Array.isArray(t)&&t.length>=n&&t.length<=s&&t.every((t=>typeof t===e))}function tp(t,e){Array.isArray(t)?(v(t.length>0,(()=>`${e} is unexpectedly an empty array.`)),t.forEach(((t,n)=>tp(t,`element ${n+1} of ${e}`)))):v(Number.isInteger(t)&&t>0,(()=>`Expected ${e} to be a positive integer, but got ${ep(t)}.`))}function ep(t){return null===t?"null":Array.isArray(t)?"["+t.map((t=>ep(t))).join(",")+"]":"string"==typeof t?`"${t}"`:`${t}`}function np(t){return"relu"===t?"relu":"linear"===t?"linear":"elu"===t?"elu":null}function sp(t,e){return Xr((()=>Xi(li(ii(t,t),e,!0))))}class rp extends qr{getConfig(){return{}}}class ap extends rp{constructor(t){super(),this.defaultMaxValue=2,this.defaultAxis=0,this.maxValue=null!=t.maxValue?t.maxValue:this.defaultMaxValue,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return Xr((()=>{const e=sp(t,this.axis),n=Da(e,0,this.maxValue);return ii(t,Va(n,aa(Fc(),e)))}))}getConfig(){return{maxValue:this.maxValue,axis:this.axis}}}ap.className="MaxNorm",Kr(ap);class ip extends rp{constructor(t){super(),this.defaultAxis=0,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return Xr((()=>Va(t,aa(Fc(),sp(t,this.axis)))))}getConfig(){return{axis:this.axis}}}ip.className="UnitNorm",Kr(ip);class op extends rp{apply(t){return Bi(t)}}op.className="NonNeg",Kr(op);class lp extends rp{constructor(t){super(),this.defaultMinValue=0,this.defaultMaxValue=1,this.defaultRate=1,this.defaultAxis=0,this.minValue=null!=t.minValue?t.minValue:this.defaultMinValue,this.maxValue=null!=t.maxValue?t.maxValue:this.defaultMaxValue,this.rate=null!=t.rate?t.rate:this.defaultRate,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return Xr((()=>{const e=sp(t,this.axis),n=aa(ii(this.rate,Da(e,this.minValue,this.maxValue)),ii(1-this.rate,e));return ii(t,Va(n,aa(Fc(),e)))}))}getConfig(){return{minValue:this.minValue,maxValue:this.maxValue,rate:this.rate,axis:this.axis}}}lp.className="MinMaxNorm",Kr(lp);const up={maxNorm:"MaxNorm",minMaxNorm:"MinMaxNorm",nonNeg:"NonNeg",unitNorm:"UnitNorm"};function hp(t){return qc(t)}function cp(t,e={}){return Kc(t,Gr.getMap().classNameMap,e,"constraint")}function pp(t){return null==t?null:"string"==typeof t?cp({className:t in up?up[t]:t,config:{}}):t instanceof rp?t:cp(t)}const dp=["channelsFirst","channelsLast"],fp=["nearest","bilinear"],mp=["valid","same","causal"],gp=["max","avg"],yp=["sum","mul","concat","ave"],bp=new Map;function kp(t){Xc(dp,"DataFormat",t)}function wp(t){Xc(mp,"PaddingMode",t)}function xp(t){Xc(gp,"PoolMode",t)}const Np=[];function vp(t,e){Np.push(t);try{const t=e();return Np.pop(),t}catch(t){throw Np.pop(),t}}function Ip(t){if(!Ep(t))throw new Error("Not a valid tensor name: '"+t+"'");return(0===Np.length?"":Np.join("/")+"/")+t}function Sp(t){if(!Ep(t))throw new Error("Not a valid tensor name: '"+t+"'");bp.has(t)||bp.set(t,0);const e=bp.get(t);if(bp.set(t,bp.get(t)+1),e>0){const n=`${t}_${e}`;return bp.set(n,1),n}return t}const Tp=new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);function Ep(t){return!!t.match(Tp)}function Ap(t,e,n){null==e&&(e=0),null==n&&(n=t.length);let s=1;for(let r=e;r<n;++r)s*=t[r];return s}function Dp(t){return no(t=Array.isArray(t)?new Float32Array(t):t)}function $p(t){return mi(Dp(t)).dataSync()[0]}function Mp(t){return ai(Dp(t)).dataSync()[0]}function Fp(t,e){if(e<t)throw new Cc(`end (${e}) < begin (${t}) is forbidden.`);const n=[];for(let s=t;s<e;++s)n.push(s);return n}function _p(t,e){return t.asType(e)}function zp(t,e=-1){const n=t.shape.slice();return e<0&&(e=n.length+e+1),n.splice(e,0,1),t.reshape(n)}function Cp(t,e,n){return Xr((()=>{switch(t.rank){case 1:return ji(t,e,n);case 2:return qi(t,[e,0],[n,t.shape[1]]);case 3:return Gi(t,[e,0,0],[n,t.shape[1],t.shape[2]]);case 4:return Ki(t,[e,0,0,0],[n,t.shape[1],t.shape[2],t.shape[3]]);case 5:return Hi(t,[e,0,0,0,0],[n,t.shape[1],t.shape[2],t.shape[3],t.shape[4]]);case 6:return Hi(t,[e,0,0,0,0,0],[n,t.shape[1],t.shape[2],t.shape[3],t.shape[4],t.shape[5]]);default:throw new Cc(`sliceAlongFirstAxis() received an unsupported tensor rank: ${t.rank}`)}}))}function Op(t,e,n){return Xr((()=>{switch(t.rank){case 1:return ji(t,e,n);case 2:return qi(t,[0,e],[t.shape[0],n]);case 3:return Gi(t,[0,0,e],[t.shape[0],t.shape[1],n]);case 4:return Ki(t,[0,0,0,e],[t.shape[0],t.shape[1],t.shape[2],n]);default:throw new Cc(`sliceAlongLastAxis() received an unsupported tensor rank: ${t.rank}`)}}))}function Lp(t,e,n,s){return Xr((()=>{switch(t.rank){case 1:return ji(t,e,n);case 2:switch(s){case 1:return Cp(t,e,n);case 2:return Op(t,e,n);default:throw new Cc(`The axis is not within the rank of the tensor ${s}`)}case 3:switch(s){case 1:return Cp(t,e,n);case 2:return Gi(t,[0,e,0],[t.shape[0],n,t.shape[2]]);case 3:return Op(t,e,n);default:throw new Cc(`The axis is not within the rank of the tensor ${s}`)}case 4:switch(s){case 1:return Cp(t,e,n);case 2:return Ki(t,[0,e,0,0],[t.shape[0],n,t.shape[2],t.shape[3]]);case 3:return Ki(t,[0,0,e,0],[t.shape[0],t.shape[1],n,t.shape[3]]);case 4:return Op(t,e,n);default:throw new Cc(`The axis is not within the rank of the tensor ${s}`)}default:throw new Cc(`sliceAlongLastAxis() received an unsupported tensor rank: ${t.rank}`)}}))}function Rp(t,e=-1){let n;return e<0&&(n=t[0].rank,e=0!==n?n:0),e===t[0].rank&&(e=-1),$a(t,e)}function Bp(t,e){switch(t.rank){case 1:return Ma([t,e]);case 2:return Fa([t,e],0);case 3:return _a([t,e],0);case 4:return za([t,e],0);default:throw new Cc(`concatAlongFirstAxis() received an unsupported tensor rank: ${t.rank}`)}}function Wp(t,e){if(Array.isArray(e)||(e=[e]),t.rank!==e.length)throw new Cc(`The length of input n (${e.length}) does not match the number of dimensions in input x (${t.rank})`);return Ja(t,e)}function Pp(t,e=0,n=1,s,r){return Li(t,e,n,s,r)}function Vp(t,e,n,s){if(t.rank<2||e.rank<2)throw new Oc(`dot requires both inputs to be rank >= 2 but got x shape = ${t.shape} and y shape = ${e.shape}`);if(e.rank>=3&&t.shape.slice(-1)[0]!==e.shape.slice(-2)[0])throw new Oc(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${t.shape} and  y shape = ${e.shape}`);if(2===t.rank&&2===e.rank)return $o({a:t,b:e,transposeA:!1,transposeB:!1,bias:s?jp(t.rank,s,"channelsLast"):null,activation:n});{const r=t.shape.slice(),a=r.pop();t=t.reshape([-1,a]);const i=e.shape.slice(),o=i.pop(),l=i.pop(),u=[...i,o],h=Array.from({length:e.rank},((t,n)=>0===n?e.rank-2:n<=e.rank-2?n-1:n));e=e.transpose(h).reshape([l,-1]);const c=[...r,...u];return $o({a:t,b:e,transposeA:!1,transposeB:!1,bias:s?jp(t.rank,s,"channelsLast"):null,activation:n}).reshape(c)}}function Up(t,e,n){return Xr((()=>(e=Array.isArray(e)?no(e,"int32"):e.toInt(),Qa(t,e,n))))}function Hp(t){return ii(t,t)}function jp(t,e,n){const s=e.shape;if(1!==e.rank&&e.rank!==t)throw new Cc(`Unexpected bias dimensions: ${e.rank}; expected it to be 1 or ${t}`);if(5===t){if("channelsFirst"===n)return 1===s.length?e.reshape([1,s[0],1,1,1]):e.reshape([1,s[3],s[0],s[1],s[2]]);if("channelsLast"===n)return 1===s.length?e.reshape([1,1,1,1,s[0]]):e.reshape([1].concat(s))}else if(4===t){if("channelsFirst"===n)return 1===s.length?e.reshape([1,s[0],1,1]):e.reshape([1,s[2],s[0],s[1]]);if("channelsLast"===n)return 1===s.length?e.reshape([1,1,1,s[0]]):e.reshape([1].concat(s))}else if(3===t){if("channelsFirst"===n)return 1===s.length?e.reshape([1,s[0],1]):e.reshape([1,s[1],s[0]]);if("channelsLast"===n)return 1===s.length?e.reshape([1,1,s[0]]):e.reshape([1].concat(s))}else if(t<3)return e;throw new Cc(`Unsupported input rank by biasAdd: ${e.rank}`)}function qp(t,e,n){return Xr((()=>(null==n&&(n="channelsLast"),kp(n),t.add(jp(t.rank,e,n)))))}function Gp(t,e,n,s){return Xr((()=>ho(t,e,n,s)))}function Kp(t,e,n=!1){return n?t():e()}const Jp=["fanIn","fanOut","fanAvg"],Zp=["normal","uniform","truncatedNormal"];class Yp extends qr{fromConfigUsesCustomObjects(){return!1}getConfig(){return{}}}class Xp extends Yp{apply(t,e){return Di(t,e)}}Xp.className="Zeros",Kr(Xp);class Qp extends Yp{apply(t,e){return $i(t,e)}}Qp.className="Ones",Kr(Qp);class td extends Yp{constructor(t){if(super(),"object"!=typeof t)throw new Cc(`Expected argument of type ConstantConfig but got ${t}`);if(void 0===t.value)throw new Cc(`config must have value set but got ${t}`);this.value=t.value}apply(t,e){return Xr((()=>ii(na(this.value),$i(t,e))))}getConfig(){return{value:this.value}}}td.className="Constant",Kr(td);class ed extends Yp{constructor(t){super(),this.DEFAULT_MINVAL=-.05,this.DEFAULT_MAXVAL=.05,this.minval=t.minval||this.DEFAULT_MINVAL,this.maxval=t.maxval||this.DEFAULT_MAXVAL,this.seed=t.seed}apply(t,e){return Ri(t,this.minval,this.maxval,e)}getConfig(){return{minval:this.minval,maxval:this.maxval,seed:this.seed}}}ed.className="RandomUniform",Kr(ed);class nd extends Yp{constructor(t){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=t.mean||this.DEFAULT_MEAN,this.stddev=t.stddev||this.DEFAULT_STDDEV,this.seed=t.seed}apply(t,e){if("float32"!==(e=e||"float32")&&"int32"!==e)throw new Oc(`randomNormal does not support dType ${e}.`);return Pp(t,this.mean,this.stddev,e,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}nd.className="RandomNormal",Kr(nd);class sd extends Yp{constructor(t){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=t.mean||this.DEFAULT_MEAN,this.stddev=t.stddev||this.DEFAULT_STDDEV,this.seed=t.seed}apply(t,e){if("float32"!==(e=e||"float32")&&"int32"!==e)throw new Oc(`truncatedNormal does not support dType ${e}.`);return ro(t,this.mean,this.stddev,e,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}sd.className="TruncatedNormal",Kr(sd);class rd extends Yp{constructor(t){super(),this.gain=null!=t.gain?t.gain:1}apply(t,e){return Xr((()=>{if(2!==t.length||t[0]!==t[1])throw new Cc("Identity matrix initializer can only be used for 2D square matrices.");return ii(this.gain,Za(t[0]))}))}getConfig(){return{gain:this.gain}}}rd.className="Identity",Kr(rd);class ad extends Yp{constructor(t){if(super(),t.scale<0)throw new Cc(`scale must be a positive float. Got: ${t.scale}`);var e;this.scale=null==t.scale?1:t.scale,this.mode=null==t.mode?"fanIn":t.mode,e=this.mode,Xc(Jp,"FanMode",e),this.distribution=null==t.distribution?"normal":t.distribution,function(t){Xc(Zp,"Distribution",t)}(this.distribution),this.seed=t.seed}apply(t,e){const n=function(t,e="channelsLast"){let n,s;if(kp(e),2===t.length)n=t[0],s=t[1];else if(-1!==[3,4,5].indexOf(t.length)){if("channelsFirst"===e){const e=Ap(t,2);n=t[1]*e,s=t[0]*e}else if("channelsLast"===e){const e=Ap(t,0,t.length-2);n=t[t.length-2]*e,s=t[t.length-1]*e}}else{const e=Ap(t);n=Math.sqrt(e),s=Math.sqrt(e)}return[n,s]}(t),s=n[0],r=n[1];let a=this.scale;if("fanIn"===this.mode?a/=Math.max(1,s):"fanOut"===this.mode?a/=Math.max(1,r):a/=Math.max(1,(s+r)/2),"normal"===this.distribution){const n=Math.sqrt(a);if("float32"!==(e=e||"float32")&&"int32"!==e)throw new Oc(`${this.getClassName()} does not support dType ${e}.`);return ro(t,0,n,e,this.seed)}{const n=Math.sqrt(3*a);return Ri(t,-n,n,e)}}getConfig(){return{scale:this.scale,mode:this.mode,distribution:this.distribution,seed:this.seed}}}ad.className="VarianceScaling",Kr(ad);class id extends ad{constructor(t){super({scale:1,mode:"fanAvg",distribution:"uniform",seed:null==t?null:t.seed})}getClassName(){return ad.className}}id.className="GlorotUniform",Kr(id);class od extends ad{constructor(t){super({scale:1,mode:"fanAvg",distribution:"normal",seed:null==t?null:t.seed})}getClassName(){return ad.className}}od.className="GlorotNormal",Kr(od);class ld extends ad{constructor(t){super({scale:2,mode:"fanIn",distribution:"normal",seed:null==t?null:t.seed})}getClassName(){return ad.className}}ld.className="HeNormal",Kr(ld);class ud extends ad{constructor(t){super({scale:2,mode:"fanIn",distribution:"uniform",seed:null==t?null:t.seed})}getClassName(){return ad.className}}ud.className="HeUniform",Kr(ud);class hd extends ad{constructor(t){super({scale:1,mode:"fanIn",distribution:"normal",seed:null==t?null:t.seed})}getClassName(){return ad.className}}hd.className="LeCunNormal",Kr(hd);class cd extends ad{constructor(t){super({scale:1,mode:"fanIn",distribution:"uniform",seed:null==t?null:t.seed})}getClassName(){return ad.className}}cd.className="LeCunNormal",Kr(cd);class pd extends Yp{constructor(t){if(super(),this.DEFAULT_GAIN=1,this.gain=null==t.gain?this.DEFAULT_GAIN:t.gain,this.seed=t.seed,null!=this.seed)throw new Oc("Random seed is not implemented for Orthogonal Initializer yet.")}apply(t,e){return Xr((()=>{if(t.length<2)throw new Oc("Shape must be at least 2D.");t[0]*t[1]>2e3&&console.warn(`Orthogonal initializer is being called on a matrix with more than 2000 (${t[0]*t[1]}) elements: Slowness may result.`);const e=Pp(t[0]>t[1]?[t[1],t[0]]:t,0,1,"float32");let n=dl.gramSchmidt(e);return t[0]>t[1]&&(n=n.transpose()),ii(this.gain,n)}))}getConfig(){return{gain:this.gain,seed:this.seed}}}pd.className="Orthogonal",Kr(pd);const dd={constant:"Constant",glorotNormal:"GlorotNormal",glorotUniform:"GlorotUniform",heNormal:"HeNormal",heUniform:"HeUniform",identity:"Identity",leCunNormal:"LeCunNormal",leCunUniform:"LeCunUniform",ones:"Ones",orthogonal:"Orthogonal",randomNormal:"RandomNormal",randomUniform:"RandomUniform",truncatedNormal:"TruncatedNormal",varianceScaling:"VarianceScaling",zeros:"Zeros"};function fd(t,e={}){return Kc(t,Gr.getMap().classNameMap,e,"initializer")}function md(t){return qc(t)}function gd(t){if("string"==typeof t){const e=t in dd?dd[t]:t;if("GlorotNormal"===e)return new od;if("GlorotUniform"===e)return new id;if("HeNormal"===e)return new ld;if("HeUniform"===e)return new ud;if("LeCunNormal"===e)return new hd;if("LeCunUniform"===e)return new cd;{const t={};return t.className=e,t.config={},fd(t)}}return t instanceof Yp?t:fd(t)}let yd=0;function bd(){return yd++}const kd={};function wd(t=""){return t in kd||(kd[t]=0),kd[t]+=1,t+kd[t].toString()}function xd(t){return Array.isArray(t)&&Array.isArray(t[0])}function Nd(t){return 0===t.length?[]:Array.isArray(t[0])?t:[t]}function vd(t){let e;if(Array.isArray(t)){if(1!==t.length)throw new Cc(`Expected Tensor length to be 1; got ${t.length}`);e=t[0]}else e=t;return e}function Id(t){if(Array.isArray(t)&&Array.isArray(t[0])){if(1===t.length)return(t=t)[0];throw new Cc(`Expected exactly 1 Shape; got ${t.length}`)}return t}function Sd(t){let e=0;for(const n of t)0===n.shape.length?e+=1:e+=n.shape.reduce(((t,e)=>t*e));return e}class Td{constructor(t,e="float32",n="Variable",s=!0,r=null){this.dtype=null==e?"float32":e,this.shape=t.shape,this.id=bd(),n=null==n?"Variable":n,this.originalName=Ip(n),this.name=Sp(this.originalName),this.trainable_=s,this.constraint=r,this.val=function(t,e=!0,n,s){return $s.makeVariable(t,e,n,s)}(t,this.trainable_,this.name,this.dtype)}read(){return this.assertNotDisposed(),this.val}write(t){return this.assertNotDisposed(),function(t,e){if(t.shape.toString()!==e.shape.toString())throw new Error("Shape mismatch: "+JSON.stringify(t.shape)+" vs. "+JSON.stringify(e.shape))}(this.val,t),this.val.id!==t.id&&(this.val.assign(t),null!=this.constraint&&this.val.assign(this.constraint.apply(this.val))),this}dispose(){this.assertNotDisposed(),this.val.dispose()}assertNotDisposed(){if(this.val.isDisposed)throw new Error(`LayersVariable ${this.name} is already disposed.`)}get trainable(){return this.trainable_}set trainable(t){this.trainable_=t,this.val.trainable=t}}function Ed(t){return t.map((t=>t.read()))}function Ad(t){t.forEach((t=>{t[0].write(t[1])}))}class Dd{constructor(t){this.dtype=t.dtype,this.shape=t.shape,null!=t.shape?this.ndim=t.shape.length:this.ndim=t.ndim,this.maxNDim=t.maxNDim,this.minNDim=t.minNDim,this.axes=t.axes||{}}}class $d{constructor(t,e,n,s,r,a,i){this.dtype=t,this.shape=e,this.sourceLayer=n,this.inputs=s,this.callArgs=r,this.outputTensorIndex=i,this.id=bd(),null!=a&&(this.originalName=Ip(a),this.name=Sp(this.originalName)),this.rank=e.length}}let Md=0;class Fd{constructor(t,e){this.callArgs=e,this.id=Md++,this.outboundLayer=t.outboundLayer,this.inboundLayers=t.inboundLayers,this.nodeIndices=t.nodeIndices,this.tensorIndices=t.tensorIndices,this.inputTensors=t.inputTensors,this.outputTensors=t.outputTensors,this.inputMasks=t.inputMasks,this.outputMasks=t.outputMasks,this.inputShapes=t.inputShapes,this.outputShapes=t.outputShapes;for(const e of t.inboundLayers)null!=e&&e.outboundNodes.push(this);t.outboundLayer.inboundNodes.push(this)}getConfig(){const t=[];for(const e of this.inboundLayers)null!=e?t.push(e.name):t.push(null);return{outboundLayer:this.outboundLayer?this.outboundLayer.name:null,inboundLayers:t,nodeIndices:this.nodeIndices,tensorIndices:this.tensorIndices}}}let _d=0;class zd extends qr{constructor(t={}){super(),this._callHook=null,this._addedWeightNames=[],this._stateful=!1,this.id=_d++,this.activityRegularizer=null,this.inputSpec=null,this.supportsMasking=!1,this._trainableWeights=[],this._nonTrainableWeights=[],this._losses=[],this._updates=[],this._built=!1,this.inboundNodes=[],this.outboundNodes=[];let e=t.name;if(!e){const t=this.getClassName();e=Uc(t)+"_"+wd(t)}if(this.name=e,this.trainable_=null==t.trainable||t.trainable,null!=t.inputShape||null!=t.batchInputShape){let e;if(null!=t.batchInputShape)e=t.batchInputShape;else if(null!=t.inputShape){let n=null;null!=t.batchSize&&(n=t.batchSize),e=[n].concat(t.inputShape)}this.batchInputShape=e;let n=t.dtype;null==n&&(n=t.inputDType),null==n&&(n="float32"),this.dtype=n}null!=t.weights?this.initialWeights=t.weights:this.initialWeights=null,this._refCount=null,this.fastWeightInitDuringBuild=!1}static nodeKey(t,e){return t.name+"_ib-"+e.toString()}getNodeAtIndex(t,e){if(0===this.inboundNodes.length)throw new zc(`The layer has never been called and thus has no defined ${e}.`);if(this.inboundNodes.length<=t)throw new Cc(`Asked to get ${e} at node ${t}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);return this.inboundNodes[t]}getInputAt(t){return Pc(this.getNodeAtIndex(t,"input").inputTensors)}getOutputAt(t){return Pc(this.getNodeAtIndex(t,"output").outputTensors)}get input(){if(this.inboundNodes.length>1)throw new _c(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);if(0===this.inboundNodes.length)throw new _c(`Layer ${this.name} is not connected, no input to return.`);return Pc(this.getNodeAtIndex(0,"input").inputTensors)}get output(){if(0===this.inboundNodes.length)throw new _c(`Layer ${this.name} has no inbound nodes.`);if(this.inboundNodes.length>1)throw new _c(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);return Pc(this.getNodeAtIndex(0,"output").outputTensors)}get losses(){return this._losses}calculateLosses(){return this.losses.map((t=>t()))}get updates(){return this._updates}get built(){return this._built}set built(t){this._built=t}get trainable(){return this.trainable_}set trainable(t){this._trainableWeights.forEach((e=>e.trainable=t)),this.trainable_=t}get trainableWeights(){return this.trainable_?this._trainableWeights.filter((t=>t.trainable)):[]}set trainableWeights(t){this._trainableWeights=t}get nonTrainableWeights(){return this.trainable?this._trainableWeights.filter((t=>!t.trainable)).concat(this._nonTrainableWeights):this._trainableWeights.concat(this._nonTrainableWeights)}set nonTrainableWeights(t){this._nonTrainableWeights=t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}get stateful(){return this._stateful}resetStates(){if(!this.stateful)throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.")}assertInputCompatibility(t){if(t=Vc(t),null==this.inputSpec||0===this.inputSpec.length)return;const e=Vc(this.inputSpec);if(t.length!==e.length)throw new Cc(`Layer ${this.name} expects ${e.length} inputs, but it received ${t.length} input tensors. Input received: ${t}`);for(let n=0;n<t.length;n++){const s=t[n],r=e[n];if(null==r)continue;const a=s.rank;if(null!=r.ndim&&a!==r.ndim)throw new Cc(`Input ${n} is incompatible with layer ${this.name}: expected ndim=${r.ndim}, found ndim=${a}`);if(null!=r.maxNDim&&a>r.maxNDim)throw new Cc(`Input ${n} is incompatible with layer ${this.name}: expected max_ndim=${r.maxNDim}, found ndim=${a}`);if(null!=r.minNDim&&a<r.minNDim)throw new Cc(`Input ${n} is incompatible with layer ${this.name}: expected min_ndim=${r.minNDim}, found ndim=${a}.`);if(null!=r.dtype&&s.dtype!==r.dtype)throw new Cc(`Input ${n} is incompatible with layer ${this.name} : expected dtype=${r.dtype}, found dtype=${s.dtype}.`);if(r.axes){const t=s.shape;for(const e in r.axes){const s=Number(e),a=r.axes[e],i=s>=0?t[s]:t[t.length+s];if(null!=a&&-1===[a,null].indexOf(i))throw new Cc(`Input ${n} is incompatible with layer ${this.name}: expected axis ${s} of input shape to have value ${a} but got shape ${t}.`)}}if(null!=r.shape)for(let t=0;t<r.shape.length;++t){const e=r.shape[t],a=s.shape[t];if(null!=e&&null!=a&&e!==a)throw new Cc(`Input ${n} is incompatible with layer ${this.name}: expected shape=${r.shape}, found shape=${s.shape}.`)}}}call(t,e){return t}invokeCallHook(t,e){null!=this._callHook&&this._callHook(t,e)}setCallHook(t){this._callHook=t}clearCallHook(){this._callHook=null}apply(t,e){e=e||{},this.assertNotDisposed();const n=Vc(t);let s=!0;for(const t of n)if(!(t instanceof $d)){s=!1;break}let r=!0;for(const t of n)if(t instanceof $d){r=!1;break}if(s===r)throw new Cc("Arguments to apply() must be all SymbolicTensors or all Tensors");return vp(this.name,(()=>{if(!this.built){this.assertInputCompatibility(t);const e=[];for(const n of Vc(t))e.push(n.shape);this.build(Pc(e)),this.built=!0,this.initialWeights&&this.setWeights(this.initialWeights),null===this._refCount&&r&&(this._refCount=1)}if(this.assertInputCompatibility(t),r){let s=this.call(t,e);const r=Vc(s),a=[];for(let t of r)-1!==n.indexOf(t)&&(t=t.clone()),a.push(t);if(s=Pc(a),null!=this.activityRegularizer)throw new Oc("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return s}{const n=function(t){t=Vc(t);const e=[];for(const n of t)e.push(n.shape);return Pc(e)}(t),s=this.computeOutputShape(n);let r;const a="float32";if(this.warnOnIncompatibleInputShape(Array.isArray(t)?n[0]:n),r=null!=s&&s.length>0&&Array.isArray(s[0])?s.map(((n,s)=>new $d(a,n,this,Vc(t),e,this.name,s))):new $d(a,s,this,Vc(t),e,this.name),this.addInboundNode(t,r,null,null,n,s,e),this._refCount++,null!=this.activityRegularizer)throw new Oc("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return r}}))}warnOnIncompatibleInputShape(t){if(null!=this.batchInputShape)if(t.length!==this.batchInputShape.length)console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(t)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);else{let e=!1;this.batchInputShape.forEach(((n,s)=>{null!=n&&null!=t[s]&&t[s]!==n&&(e=!0)})),e&&console.warn(`The shape of the input tensor (${JSON.stringify(t)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`)}}get outputShape(){if(null==this.inboundNodes||0===this.inboundNodes.length)throw new _c(`The layer ${this.name} has never been called and thus has no defined output shape.`);const t=[];for(const e of this.inboundNodes){const n=JSON.stringify(e.outputShapes);-1===t.indexOf(n)&&t.push(n)}if(1===t.length){const t=this.inboundNodes[0].outputShapes;return Array.isArray(t)&&Array.isArray(t[0])&&1===t.length?t[0]:t}throw new _c(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`)}countParams(){if(!this.built)throw new zc(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);return Sd(this.weights)}build(t){this.built=!0}getWeights(t=!1){return Ed(t?this.trainableWeights:this.weights)}setWeights(t){Xr((()=>{const e=this.weights;if(e.length!==t.length)throw new Cc(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${t.length}, but the layer was expecting ${e.length} weights. Provided weights: ${t}...`);if(0===e.length)return;const n=[],s=Ed(e);for(let r=0;r<s.length;++r){const a=s[r],i=e[r],o=t[r];if(!A(a.shape,o.shape))throw new Cc(`Layer weight shape ${a.shape} not compatible with provided weight shape ${o.shape}`);n.push([i,o])}Ad(n)}))}addWeight(t,e,n,s,r,a,i){if(-1!==this._addedWeightNames.indexOf(t))throw new Cc(`Duplicate weight name ${t} for layer ${this.name}`);this._addedWeightNames.push(t),null==n&&(n="float32"),this.fastWeightInitDuringBuild&&(s=gd("zeros"));const o=s.apply(e,n),l=new Td(o,n,t,a,i);return o.dispose(),null!=r&&this.addLoss((()=>r.apply(l.read()))),null==a&&(a=!0),a?this._trainableWeights.push(l):this._nonTrainableWeights.push(l),l}setFastWeightInitDuringBuild(t){this.fastWeightInitDuringBuild=t}addLoss(t){null==t||Array.isArray(t)&&0===t.length||(t=Vc(t),void 0!==this._losses&&null!==this._losses&&this.losses.push(...t))}computeOutputShape(t){return t}computeMask(t,e){if(!this.supportsMasking){if(null!=e){if(!Array.isArray(e))throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);e.forEach((t=>{if(null!=t)throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`)}))}return null}return e}addInboundNode(t,e,n,s,r,a,i=null){const o=Vc(t);e=Vc(e),n=Vc(n),s=Vc(s),r=Nd(r),a=Nd(a);const l=[],u=[],h=[];for(const t of o)l.push(t.sourceLayer),u.push(t.nodeIndex),h.push(t.tensorIndex);new Fd({outboundLayer:this,inboundLayers:l,nodeIndices:u,tensorIndices:h,inputTensors:o,outputTensors:e,inputMasks:n,outputMasks:s,inputShapes:r,outputShapes:a},i);for(let t=0;t<e.length;t++)e[t].sourceLayer=this,e[t].nodeIndex=this.inboundNodes.length-1,e[t].tensorIndex=t}getConfig(){const t={name:this.name,trainable:this.trainable};return null!=this.batchInputShape&&(t.batchInputShape=this.batchInputShape),null!=this.dtype&&(t.dtype=this.dtype),t}disposeWeights(){return this.weights.forEach((t=>t.dispose())),this.weights.length}assertNotDisposed(){if(0===this._refCount)throw new Error(`Layer '${this.name}' is already disposed.`)}dispose(){if(!this.built)throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);if(null===this._refCount)throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);this.assertNotDisposed();let t=0;return 0==--this._refCount&&(t=this.disposeWeights()),{refCountAfterDispose:this._refCount,numDisposedVariables:t}}}function Cd(t,e,n){if((null==e||null!=n&&n>0)&&(e=t.sourceLayer,n=t.nodeIndex),0===e.inboundNodes.length)return[t];{const t=e.inboundNodes[n];if(0===t.inboundLayers.length)return t.inputTensors;{const e=[];for(let n=0;n<t.inboundLayers.length;n++){const s=Cd(t.inputTensors[n],t.inboundLayers[n],t.nodeIndices[n]);for(const t of s)-1===e.indexOf(t)&&e.push(t)}return e}}}class Od extends zd{constructor(t){if(super({dtype:t.dtype,name:null!=t.name?t.name:wd("input").toString()}),null==t.batchSize&&(t.batchSize=null),null==t.sparse&&(t.sparse=!1),this.trainable=!1,this.built=!0,this.sparse=t.sparse,null!=t.inputShape&&null!=t.batchInputShape)throw new Cc("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");let e=t.batchInputShape;if(null==e){if(null==t.inputShape)throw new Cc("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");e=[t.batchSize].concat(t.inputShape)}else if(null!=t.batchSize)throw new Cc("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");const n=t.dtype||"float32";this.batchInputShape=e,this.dtype=n,this.inputSpec=[{shape:e}];const s=new $d(this.dtype,this.batchInputShape,this,[],{},this.name);s.nodeIndex=0,s.tensorIndex=0,new Fd({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:[s],outputTensors:[s],inputMasks:[null],outputMasks:[null],inputShapes:[e],outputShapes:[e]})}apply(t,e){throw new Cc(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`)}dispose(){return{refCountAfterDispose:this._refCount,numDisposedVariables:0}}getConfig(){return{batchInputShape:this.batchInputShape,dtype:this.dtype,sparse:this.sparse,name:this.name}}}async function Ld(t){if(null==t)return;const e=[],n=[],s=[];for(const r in t){const a=t[r];if("number"!=typeof a){const t=a;e.push(t.data()),n.push(r),s.push(t)}}if(e.length>0){const r=await Promise.all(e);for(let e=0;e<r.length;++e)t[n[e]]=r[e][0];Qr(s)}}function Rd(t){if(null!=t)for(const e in t){const n=t[e];"number"!=typeof n&&n.dispose()}}var Bd;Od.className="InputLayer",Kr(Od),function(t){t[t.SILENT=0]="SILENT",t[t.VERBOSE=1]="VERBOSE"}(Bd||(Bd={}));class Wd{constructor(){this.validationData=null}setParams(t){this.params=t}async onEpochBegin(t,e){}async onEpochEnd(t,e){}async onBatchBegin(t,e){}async onBatchEnd(t,e){}async onTrainBegin(t){}async onTrainEnd(t){}setModel(t){}}class Pd{constructor(t,e=10){null==t&&(t=[]),this.callbacks=t,this.queueLength=e}append(t){this.callbacks.push(t)}setParams(t){for(const e of this.callbacks)e.setParams(t)}setModel(t){for(const e of this.callbacks)e.setModel(t)}async onEpochBegin(t,e){null==e&&(e={});for(const n of this.callbacks)await n.onEpochBegin(t,e)}async onEpochEnd(t,e){null==e&&(e={});for(const n of this.callbacks)await n.onEpochEnd(t,e)}async onBatchBegin(t,e){null==e&&(e={});for(const n of this.callbacks)await n.onBatchBegin(t,e)}async onBatchEnd(t,e){null==e&&(e={});for(const n of this.callbacks)await n.onBatchEnd(t,e)}async onTrainBegin(t){null==t&&(t={});for(const e of this.callbacks)await e.onTrainBegin(t)}async onTrainEnd(t){null==t&&(t={});for(const e of this.callbacks)await e.onTrainEnd(t)}}class Vd extends Wd{constructor(){super()}async onEpochBegin(t){this.seen=0,this.totals={}}async onBatchEnd(t,e){null==e&&(e={});const n=null==e.size?0:e.size;this.seen+=n;for(const t in e){const s=e[t];if("number"==typeof s)this.totals.hasOwnProperty(t)||(this.totals[t]=0),this.totals[t]=this.totals[t]+s*n;else{let e;t in this.totals?e=this.totals[t]:this.totals[t]=0;const r=Xr((()=>aa(this.totals[t],ii(s,n))));this.totals[t]=r,null!=e&&e.dispose()}}}async onEpochEnd(t,e){if(null!=e)for(const t of this.params.metrics)null!=this.totals[t]&&("number"==typeof this.totals[t]?e[t]=this.totals[t]/this.seen:Xr((()=>{const n=ii(Va(1,this.seen),this.totals[t]);e[t]=n,this.totals[t].dispose(),ta(e[t])})))}}class Ud extends Wd{async onTrainBegin(t){this.epoch=[],this.history={}}async onEpochEnd(t,e){null==e&&(e={}),this.epoch.push(t);for(const t in e)null==this.history[t]&&(this.history[t]=[]),this.history[t].push(e[t])}async syncData(){const t=[],e=[],n=[];for(const s in this.history){const r=this.history[s];for(let a=0;a<r.length;++a)if("number"!=typeof r[a]){const i=r[a];t.push(i.data()),e.push(s),n.push(a)}}const s=await Promise.all(t);for(let t=0;t<s.length;++t)this.history[e[t]][n[t]].dispose(),this.history[e[t]][n[t]]=s[t][0]}}class Hd extends Wd{constructor(t,e){if(super(),this.currentEpoch=0,this.yieldEvery=e||"auto","auto"===this.yieldEvery&&(this.yieldEvery=125),"never"===this.yieldEvery&&null!=t.onYield)throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");O(this.yieldEvery)&&(this.maybeWait=function(t,e){let n,s=ls();return(...r)=>{const a=ls();return a-s<e||(s=a,n=t(...r)),n}}(this.maybeWait.bind(this),this.yieldEvery)),this.trainBegin=t.onTrainBegin,this.trainEnd=t.onTrainEnd,this.epochBegin=t.onEpochBegin,this.epochEnd=t.onEpochEnd,this.batchBegin=t.onBatchBegin,this.batchEnd=t.onBatchEnd,this.yield=t.onYield}async maybeWait(t,e,n){const s=[];null!=this.yield&&(await Ld(n),s.push(this.yield(t,e,n))),s.push(Il()),await Promise.all(s)}async onEpochBegin(t,e){this.currentEpoch=t,null!=this.epochBegin&&(await Ld(e),await this.epochBegin(t,e))}async onEpochEnd(t,e){const n=[];null!=this.epochEnd&&(await Ld(e),n.push(this.epochEnd(t,e))),"epoch"===this.yieldEvery&&n.push(Il()),await Promise.all(n)}async onBatchBegin(t,e){null!=this.batchBegin&&(await Ld(e),await this.batchBegin(t,e))}async onBatchEnd(t,e){const n=[];null!=this.batchEnd&&(await Ld(e),n.push(this.batchEnd(t,e))),"batch"===this.yieldEvery?n.push(Il()):O(this.yieldEvery)&&n.push(this.maybeWait(this.currentEpoch,t,e)),await Promise.all(n)}async onTrainBegin(t){null!=this.trainBegin&&(await Ld(t),await this.trainBegin(t))}async onTrainEnd(t){null!=this.trainEnd&&(await Ld(t),await this.trainEnd(t))}}function jd(t,e){return null==t&&(t={}),t instanceof Wd?[t]:Array.isArray(t)&&t[0]instanceof Wd?t:Vc(t).map((t=>new Hd(t,e)))}class qd{constructor(){}static registerCallbackConstructor(t,e){v(t>=0&&Number.isInteger(t),(()=>`Verbosity level is expected to be an integer >= 0, but got ${t}`)),qd.checkForDuplicate(e),null==qd.constructors[t]&&(qd.constructors[t]=[]),qd.constructors[t].push(e)}static checkForDuplicate(t){for(const e in qd.constructors)qd.constructors[+e].forEach((e=>{if(e===t)throw new Cc("Duplicate callback constructor.")}))}static clear(){qd.constructors={}}static createCallbacks(t){const e=[];for(const n in qd.constructors){const s=+n;t>=s&&e.push(...qd.constructors[s])}return e.map((t=>new t))}}function Gd(t,e,n,s,r,a,i,o,l){const u=new Ud,h=[new Vd,...qd.createCallbacks(e)];null!=t&&h.push(...t),h.push(u);const c=new Pd(h);return c.setParams({epochs:n,initialEpoch:s,samples:r,steps:a,batchSize:i,verbose:e,doValidation:o,metrics:l}),{callbackList:c,history:u}}function Kd(t,e={},n=!1){return Kc(t,Gr.getMap().classNameMap,e,"layer",n)}function Jd(t,e){return Xr((()=>{"float32"!==t.dtype&&(t=t.asType("float32"));const n=li(Hp(t),e,!0),s=Ya(n.shape,Fc()),r=Xi(di(n,s));return Va(t,r)}))}function Zd(t,e){return Xr((()=>fi(Hp(oi(e,t)),-1)))}function Yd(t,e){return Xr((()=>fi(ra(oi(e,t)),-1)))}function Xd(t,e){return Xr((()=>{const n=oi(t,e),s=Da(ra(t),Fc(),Number.MAX_VALUE),r=ra(Va(n,s));return ii(100,fi(r,-1))}))}function Qd(t,e,n=!1){return Xr((()=>{if(n)e=Ji(e);else{const t=li(e,e.shape.length-1,!0);e=Va(e,t)}return e=Da(e,Fc(),1-Fc()),Ti(li(ii(t.toFloat(),si(e)),e.shape.length-1))}))}function tf(t,e,n=!1){return Xr((()=>{const s=Xa(function(t){const e=[Ap(t.shape)];return t.reshape(e)}(t)).toInt(),r=(e=Da(e,Fc(),1-Fc())).shape;return Qd(Ai(s,r[r.length-1]).reshape(r),e,n)}))}function ef(t,e){return Xr((()=>{let n;return n=Da(e,Fc(),1-Fc()),n=si(Va(n,oi(1,n))),fi(function(t,e){if(!A(t.shape,e.shape))throw new Cc(`logits and labels must have the same shape, but got shapes ${JSON.stringify(t.shape)} and ${JSON.stringify(e.shape)}`);return Xr((()=>{const n=e.relu(),s=e.abs().neg();return n.sub(e.mul(t)).add(s.exp().log1p())}))}(t,n),-1)}))}function nf(t,e){return Xr((()=>{const n=Jd(t,-1),s=Jd(e,-1),r=ii(n,s);return Ti(li(r,-1))}))}qd.constructors={};const sf={meanSquaredError:Zd,meanAbsoluteError:Yd,meanAbsolutePercentageError:Xd,meanSquaredLogarithmicError:function(t,e){return Xr((()=>{const n=Da(e,Fc(),Number.MAX_VALUE),s=si(aa(1,n)),r=Da(t,Fc(),Number.MAX_VALUE),a=si(aa(1,r));return fi(Hp(oi(s,a)),-1)}))},squaredHinge:function(t,e){return Xr((()=>{const n=di(0,oi(1,ii(t,e)));return fi(Hp(n),-1)}))},hinge:function(t,e){return Xr((()=>{const n=di(0,oi(1,ii(t,e)));return fi(n,-1)}))},categoricalHinge:function(t,e){return Xr((()=>{const n=li(ii(t,e),-1),s=ai(ii(oi(1,t),e),-1);return di(0,aa(1,oi(s,n)))}))},logcosh:function(t,e){return Xr((()=>{const n=Math.log(2),s=oi(e,t),r=oi(aa(s,Zi(ii(-2,s))),n);return fi(r,-1)}))},categoricalCrossentropy:Qd,sparseCategoricalCrossentropy:tf,binaryCrossentropy:ef,kullbackLeiblerDivergence:function(t,e){return Xr((()=>{const n=Da(t,Fc(),1),s=Da(e,Fc(),1);return li(ii(t,si(Va(n,s))),-1)}))},poisson:function(t,e){return Xr((()=>{const n=si(aa(Fc(),e));return fi(oi(e,ii(t,n)),-1)}))},cosineProximity:nf};function rf(t){if("string"==typeof t){if(t in sf)return sf[t];let e=`Unknown loss ${t}`;throw t.toLowerCase().includes("softmaxcrossentropy")&&(e=`Unknown loss ${t}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`),new Cc(e)}return t}function af(t,e){return Xr((()=>{const n=ii(.5,Mi(e)),s=_p(ti(e,n),t.dtype);return fi(Ga(t,s),-1)}))}function of(t,e){return Xr((()=>_p(Ga(la(t,-1),la(e,-1)),"float32")))}function lf(t,e){return ef(t,e)}function uf(t,e){return t.rank===e.rank&&(t=t.squeeze([t.rank-1])),(e=e.argMax(-1)).dtype!==t.dtype&&(e=e.asType(t.dtype)),Ga(t,e).asType("float32")}const hf=Qd,cf=tf,pf={binaryAccuracy:af,categoricalAccuracy:of,precision:function(t,e){return Xr((()=>{const n=function(t,e){return Xr((()=>hi(t.equal(1),e.equal(1)).sum().cast("float32")))}(t,e),s=function(t,e){return Xr((()=>hi(t.equal(0),e.equal(1)).sum().cast("float32")))}(t,e),r=n.add(s);return oo(ti(r,0),n.div(r),0).cast("float32")}))},categoricalCrossentropy:hf,sparseCategoricalCrossentropy:cf,mse:Zd,MSE:Zd,mae:Yd,MAE:Yd,mape:Xd,MAPE:Xd,cosine:nf};function df(t){if("string"==typeof t&&t in pf)return pf[t];if("string"!=typeof t&&null!=t)return t;throw new Cc(`Unknown metric ${t}`)}function ff(t){if(Bc(null!==t,`Unknown LossOrMetricFn ${t}`),"string"==typeof t)return t;{let e;for(const n of Object.keys(sf))if(sf[n]===t){e=n;break}if(void 0!==e)return e;for(const n of Object.keys(pf))if(pf[n]===t){e=n;break}return void 0!==e?e:t.name}}function mf(t,e,n=!1){if(null==t||"object"!=typeof t||Object.getPrototypeOf(t)!==Object.prototype||!gf(t))throw new Error("User-defined metadata is expected to be a JSON object, but is not.");if(n){const n=JSON.stringify(t);n.length>1048576&&console.warn(`User-defined metadata of model "${e}" is too large in size (length=${n.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= 1048576.`)}}function gf(t){if(null===t)return!0;if("object"==typeof t){if(Object.getPrototypeOf(t)===Object.prototype){const e=Object.keys(t);for(const n of e){if("string"!=typeof n)return!1;if(!gf(t[n]))return!1}return!0}if(Array.isArray(t)){for(const e of t)if(!gf(e))return!1;return!0}return!1}{const e=typeof t;return"string"===e||"number"===e||"boolean"===e}}function yf(t,e,n=console.log){let s="";for(let n=0;n<t.length;++n)n>0&&(s=s.slice(0,s.length-1)+" "),s+=t[n],s=s.slice(0,e[n]),s+=" ".repeat(e[n]-s.length);n(s)}function bf(t,e,n){let s;try{s=JSON.stringify(t.outputShape)}catch(t){s="multiple"}yf([`${t.name} (${t.getClassName()})`,s,t.countParams().toString()],e,n)}function kf(t,e,n,s){let r;try{r=JSON.stringify(t.outputShape)}catch(t){r="multiple"}const a=[];for(const e of t.inboundNodes)if(!(null!=n&&n.length>0&&-1===n.indexOf(e)))for(let t=0;t<e.inboundLayers.length;++t){const n=e.inboundLayers[t].name,s=e.nodeIndices[t],r=e.tensorIndices[t];a.push(`${n}[${s}][${r}]`)}const i=t.name,o=t.getClassName(),l=0===a.length?"":a[0];yf([`${i} (${o})`,r,t.countParams().toString(),l],e,s);for(let t=1;t<a.length;++t)yf(["","","",a[t]],e,s)}function wf(t,e,n){return("inboundNodes"===t||"outputLayers"===t||"inputLayers"===t)&&0===e&&"string"==typeof n}function xf(t,e){if(null===t)return null;if("string"==typeof t)return Hc(t);if("number"==typeof t||"boolean"==typeof t)return t;if(t instanceof Array){const n=[],s=t.length;for(let r=0;r<s;++r){const s=t[r];wf(e,r,s)?n.push(s):n.push(xf(s,e))}return n}{const e={};for(const n of Object.keys(t)){const s=t[n];if("name"===n&&"string"==typeof s)e[n]=s;else{const t=Hc(n);e[t]=xf(s,t)}}return e}}function Nf(t,e){if(null==t)return null;if("string"==typeof t)return Uc(t);if("number"==typeof t||"boolean"==typeof t)return t;if(t instanceof Array){const n=[],s=t.length;for(let r=0;r<s;++r){const s=t[r];wf(e,r,s)?n.push(s):n.push(Nf(s,e))}return n}{const e={};for(const n of Object.keys(t)){const s=t[n];e[Uc(n)]="name"!==n&&"className"!==n||"string"!=typeof s?Nf(s,n):s}return e}}class vf{constructor(t){if(this.id2Value={},this.id2Mask={},this.name2Id={},t instanceof vf)for(const e in t.id2Value)this.id2Value[e]=t.id2Value[e],e in t.id2Mask&&(this.id2Mask[e]=t.id2Mask[e]);else{if(null==t)return;for(const e of t)this.add(e.key,e.value)}}add(t,e,n){if(null!=this.id2Value[t.id])throw new Cc(`Duplicate key: name=${t.name}, id=${t.id}`);return this.id2Value[t.id]=function(t,e){if(null==t.dtype||t.dtype===e.dtype)return e;try{return Ir(e,t.dtype)}catch(n){throw new Cc(`The dtype of the feed (${e.dtype}) can not be cast to the dtype of the key '${t.name}' (${t.dtype}).`)}}(t,e),this.name2Id[t.name]=t.id,null!=n&&(this.id2Mask[t.id]=n),this}addFeed(t){this.add(t.key,t.value)}hasKey(t){return null!=this.id2Value[t.id]}names(){return Object.keys(this.name2Id)}getValue(t){if(t instanceof $d){if(null==this.id2Value[t.id])throw new Cc(`Nonexistent key: ${t.name}`);return this.id2Value[t.id]}{const e=this.name2Id[t];if(null==e)throw new Cc(`Feed dict has no SymbolicTensor name: ${t}`);return this.id2Value[e]}}getMask(t){if(t instanceof $d){if(null==this.id2Value[t.id])throw new Cc(`Nonexistent key: ${t.name}`);return this.id2Mask[t.id]}{const e=this.name2Id[t];if(null==e)throw new Cc(`Feed dict has no SymbolicTensor name: ${t}`);return this.id2Mask[e]}}disposeMasks(){null!=this.id2Mask&&Qr(this.id2Mask)}}const If={},Sf={};function Tf(t,e,n,s){const r=null!=n&&n.training,a=Array.isArray(t),i=a?t:[t],o=i.map((t=>t.name)),l=[],u=e.names();for(const t of o)-1!==u.indexOf(t)?l.push(e.getValue(t)):l.push(null);null!=s&&(s.maxNumTensors=-1/0,s.minNumTensors=1/0);const h=o.join(",")+"|"+e.names().join(",");let c,p;if(null==If[h]){const t=function(t,e){v(null!=t&&t.length>0,(()=>"Expected at least one fetch, got none"));let n=[],s={};if(1===t.length){const r=Af(t[0],e);n=r.sorted,s=r.recipientMap}else{const r=new Set;for(const a of t){const{sorted:t,recipientMap:i}=Af(a,e);for(const e of t)r.has(e.name)||(n.push(e),r.add(e.name));for(const t in i)null==s[t]&&(s[t]=new Set),i[t].forEach((e=>s[t].add(e)))}}return{sorted:n,recipientCounts:Ef(s)}}(i,e);c=t.sorted,p=t.recipientCounts,If[h]=c,Sf[h]=p}c=If[h],p={},r||Object.assign(p,Sf[h]);const d=new vf(e);for(let t=0;t<c.length;++t){if(null!=s){const t=Yr().numTensors;t>s.maxNumTensors&&(s.maxNumTensors=t),t<s.minNumTensors&&(s.minNumTensors=t)}const a=c[t],i=a.sourceLayer;if(i instanceof Od)continue;const u=[],h=[],f=[];let m=!1;for(const t of a.inputs){const n=d.getValue(t),s=d.getMask(t);u.push(n),h.push(s),null!=s&&(m=!0),r||(p[t.name]--,0!==p[t.name]||e.hasKey(t)||-1!==o.indexOf(t.name)||n.isDisposed||!0===t.sourceLayer.stateful||f.push(n))}m&&((n=n||{}).mask=h[0]);const g=Vc(i.apply(u,n));let y=null;i.supportsMasking&&(y=i.computeMask(u,h));const b=Df(a),k=Array.isArray(b)?b:[b];for(let t=0;t<k.length;++t){d.hasKey(k[t])||d.add(k[t],g[t],Array.isArray(y)?y[0]:y);const e=o.indexOf(k[t].name);-1!==e&&(l[e]=g[t])}r||Qr(f)}return d.disposeMasks(),a?l:l[0]}function Ef(t){const e={};for(const n in t)e[n]=t[n].size;return e}function Af(t,e){const n=new Set,s=[],r={};for(const t of e.names())n.add(t);const a=[],i=[];for(a.push(t);a.length>0;){const t=a[a.length-1];if(n.has(t.name)){a.pop();continue}const e=i[i.length-1]===a.length-1;if(0===t.inputs.length||e)a.pop(),s.push(t),n.add(t.name),e&&i.pop();else{i.push(a.length-1);for(const e of t.inputs)null==r[e.name]&&(r[e.name]=new Set),r[e.name].add(t.name),n.has(e.name)||a.push(e)}}return{sorted:s,recipientMap:r}}function Df(t){let e;if(1===t.sourceLayer.inboundNodes.length)e=t.sourceLayer.output;else{let n=null;for(let e=0;e<t.sourceLayer.inboundNodes.length;++e)for(const s of t.sourceLayer.inboundNodes[e].outputTensors)if(s.id===t.id){n=e;break}e=t.sourceLayer.getOutputAt(n)}return e}class $f extends zd{constructor(t){if(super({}),this.containerNodes=new Set,this.name=t.name,null==this.name){const t=this.getClassName().toLowerCase();this.name=wd(t)}if(this.supportsMasking=!1,this.trainable_=!0,Array.isArray(t.inputs)?this.inputs=t.inputs.slice():this.inputs=[t.inputs],Array.isArray(t.outputs)?this.outputs=t.outputs.slice():this.outputs=[t.outputs],Zc(this.inputs).length!==this.inputs.length)throw new Cc(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map((t=>t.name))}`);Zc(this.outputs).length!==this.outputs.length&&console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map((t=>t.name))}`),this.inputLayers=[],this.inputLayersNodeIndices=[],this.inputLayersTensorIndices=[],this.outputLayers=[],this.outputLayersNodeIndices=[],this.outputLayersTensorIndices=[],this.layers=[],this.internalContainerRefs=[];for(const t of this.outputs){const e=t.sourceLayer,n=t.nodeIndex,s=t.tensorIndex;this.outputLayers.push(e),this.outputLayersNodeIndices.push(n),this.outputLayersTensorIndices.push(s)}for(const t of this.inputs){const e=t.sourceLayer,n=t.nodeIndex,s=t.tensorIndex;Bc(0===n,"input layer has >1 nodes"),Bc(0===s,"input layer has >1 tensors"),this.inputLayers.push(e),this.inputLayersNodeIndices.push(n),this.inputLayersTensorIndices.push(s)}this.inputNames=[],this.outputNames=[],this.feedInputShapes=[],this.feedInputNames=[],this.feedOutputNames=[];for(let e=0;e<this.inputLayers.length;e++){const n=this.inputLayers[e];if(!(n instanceof Od))throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${t.inputs}. Input ${e} (0-based) originates from layer type ${n.getClassName()}.`);this.inputNames.push(n.name),this.feedInputShapes.push(n.batchInputShape),this.feedInputNames.push(n.name)}for(const t of this.outputLayers)this.outputNames.push(t.name);this.internalInputShapes=this.inputs.map((t=>t.shape)),this.internalOutputShapes=this.outputs.map((t=>t.shape));const e={},n={},s={},r={},a={},i=[],o=(t,e,n,s,r,l)=>{null!=s&&null!=r&&null!=l||(s=t.sourceLayer,r=t.nodeIndex,l=t.tensorIndex);const u=s.inboundNodes[r];if(-1!==n.indexOf(u))throw new zc(`The tensor ${t.name} at layer "${s.name}" is part of a cycle.`);if(-1!==e.indexOf(u))return;this.containerNodes.add($f.nodeKey(s,r)),s.id in a||(a[s.id]=Object.keys(a).length),-1===n.indexOf(u)&&n.push(u);const h=u.inboundLayers.length;for(let t=0;t<h;t++){const s=u.inputTensors[t],r=u.inboundLayers[t],a=u.nodeIndices[t],i=u.tensorIndices[t];o(s,e,n,r,a,i)}for(e.push(u);n.indexOf(u)>=0;)n.splice(n.indexOf(u),1);i.push(u)},l=[],u=[];for(const t of this.outputs)o(t,l,u);const h=i.slice().reverse();for(const t of h){n[t.id]=t,t.id in e||(e[t.id]=0);let a=e[t.id];const i=null==s[t.outboundLayer.id]?0:s[t.outboundLayer.id];a=Math.max(a,i),s[t.outboundLayer.id]=a,r[t.outboundLayer.id]=t.outboundLayer,e[t.id]=a;for(let s=0;s<t.inboundLayers.length;s++){const r=t.inboundLayers[s],i=t.nodeIndices[s],o=r.inboundNodes[i],l=null==e[o.id]?0:e[o.id];e[o.id]=Math.max(a+1,l),n[o.id]=o}}const c={};for(const t in e){const s=e[t];s in c||(c[s]=[]),c[s].push(n[t])}const p={};for(const t in s){const e=s[t];e in p||(p[e]=[]),p[e].push(r[t])}let d=Object.keys(p).map((t=>parseInt(t,10))).sort(Jc);this.layers=[];for(const t of d){const e=p[t];e.sort(((t,e)=>{const n=a[t.id],s=a[e.id];return n<s?-1:n>s?1:0}));for(const t of e)t instanceof $f&&this.internalContainerRefs.push(t),this.layers.push(t)}this.layersByDepth=p,d=Object.keys(c).map((t=>parseInt(t,10))).sort(Jc);const f=this.inputs.slice(),m=[];for(const t of d)for(const e of c[t]){const t=e.outboundLayer;if(null!=t){for(const n of e.inputTensors)if(-1===f.indexOf(n))throw new zc(`Graph disconnected: cannot obtain value for tensor ${n} at layer "${t.name}". The following previous layers were accessed without issue: ${m}`);for(const t of e.outputTensors)f.push(t);m.push(t.name)}}this.nodesByDepth=c;const g=this.layers.map((t=>t.name));for(const t of g){const e=g.filter((e=>e===t)).length;if(1!==e)throw new zc(`The name "${t}" is used ${e} times in the model. All layer names should be unique. Layer names: `+JSON.stringify(g))}this.outboundNodes=[],this.inboundNodes=[],new Fd({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:this.inputs.map((t=>null)),outputMasks:this.outputs.map((t=>null)),inputShapes:this.inputs.map((t=>t.shape)),outputShapes:this.outputs.map((t=>t.shape))}),this.built=!0,this._refCount=1}assertNotDisposed(){if(0===this._refCount)throw new Error(`Container '${this.name}' is already disposed.`)}dispose(){this.assertNotDisposed();const t={refCountAfterDispose:null,numDisposedVariables:0};if(0==--this._refCount){for(const e of this.layers)t.numDisposedVariables+=e.dispose().numDisposedVariables;for(const e of this.internalContainerRefs)t.numDisposedVariables+=e.dispose().numDisposedVariables}return t.refCountAfterDispose=this._refCount,t}get trainable(){return this.trainable_}set trainable(t){this.layers.forEach((e=>{e._trainableWeights.forEach((e=>e.trainable=t))})),this.trainable_=t}get trainableWeights(){if(this._trainableWeights.length>0)throw new Cc("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");if(!this.trainable)return[];let t=[];for(const e of this.layers)t=t.concat(e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.layers)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const t of this.layers)e.push(...t.trainableWeights);return e.concat(t)}return t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}loadWeights(t,e=!0){const n={};let s=0;for(const t of this.layers)for(const e of t.weights){if(null!=n[e.originalName])throw new Cc(`Duplicate weight name: ${e.originalName}`);n[e.originalName]=e,s++}const r=[];for(const s in t){let a=s;if(null==n[s]){const t=s.split("/");a=t.slice(0,-2).concat([t[t.length-1]]).join("/")}if(null!=n[a])r.push([n[a],t[s]]);else if(e)throw new Cc(`Provided weight data has no target variable: ${s}`);delete n[a]}if(e){const t=[];for(const e in n)t.push(e);if(t.length>0)throw new Cc(`${t.length} of ${s} weights are not set: ${t}`)}Ad(r)}updatedConfig(){const t=this.getConfig(),e={};return e.className=this.getClassName(),e.config=t,e.kerasVersion="tfjs-layers 2.8.3",e.backend="TensorFlow.js",e}toJSON(t,e=!0){const n=Nf(this.updatedConfig());return e?JSON.stringify(n):n}call(t,e){return Xr((()=>{t=Vc(t);const n=new vf;for(let e=0;e<this.inputs.length;++e)n.add(this.inputs[e],t[e]);return Tf(this.outputs,n,e)}))}computeMask(t,e){return Xr((()=>{let n;return t=Vc(t),n=null==e?Rc(null,t.length):Vc(e),this.runInternalGraph(t,n)[1]}))}computeOutputShape(t){const e=Nd(t);if(e.length!==this.inputLayers.length)throw new Cc(`Invalid inputShape argument ${t}: model has ${this.inputLayers.length} tensor inputs.`);const n={};for(let t=0;t<e.length;t++){const s=this.inputLayers[t],r=e[t];n[s.name+"_0_0"]=r}const s=Object.keys(this.nodesByDepth).map((t=>parseInt(t,10))).sort(Jc);if(s.length>1)for(const t of s){const e=this.nodesByDepth[t];for(const t of e){const e=t.outboundLayer;if(-1!==this.inputLayers.map((t=>t.id)).indexOf(e.id))continue;const s=[];for(let e=0;e<t.inboundLayers.length;e++){const r=t.inboundLayers[e],a=t.nodeIndices[e],i=t.tensorIndices[e],o=n[`${r.name}_${a}_${i}`];s.push(o)}const r=Nd(e.computeOutputShape(Pc(s))),a=e.inboundNodes.indexOf(t);for(let t=0;t<r.length;t++)n[`${e.name}_${a}_${t}`]=r[t]}}const r=[],a=[];for(let t=0;t<this.outputLayers.length;t++){const e=this.outputLayers[t],n=this.outputLayersNodeIndices[t],s=this.outputLayersTensorIndices[t],r=`${e.name}_${n}_${s}`;a.push(r)}for(let t=0;t<a.length;t++){const e=a[t];Bc(e in n),r.push(n[e])}return Pc(r)}runInternalGraph(t,e){null==e&&(e=Rc(null,t.length));const n={};for(let s=0;s<this.inputs.length;++s){const r=this.inputs[s],a=t[s],i=e[s];n[r.id]=[a,i]}const s=Object.keys(this.nodesByDepth).map((t=>parseInt(t,10))).sort(Jc);for(const t of s){const e=this.nodesByDepth[t];for(const t of e){const e=t.outboundLayer,s=t.inputTensors,r=t.outputTensors,a=new Array;for(const t of s)t.id in n&&a.push(n[t.id]);if(a.length===s.length){let s,i,o,l,u={};if(null!=t.callArgs&&(u=t.callArgs),1===a.length){const[t,n]=a[0];null==u.mask&&(u.mask=n),o=Vc(e.call(t,u)),l=Vc(e.computeMask(t,n)),s=[t],i=[n]}else s=a.map((t=>t[0])),i=a.map((t=>t[1])),null==u.mask&&(u.mask=i),o=Vc(e.call(s,u)),l=Vc(e.computeMask(s,i));if(e.activityRegularizer)throw new Oc("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");for(let t=0;t<r.length;++t){const e=r[t],s=o[t],a=l[t];n[e.id]=[s,a]}}}}const r=[],a=[],i=[];for(const t of this.outputs){Bc(t.id in n,`Could not compute output ${t.name} : ${t.id}`);const[e,s]=n[t.id];i.push(e.shape),r.push(e),a.push(s)}return[r,a,i]}buildNodeConversionMap(t){const e={};let n;for(const t of this.layers){n=t instanceof $f?1:0;for(let s=0;s<t.inboundNodes.length;s++){const r=$f.nodeKey(t,s);this.containerNodes.has(r)&&(e[r]=n,n+=1)}}return e}getLayer(t,e){if(null!=e){if(this.layers.length<=e)throw new Cc(`Was asked to retrieve layer at index ${e}, but model only has ${this.layers.length} layer(s).`);return this.layers[e]}if(null==t)throw new Cc("Provide either a layer name or layer index");for(const e of this.layers)if(e.name===t)return e;throw new Cc(`No such layer: ${t}`)}calculateLosses(){return Xr((()=>{const t=[];for(const e of this.layers)for(let n=0;n<e.inboundNodes.length;++n){const s=$f.nodeKey(e,n);this.containerNodes.has(s)&&t.push(...e.calculateLosses())}return t}))}getConfig(){const t={name:this.name},e=this.buildNodeConversionMap(this.layers),n=[];for(const t of this.layers){const s=t.getClassName(),r=t.getConfig(),a=[];for(let n=0;n<t.inboundNodes.length;n++){const s=t.inboundNodes[n],r=$f.nodeKey(t,n);let i={};if(this.containerNodes.has(r)){if(s.callArgs)try{JSON.stringify(s.callArgs),i=s.callArgs}catch(e){console.warn(`Layer ${t.name} was passed non-serializable keyword arguments: ${s.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`),i={}}if(s.inboundLayers.length>0){const t=[];for(let n=0;n<s.inboundLayers.length;n++){const r=s.inboundLayers[n],a=s.nodeIndices[n],o=s.tensorIndices[n];let l=e[$f.nodeKey(r,a)];null==l&&(l=0),t.push([r.name,l,o,i])}a.push(t)}}}const i={};i.name=t.name,i.className=s,i.config=r,i.inboundNodes=a,n.push(i)}t.layers=n;const s=[];for(let t=0;t<this.inputLayers.length;t++){const n=this.inputLayers[t],r=this.inputLayersNodeIndices[t],a=$f.nodeKey(n,r);if(!this.containerNodes.has(a))continue;let i=e[a];null==i&&(i=0);const o=this.inputLayersTensorIndices[t];s.push([n.name,i,o])}t.inputLayers=s;const r=[];for(let t=0;t<this.outputLayers.length;t++){const n=this.outputLayers[t],s=this.outputLayersNodeIndices[t],a=$f.nodeKey(n,s);if(!this.containerNodes.has(a))continue;let i=e[a];null==i&&(i=0);const o=this.outputLayersTensorIndices[t];r.push([n.name,i,o])}return t.outputLayers=r,t}static fromConfig(t,e,n={},s=!1){const r={},a={};function i(t,e){t.name in a?a[t.name].push(e):a[t.name]=[e]}function o(t,e){const n=[];let s;for(const a of e){const o=a[0],l=a[1],u=a[2];if(s=null==a[3]?{}:a[3],!(o in r))return void i(t,e);const h=r[o];if(h.inboundNodes.length<=l)return void i(t,e);const c=h.inboundNodes[l];n.push(c.outputTensors[u])}n.length>0&&t.apply(Pc(n),s)}function l(t){const n=t.name,a=Kd(t,null!=e.customObjects?e.customObjects:{});a.setFastWeightInitDuringBuild(s),r[n]=a,t.inboundNodes.forEach((t=>{if(!(t instanceof Array))throw new Cc(`Corrupted configuration, expected array for nodeData: ${t}`);i(a,t)}))}const u=e.name,h=e.layers;for(const t of h)l(t);for(;!Yc(a);)for(const t of h){const e=r[t.name];if(e.name in a){const t=a[e.name];delete a[e.name];for(const n of t)o(e,n)}}const c=[],p=[],d=e.inputLayers;for(const t of d){const e=t[0],n=t[1],s=t[2];Bc(e in r);const a=r[e].inboundNodes[n].outputTensors;c.push(a[s])}const f=e.outputLayers;for(const t of f){const e=t[0],n=t[1],s=t[2];Bc(e in r);const a=r[e].inboundNodes[n].outputTensors;p.push(a[s])}return new t({inputs:c,outputs:p,name:u})}get stateful(){if(this._stateful)throw new Cc("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");for(const t of this.layers)if(t.stateful)return!0;return!1}resetStates(){Xr((()=>{this.layers.forEach((t=>{t.stateful&&t.resetStates()}))}))}}function Mf(t,e){return function(t,e,n){const s=e.length;if(null==t||Array.isArray(t)&&0===t.length)return e.map((t=>null));if(1===s)return Array.isArray(t)&&1===t.length?t:"object"==typeof t&&e[0]in t?[t[e[0]]]:[t];if(Array.isArray(t)){if(t.length!==s)throw new Error(`Provided ${n} is an array of ${t.length} element(s), but the model has ${s} outputs. Make sure a set of weights is provided for each model output.`);return t}if("object"==typeof t&&Object.keys(t).length>0&&"object"==typeof t[Object.keys(t)[0]]){const n=[];return e.forEach((e=>{e in t?n.push(t[e]):n.push(null)})),n}throw new Error(`The model has multiple (${s}) outputs, so ${n} must be either an array with ${s} elements or an object with ${e} keys. Provided ${n} not understood: ${JSON.stringify(t)}`)}(t,e,"classWeight")}async function Ff(t,e,n,s){if(null!=e||null!=s)throw new Error("Support sampleWeight is not implemented yet");if(null!=n){const e=Xr((()=>{if(1===t.shape.length)return t.clone();if(2===t.shape.length){if(t.shape[1]>1){const e=1;return t.argMax(e)}if(1===t.shape[1])return t.reshape([t.shape[0]]);throw new Error(`Encountered unexpected last-dimension size (${t.shape[1]}) during handling of class weights. The size is expected to be >= 1.`)}throw new Error(`Unexpected rank of target (y) tensor (${t.rank}) during handling of class weights. The rank is expected to be 1 or 2.`)})),s=Array.from(await e.data());Qr(e);const r=[];return s.forEach((t=>{if(null==n[t])throw new Error(`classWeight must contain all classes in the training data. The class ${t} exists in the data but not in classWeight`);r.push(n[t])})),no(r,"float32")}return null}function _f(t,e){return ii(t,e)}function zf(t,e){let n,s;const r=e;n=r.xs,s=r.ys,v(null!=n&&null!=s,(()=>`A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${e}`));const a=Cf("input",t.inputNames,n),i=Cf("output",t.outputNames,s),o=a[0].shape[0];v(a.length===t.inputs.length,(()=>`LayersModel has ${t.inputs.length} inputs, but the dataset provides ${a.length} inputs.  (Expected input keys: ${JSON.stringify(t.inputNames)})`)),v(i.length===t.outputs.length,(()=>`LayersModel has ${t.outputs.length} outputs, but the dataset provides ${i.length} outputs.  (Expected output keys: ${JSON.stringify(t.outputNames)})`));for(let e=0;e<a.length;e++)v(a[e].shape[0]===o,(()=>`Batch size mismatch: input ${t.inputNames[e]} has ${a[e].shape[0]}; expected  ${o} based on input ${t.inputNames[0]}.`));for(let e=0;e<i.length;e++)v(i[e].shape[0]===o,(()=>`Batch size mismatch: output ${t.outputNames[e]} has ${i[e].shape[0]}; expected  ${o} based on input ${t.inputNames[0]}.`));return{xs:a,ys:i}}function Cf(t,e,n){if(n instanceof ms)return[n];if(Array.isArray(n))return v(n.length===e.length,(()=>`Received an array of ${n.length} Tensors, but expected ${e.length} to match the ${t} keys ${e}.`)),n;{const s=[];for(const r of e){if(null==n[r])throw new Cc(`The feature data generated by the dataset lacks the required ${t} key '${r}'.`);s.push(n[r])}return s}}function Of(t){return"function"==typeof t.iterator}function Lf(t){v(t>0&&Number.isInteger(t),(()=>`batchSize is required to be a positive integer, but got ${t}`))}function Rf(t,e,n){return null==t?[null]:Array.isArray(t)?t.map((t=>Cp(t,e,n-e))):Cp(t,e,n-e)}function Bf(t,e){return Xr((()=>null==t?null:Array.isArray(t)?t.map((t=>Bf(t,e))):Up(t,"int32"===e.dtype?e:e.toInt())))}function Wf(t,e){const n=[];let s=0,r=null;for(;s<t;)r=s+e,r>=t&&(r=t),n.push([s,r]),s=r;return n}function Pf(t){const e=[];t instanceof ms&&(t=[t]);for(let n=0;n<t.length;++n){const s=t[n];if(1===s.rank)e.push(zp(s,1));else{if(0===s.rank)throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");e.push(s)}}return e}function Vf(t,e){if(null==t)return;const n=[];if(e instanceof ms)n.push(e.id);else if(Array.isArray(e))e.forEach((t=>n.push(t.id)));else if(null!=e)for(const t in e){const s=e[t];n.push(s.id)}const s=[];if(t instanceof ms)-1===n.indexOf(t.id)&&s.push(t);else if(Array.isArray(t))t.forEach((t=>{-1===n.indexOf(t.id)&&s.push(t)}));else if(null!=t)for(const e in t){const r=t[e];-1===n.indexOf(r.id)&&s.push(r)}s.forEach((t=>{t.isDisposed||t.dispose()}))}function Uf(t){return Array.isArray(t)}function Hf(t){return!function(t){return t instanceof ms}(t)&&!Uf(t)}function jf(t,e,n,s=!0,r=""){if(null==e||0===e.length){if(null!=t){let e=!1;if(Uf(t)&&t.length>0)e=!0;else if(Hf(t)){for(const n in t)if(t.hasOwnProperty(n)){e=!0;break}}else e=!0;if(e)throw new Cc(`Error when checking model ${r} expected no data, but got ${t}`)}return[]}if(null==t)return e.map((t=>null));let a;if(Hf(t)){t=t,a=[];for(const n of e){if(null==t[n])throw new Cc(`No data provided for "${n}". Need data for each key in: ${e}`);a.push(t[n])}}else if(Uf(t)){if((t=t).length!==e.length)throw new Cc(`Error when checking model ${r}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${e.length} Tensor(s), but instead got the following list of Tensor(s): ${t}`);a=t}else{if(t=t,e.length>1)throw new Cc(`The model ${r} expects ${e.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${t.shape}`);a=[t]}if(a=Pf(a),null!=n)for(let t=0;t<e.length;++t){if(null==n[t])continue;const i=a[t];if(i.shape.length!==n[t].length)throw new Cc(`Error when checking ${r}: expected ${e[t]} to have ${n[t].length} dimension(s). but got array with shape ${i.shape}`);for(let a=0;a<n[t].length;++a){if(0===a&&!s)continue;const o=i.shape[a],l=n[t][a];if(null!=l&&l>=0&&o!==l)throw new Cc(`Error when checking ${r}: expected ${e[t]} to have shape [${n[t]}], but got array with shape [${i.shape}].`)}}return a}function qf(t,e,n,s=!0,r=""){let a;if(Array.isArray(t)){if(t.length!==e.length)throw new Cc(`Error when checking model ${r}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${e.length} Tensor(s), but instead got ${t.length} Tensors(s).`);a=t}else{if(e.length>1)throw new Cc(`The model expects ${e.length} ${r} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(t.shape)}.`);a=[t]}if(null!=n)for(let t=0;t<e.length;++t){if(null==n[t])continue;const i=a[t];if(i.shape.length!==n[t].length)throw new Cc(`Error when checking ${r}: expected ${e[t]} to have ${n[t].length} dimension(s), but got array with shape ${JSON.stringify(i.shape)}`);for(let a=0;a<n[t].length;++a){if(0===a&&!s)continue;const o=i.shape[a],l=n[t][a];if(null!=l&&l!==o)throw new Cc(`Error when checking ${r}: expected ${e[t]} to have shape ${JSON.stringify(n[t])} but got array with shape ${JSON.stringify(i.shape)}.`)}}}class Gf extends $f{constructor(t){super(t),this.isTraining=!1}summary(t,e,n=console.log){if(!this.built)throw new Cc("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");!function(t,e,n,s=console.log){const r=function(t){let e=!0;const n=[],s=[];for(const e in t.nodesByDepth)n.push(t.nodesByDepth[e]);for(const t of n){if(t.length>1||1===t.length&&t[0].inboundLayers.length>1){e=!1;break}s.push(...t)}if(e)for(const n of t.layers){let t=!1;for(const r of n.inboundNodes)if(-1!==s.indexOf(r)){if(t){e=!1;break}t=!0}if(!e)break}return e}(t),a=["Layer (type)","Output shape","Param #"];let i;if(r?(e=e||65,n=n||[.45,.85,1]):(e=e||98,n=n||[.33,.55,.67,1]),n[n.length-1]<=1&&(n=n.map((t=>Math.floor(e*t)))),!r){a.push("Receives inputs"),i=[];for(const e in t.nodesByDepth)i.push(...t.nodesByDepth[e])}s("_".repeat(e)),yf(a,n,s),s("=".repeat(e));const o=t.layers;for(let t=0;t<o.length;++t)r?bf(o[t],n,s):kf(o[t],n,i,s),s((t===o.length-1?"=":"_").repeat(e));t.checkTrainableWeightsConsistency();const l=function(t){let e;return e=null!=t.collectedTrainableWeights?Sd(t.collectedTrainableWeights):Sd(t.trainableWeights),e}(t),u=Sd(t.nonTrainableWeights);s(`Total params: ${l+u}`),s(`Trainable params: ${l}`),s(`Non-trainable params: ${u}`),s("_".repeat(e))}(this,t,e,n)}compile(t){if(null==t.loss&&(t.loss=[]),this.loss=t.loss,"string"==typeof t.optimizer)this.optimizer_=function(t){const e={Adagrad:()=>Nl.adagrad(.01),Adadelta:()=>Nl.adadelta(1,.95,Fc()),Adam:()=>Nl.adam(.001,.9,.999,Fc()),Adamax:()=>Nl.adamax(.002,.9,.999,Fc(),0),RMSProp:()=>Nl.rmsprop(.001,.9,0,Fc()),SGD:()=>Nl.sgd(.01)};if(e.adagrad=e.Adagrad,e.adadelta=e.Adadelta,e.adam=e.Adam,e.adamax=e.Adamax,e.rmsprop=e.RMSProp,e.sgd=e.SGD,t in e)return e[t]();throw new Cc(`Unknown Optimizer ${t}`)}(t.optimizer),this.isOptimizerOwned=!0;else{if(!(t.optimizer instanceof sa))throw new Cc("User-defined optimizer must be an instance of tf.Optimizer.");this.optimizer_=t.optimizer,this.isOptimizerOwned=!1}let e=[];if(Array.isArray(t.loss)||"string"==typeof t.loss||"function"==typeof t.loss)if(Array.isArray(t.loss)){if(t.loss.length!==this.outputs.length)throw new Cc(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${t.loss}.`);const n=t.loss;e=n.map((t=>rf(t)))}else{const n=rf(t.loss);this.outputs.forEach((t=>{e.push(n)}))}else{t.loss=t.loss;for(const e in t.loss)if(-1===this.outputNames.indexOf(e))throw new Cc(`Unknown entry in loss dictionary: "${e}". Only expected the following keys: ${this.outputNames}`);for(const n of this.outputNames)null==t.loss[n]&&console.warn(`Output "${n}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${n} during training`),e.push(rf(t.loss[n]))}this.lossFunctions=e,this.feedOutputNames=[],this.feedOutputShapes=[],this.feedLossFns=[];for(let t=0;t<this.outputs.length;++t){const e=this.internalOutputShapes[t],n=this.outputNames[t];this.feedOutputNames.push(n),this.feedOutputShapes.push(e),this.feedLossFns.push(this.lossFunctions[t])}const n=[];this.metrics=t.metrics,this.metricsNames=["loss"],this.metricsTensors=[],vp("loss",(()=>{for(let t=0;t<this.outputs.length;++t){if(-1!==n.indexOf(t))continue;const e=this.lossFunctions[t];this.outputs.length>1&&(this.metricsTensors.push([e,t]),this.metricsNames.push(this.outputNames[t]+"_loss"))}}));const s=function(t,e){if(null==t||Array.isArray(t)&&0===t.length)return e.map((t=>[]));let n;if("string"==typeof t||"function"==typeof t)n=[t];else{if(!Array.isArray(t)&&"object"!=typeof t)throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${t}`);n=t}if(Array.isArray(n))return e.map((t=>n));{const t=[];for(const s of e){let e=n.hasOwnProperty(s)?n[s]:[];Array.isArray(e)||(e=[e]),t.push(e)}return t}}(t.metrics,this.outputNames),r=(t,e,n)=>{this.outputNames.length>1&&(e=this.outputNames[t]+"_"+e),this.metricsNames.push(e),this.metricsTensors.push([n,t])};vp("metric",(()=>{for(let t=0;t<this.outputs.length;++t)-1===n.indexOf(t)&&(e=>{let n,s,a;for(const i of e){if("string"==typeof i&&-1!==["accuracy","acc","crossentropy","ce"].indexOf(i)){const e=this.internalOutputShapes[t];let r;1===e[e.length-1]||this.lossFunctions[t]===ef?-1!==["accuracy","acc"].indexOf(i)?s=af:-1!==["crossentropy","ce"].indexOf(i)&&(s=lf):this.lossFunctions[t]===tf?-1!==["accuracy","acc"].indexOf(i)?s=uf:-1!==["crossentropy","ce"].indexOf(i)&&(s=cf):-1!==["accuracy","acc"].indexOf(i)?s=of:-1!==["crossentropy","ce"].indexOf(i)&&(s=hf),-1!==["accuracy","acc"].indexOf(i)?r="acc":-1!==["crossentropy","ce"].indexOf(i)&&(r="ce"),a=s,n=""+r}else{const t=df(i);a=t,n=""+ff(i)}let e;vp(n,(()=>{e=a})),r(t,n,e)}})(s[t])})),this.collectedTrainableWeights=this.trainableWeights}checkTrainableWeightsConsistency(){null!=this.collectedTrainableWeights&&this.trainableWeights.length!==this.collectedTrainableWeights.length&&console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?")}evaluate(t,e,n={}){const s=null==n.batchSize?32:n.batchSize;Lf(s);const r=this.standardizeUserDataXY(t,e,!0,s);try{const a=r[0].concat(r[1]);this.makeTestFunction();const i=this.testFunction;return Pc(this.testLoop(i,a,s,n.verbose,n.steps))}finally{Vf(r[0],t),Vf(r[1],e)}}async evaluateDataset(t,e){return this.makeTestFunction(),async function(t,e,n){const s=null!=(n=n||{}).batches,r=t.testFunction;let a=[];if(n.verbose>0)throw new Oc("Verbose mode is not implemented yet.");v(!s||n.batches>0&&Number.isInteger(n.batches),(()=>`Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(n.batches)}`));const i="function"==typeof e.next?e:await e.iterator();let o=0,l=0;for(;!s||l<n.batches;){const e=await i.next();if(a=Xr((()=>{if(e.value){const{xs:n,ys:s}=zf(t,e.value),i=n.concat(s),u=Xr((()=>r(i)));if(Qr(i),0===l)for(let t=0;t<u.length;++t)a.push(na(0));const h=i[0].shape[0];for(let t=0;t<u.length;++t){const e=u[t],n=a[t];a[t]=Xr((()=>aa(a[t],ii(h,e)))),l>0&&Qr(n)}Qr(u),o+=h,++l}return a})),e.done){s&&console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${n.batches} batches). You may need to use the repeat() function when building your dataset.`);break}}for(let t=0;t<a.length;++t){const e=a[t];a[t]=Va(a[t],o),Qr(e)}return Pc(a)}(this,t,e)}checkNumSamples(t,e,n,s="steps"){let r;if(null!=n){if(r=null,null!=e)throw new Cc(`If ${s} is set, batchSize must be null or undefined.Got batchSize = ${e}`)}else{if(null==t)throw new Cc(`Either the input data should have a defined shape, or ${s} shoud be specified.`);r=Array.isArray(t)?t[0].shape[0]:t.shape[0]}return r}execute(t,e){if(Array.isArray(e)&&0===e.length)throw new Cc("`outputs` is an empty Array, which is not allowed.");const n=Array.isArray(e),s=n?e:[e],r=this.retrieveSymbolicTensors(s),a=new vf;if(t instanceof ms&&(t=[t]),Array.isArray(t)){if(t.length!==this.inputs.length)throw new Cc(`The number of inputs provided (${t.length}) does not match the number of inputs of this model (${this.inputs.length}).`);for(let e=0;e<this.inputs.length;++e)a.add(this.inputs[e],t[e])}else for(const e of this.inputs){const n=t[e.name];if(null==n)throw new Cc(`No value is provided for the model's input ${e.name}`);a.add(e,n)}const i=Tf(r,a);return n?i:i[0]}retrieveSymbolicTensors(t){const e=Rc(null,t.length);let n=t.length;for(const s of this.layers){const r=Array.isArray(s.output)?s.output:[s.output],a=r.map((t=>t.name));for(let s=0;s<t.length;++s){const i=a.indexOf(t[s]);if(-1!==i&&(e[s]=r[i],n--),0===n)break}if(0===n)break}if(n>0){const n=[];throw e.forEach(((e,s)=>{null==e&&n.push(t[s])})),new Cc(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(n)}`)}return e}predictLoop(t,e=32,n=!1){return Xr((()=>{const s=this.checkNumSamples(t);if(n)throw new Oc("Verbose predictLoop() is not implemented yet.");const r=Wf(s,e),a=this.outputs.map((t=>[]));for(let e=0;e<r.length;++e)Xr((()=>{const n=r[e][0],s=r[e][1],a=Rf(t,n,s),i=[];if(Array.isArray(a))for(let t=0;t<a.length;++t)i.push({key:this.inputs[t],value:a[t]});else i.push({key:this.inputs[0],value:a});const o=new vf(i);return Tf(this.outputs,o)})).forEach(((t,e)=>a[e].push(t)));return Pc(a.map((t=>$a(t,0))))}))}predict(t,e={}){const n=Pf(t);qf(n,this.inputNames,this.feedInputShapes,!1);try{const s=null==e.batchSize?32:e.batchSize;return Lf(s),this.predictLoop(n,s)}finally{Vf(n,t)}}predictOnBatch(t){qf(t,this.inputNames,this.feedInputShapes,!0);const e=(Array.isArray(t)?t[0]:t).shape[0];return this.predictLoop(t,e)}standardizeUserDataXY(t,e,n=!0,s){if(null==this.optimizer_)throw new zc("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");const r=[];for(let t=0;t<this.feedOutputShapes.length;++t){const e=this.feedOutputShapes[t];this.feedLossFns[t]===tf?r.push(e.slice(0,e.length-1).concat([1])):r.push(e)}if(function(t,e,n){const s=Zc(t.map((t=>t.shape[0])));s.sort();const r=Zc(e.map((t=>t.shape[0])));if(r.sort(),s.length>1)throw new Cc(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(t.map((t=>t.shape)))}`);if(r.length>1)throw new Cc(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(e.map((t=>t.shape)))}`);if(s.length>0&&r.length>0&&!A(s,r))throw new Cc(`Input Tensors should have the same number of samples as target Tensors. Found ${s[0]} input sample(s) and ${r[0]} target sample(s).`)}(t=jf(t,this.feedInputNames,this.feedInputShapes,!1,"input"),e=jf(e,this.feedOutputNames,r,!1,"target")),function(t,e,n){const s=[Zd,ef,Qd];for(let r=0;r<t.length;++r){const a=t[r],i=e[r],o=n[r];if(null!=i){if(i===Qd&&1===a.shape[a.shape.length-1])throw new Cc(`You are passing a target array of shape ${a.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);if(-1!==s.indexOf(i)){const t=a.shape.slice(1),e=o.slice(1);for(let n=0;n<t.length;++n){const s=t[n],r=e[n];if(null!=r&&s!==r)throw new Cc(`A target Tensor with shape ${a.shape} was passed for an output of shape ${o}, while using a loss function that expects targets to have the same shape as the output.`)}}}}}(e,this.feedLossFns,this.feedOutputShapes),this.stateful&&null!=s&&s>0&&t[0].shape[0]%s!=0)throw new Cc(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${s}. Found: ${t[0].shape[0]} sample(s).`);return[t,e]}async standardizeUserData(t,e,n,s,r=!0,a){const[i,o]=this.standardizeUserDataXY(t,e,r,a);if(null!=n)throw new Error("sample weight is not supported yet.");let l=null;if(null!=s){const t=Mf(s,this.outputNames);l=[];for(let e=0;e<t.length;++e)l.push(await Ff(o[e],null,t[e]))}return[i,o,l]}testLoop(t,e,n,s=0,r){return Xr((()=>{const a=this.checkNumSamples(e,n,r,"steps"),i=[];if(s>0)throw new Oc("Verbose mode is not implemented yet.");if(null!=r)throw new Oc("steps mode in testLoop() is not implemented yet");{const s=Wf(a,n),r=no(Fp(0,a));for(let n=0;n<s.length;++n){const a=s[n][0],o=s[n][1],l=Cp(r,a,o-a),u=Bf(e,l),h=t(u);if(0===n)for(let t=0;t<h.length;++t)i.push(na(0));for(let t=0;t<h.length;++t){const e=h[t];i[t]=aa(i[t],ii(o-a,e))}}for(let t=0;t<i.length;++t)i[t]=Va(i[t],a)}return i}))}getDedupedMetricsNames(){const t=this.metricsNames,e=[];for(let n=0;n<t.length;++n){const s=t[n];let r=s;Wc(t,s)>1&&(r+=`_${Wc(t.slice(0,n),s)}`),e.push(r)}return e}makeTrainFunction(){return t=>{const e=[],n=t.slice(0,this.inputs.length),s=t.slice(this.inputs.length,this.inputs.length+this.outputs.length),r=t.slice(this.inputs.length+this.outputs.length,this.inputs.length+2*this.outputs.length),a=[],i=this.collectedTrainableWeights.map((t=>t.read()));return[this.optimizer_.minimize((()=>{const t=[];for(let e=0;e<this.inputs.length;++e)t.push({key:this.inputs[e],value:n[e]});const i=new vf(t),o=Tf(this.outputs,i,{training:!0});let l;for(let t=0;t<this.lossFunctions.length;++t){let n=(0,this.lossFunctions[t])(s[t],o[t]);null!=r[t]&&(n=_f(n,r[t]));const a=fi(n);e.push(a),l=0===t?n:aa(l,n)}for(let t=0;t<this.metricsTensors.length;++t){let n;if(this.outputs.length>1&&t<this.outputs.length)n=e[t];else{const e=this.metricsTensors[t][0],r=this.metricsTensors[t][1];n=fi(e(s[r],o[r]))}ta(n),a.push(n)}return l=fi(l),this.calculateLosses().forEach((t=>{l=aa(l,t)})),l}),!0,i)].concat(a)}}makeTestFunction(){this.testFunction=t=>Xr((()=>{const e=[];let n;const s=t.slice(0,this.inputs.length),r=t.slice(this.inputs.length,this.inputs.length+this.outputs.length),a=[];for(let t=0;t<this.inputs.length;++t)a.push({key:this.inputs[t],value:s[t]});const i=new vf(a),o=Tf(this.outputs,i);for(let t=0;t<this.lossFunctions.length;++t){const s=this.lossFunctions[t],a=fi(s(r[t],o[t]));n=0===t?a:aa(n,a),e.push(n)}for(let t=0;t<this.metricsTensors.length;++t){const n=this.metricsTensors[t][0],s=this.metricsTensors[t][1],a=fi(n(r[s],o[s]));e.push(a)}return e}))}async fit(t,e,n={}){return async function(t,e,n,s={}){if(t.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");let r,a,i,o,l,u,h;t.isTraining=!0;try{const c=null==s.batchSize?32:s.batchSize;Lf(c);const p=!1,d=await t.standardizeUserData(e,n,s.sampleWeight,s.classWeight,p,c);r=d[0],a=d[1],h=d[2];let f,m=!1;if(null!=s.validationData&&s.validationData.length>0){if(m=!0,2!==s.validationData.length)throw 3===s.validationData.length?new Oc("validationData including sample weights is not supported yet."):new Cc(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${s.validationData} is invalid.`);i=s.validationData[0],o=s.validationData[1];const e=!0,n=await t.standardizeUserData(i,o,null,null,e,c);l=n[0],u=n[1],f=l.concat(u)}else if(null!=s.validationSplit&&s.validationSplit>0&&s.validationSplit<1){m=!0;const t=Math.floor(r[0].shape[0]*(1-s.validationSplit)),e=r[0].shape[0];l=Rf(r,t,e),r=Rf(r,0,t),u=Rf(a,t,e),a=Rf(a,0,t),f=l.concat(u)}else null!=s.validationSteps&&(m=!0);const g=r.concat(a).concat(h);t.checkTrainableWeightsConsistency();const y=t.makeTrainFunction(),b=t.getDedupedMetricsNames();let k,w;m?(t.makeTestFunction(),k=t.testFunction,w=b.slice().concat(b.map((t=>"val_"+t)))):(k=null,f=[],w=b.slice());const N=jd(s.callbacks,s.yieldEvery);return await async function(t,e,n,s,r,a,i,o,l,u,h,c,p,d,f){null==r&&(r=32),null==a&&(a=1),null==h&&(h=!0),null==p&&(p=0);let m=!1;null!=l&&null!=u&&(m=!0);const g=t.checkNumSamples(n,r,d,"steps_per_epoch");let y;null!=g&&(y=Fp(0,g)),null==i&&(i=1);const{callbackList:b,history:k}=Gd(o,i,a,p,g,d,r,m,c);b.setModel(t),t.history=k,await b.onTrainBegin(),t.stopTraining_=!1;for(let i=p;i<a;++i){await b.onEpochBegin(i);const a={};{if("batch"===h)throw new Oc("batch shuffling is not implemneted yet");h&&x(y);const i=no(y),o=Wf(g,r);for(let h=0;h<o.length;++h){const c={};if(await b.onBatchBegin(h,c),Xr((()=>{const p=o[h][0],d=o[h][1],f=Cp(i,p,d-p);c.batch=h,c.size=d-p;const g=Bf(n,f),y=e(g);for(let t=0;t<s.length;++t){const e=s[t],n=y[t];c[e]=n,ta(n)}if(h===o.length-1&&m){const e=t.testLoop(l,u,r);for(let t=0;t<s.length;++t){const n=s[t],r=e[t];ta(r),a["val_"+n]=r}}})),await b.onBatchEnd(h,c),Rd(c),t.stopTraining_)break}i.dispose()}if(await b.onEpochEnd(i,a),t.stopTraining_)break}return await b.onTrainEnd(),await t.history.syncData(),t.history}(t,y,g,b,c,s.epochs,s.verbose,N,k,f,s.shuffle,w,s.initialEpoch,null)}finally{t.isTraining=!1,Vf(r,e),Vf(a,n),Vf(l,i),Vf(u,o),null!=h&&Qr(h)}}(this,t,e,n)}async fitDataset(t,e){return async function(t,e,n){const s=null!=n.batchesPerEpoch;if(v(null!=t.optimizer,(()=>"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig).")),v(null!=n,(()=>"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call.")),v(null!=n.epochs&&n.epochs>0&&Number.isInteger(n.epochs),(()=>`For fitDataset(), config.epochs is expected to be a positive integer, but got ${n.epochs}`)),v(!s||n.batchesPerEpoch>0&&Number.isInteger(n.batchesPerEpoch),(()=>`For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${n.batchesPerEpoch}`)),v(null==n.validationSplit,(()=>"`validationSplit` is not supported by `fitDataset()`. Use validationData instead.")),t.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");t.isTraining=!0;try{const r=null!=n.validationData;let a,i;if(r)if(Of(n.validationData))v(null==n.validationBatches||n.validationBatches>0&&Number.isInteger(n.validationBatches),(()=>`For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${n.validationBatches}`));else{const t=function(t){if(3===t.length)throw new Oc("Validation with sample weights is not implemented yet.");return{xs:t[0],ys:t[1]}}(n.validationData);a=t.xs,i=t.ys}const o=t.makeTrainFunction(),l=t.getDedupedMetricsNames();let u;u=r?l.slice().concat(l.map((t=>"val_"+t))):l.slice();const h=jd(n.callbacks,n.yieldEvery),c=null==n.verbose?1:n.verbose,{callbackList:p,history:d}=Gd(h,c,n.epochs,null,null,function(t,e){let n=null;return null!=e.batchesPerEpoch?n=e.batchesPerEpoch:Number.isFinite(t.size)&&(n=t.size),n}(e,n),null,r,u);p.setModel(t),t.history=d,await p.onTrainBegin(),t.stopTraining_=!1;let f=null==n.initialEpoch?0:n.initialEpoch,m=await e.iterator();for(;f<n.epochs;){const u={};await p.onEpochBegin(f);let h=0,c=0;for(s||(m=await e.iterator());!s||h<n.batchesPerEpoch;){const e=await m.next();if(s&&e.done){console.warn(`You provided \`batchesPerEpoch\` as ${n.batchesPerEpoch}, but your dataset iterator ran out of data after ${h} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, `+n.batchesPerEpoch*n.epochs+" batches). You may need to use the repeat() function when building your dataset.");break}if(null!=e.value){const{xs:s,ys:r}=zf(t,e.value),a={};a.batch=c,a.size=s[0].shape[0],await p.onBatchBegin(c,a);const i=[];if(null!=n.classWeight){const e=Mf(n.classWeight,t.outputNames);for(let t=0;t<e.length;++t)i.push(await Ff(r[t],null,e[t]))}const u=s.concat(r).concat(i),d=o(u);Qr(u);for(let t=0;t<l.length;++t){const e=l[t],n=d[t];a[e]=n,ta(n)}await p.onBatchEnd(c,a),Rd(a),c++,h++}if(s?h>=n.batchesPerEpoch:e.done){if(r){let e;e=Of(n.validationData)?Vc(await t.evaluateDataset(n.validationData,{batches:n.validationBatches})):Vc(t.evaluate(a,i,{batchSize:null==n.validationBatchSize?32:n.validationBatchSize,verbose:0}));for(let n=0;n<t.metricsNames.length;++n)u[`val_${t.metricsNames[n]}`]=e[n]}break}if(t.stopTraining_)break}if(await p.onEpochEnd(f,u),f++,t.stopTraining_)break}return await p.onTrainEnd(),await t.history.syncData(),t.history}finally{t.isTraining=!1}}(this,t,e)}async trainOnBatch(t,e){const n=await this.standardizeUserData(t,e),s=n[0],r=n[1],a=this.makeTrainFunction()(s.concat(r)),i=[];for(const t of a){const e=await t.data();i.push(e[0])}return Qr(a),Pc(i)}getNamedWeights(t){const e=[],n=null!=t&&t.trainableOnly,s=n?this.trainableWeights:this.weights,r=this.getWeights(n);for(let t=0;t<s.length;++t)n&&!s[t].trainable||e.push({name:s[t].originalName,tensor:r[t]});return e}set stopTraining(t){this.stopTraining_=t}get stopTraining(){return this.stopTraining_}get optimizer(){return this.optimizer_}set optimizer(t){this.optimizer_!==t&&(this.optimizer_=t,this.isOptimizerOwned=!1)}dispose(){const t=super.dispose();if(0===t.refCountAfterDispose&&null!=this.optimizer&&this.isOptimizerOwned){const e=Yr().numTensors;this.optimizer_.dispose(),t.numDisposedVariables+=e-Yr().numTensors}return t}getLossIdentifiers(){let t;if("string"==typeof this.loss)t=Uc(this.loss);else if(Array.isArray(this.loss)){for(const t of this.loss)if("string"!=typeof t)throw new Error("Serialization of non-string loss is not supported.");t=this.loss.map((t=>Uc(t)))}else{const e=Object.keys(this.loss);t={};const n=this.loss;for(const s of e){if("string"!=typeof n[s])throw new Error("Serialization of non-string loss is not supported.");t[s]=Uc(n[s])}}return t}getMetricIdentifiers(){if("string"==typeof this.metrics||"function"==typeof this.metrics)return[Uc(ff(this.metrics))];if(Array.isArray(this.metrics))return this.metrics.map((t=>Uc(ff(t))));{const t={};for(const e in this.metrics)t[e]=Uc(ff(this.metrics[e]));return t}}getTrainingConfig(){return{loss:this.getLossIdentifiers(),metrics:this.getMetricIdentifiers(),optimizer_config:{class_name:this.optimizer.getClassName(),config:this.optimizer.getConfig()}}}loadTrainingConfig(t){if(null!=t.weighted_metrics)throw new Error("Loading weight_metrics is not supported yet.");if(null!=t.loss_weights)throw new Error("Loading loss_weights is not supported yet.");if(null!=t.sample_weight_mode)throw new Error("Loading sample_weight_mode is not supported yet.");const e=Kd(xf(t.optimizer_config));let n,s;if("string"==typeof t.loss)n=Hc(t.loss);else if(Array.isArray(t.loss))n=t.loss.map((t=>Hc(t)));else if(null!=t.loss){n={};for(const e in t.loss)n[e]=Hc(t.loss[e])}if(Array.isArray(t.metrics))s=t.metrics.map((t=>Hc(t)));else if(null!=t.metrics){s={};for(const e in t.metrics)s[e]=Hc(t.metrics[e])}this.compile({loss:n,metrics:s,optimizer:e})}async save(t,e){if("string"==typeof t){const e=Xs(t);if(0===e.length)throw new Cc(`Cannot find any save handlers for URL '${t}'`);if(e.length>1)throw new Cc(`Found more than one (${e.length}) save handlers for URL '${t}'`);t=e[0]}if(null==t.save)throw new Cc("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");const n=await Us(this.getNamedWeights(e)),s={modelTopology:this.toJSON(null,!1),format:"layers-model",generatedBy:"TensorFlow.js tfjs-layers v2.8.3",convertedBy:null};if(null!=e&&e.includeOptimizer&&null!=this.optimizer){s.trainingConfig=this.getTrainingConfig();const t="optimizer",{data:e,specs:r}=await Us(await this.optimizer.getWeights(),t);n.specs.push(...r),n.data=Ks([n.data,e])}if(null!=this.userDefinedMetadata){const t=!0;mf(this.userDefinedMetadata,this.name,t),s.userDefinedMetadata=this.userDefinedMetadata}return s.weightData=n.data,s.weightSpecs=n.specs,t.save(s)}setUserDefinedMetadata(t){mf(t,this.name),this.userDefinedMetadata=t}getUserDefinedMetadata(){return this.userDefinedMetadata}}Gf.className="Model",Kr(Gf);class Kf extends Gf{}Kf.className="Functional",Kr(Kf);class Jf extends Gf{constructor(t){if(super({inputs:[],outputs:[]}),t=t||{},this.trainable=!0,this.built=!1,this.name=null!=t.name?t.name:wd("sequential_"),null!=t.layers)for(const e of t.layers)this.add(e)}checkShape(t){if(t.inboundNodes[0].outputTensors[0].shape.some((t=>t<0)))throw new Cc(`Negative dimension size caused by adding layer ${t.name} with input shape [${t.inboundNodes[0].inputTensors[0].shape}]`)}add(t){const e=t instanceof Jf||t instanceof Gf;let n;if(e){if(n=t,1!==n.outputs.length)throw new Cc("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");if(1!==n.inputs.length)throw new Cc("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.")}if(0===this.outputs.length){if(0===t.inboundNodes.length){if(null==t.batchInputShape)throw new Cc("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");const e=function(t){if(null==t.batchShape&&null==t.shape)throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");if(null!=t.batchShape&&null!=t.shape)throw new Cc("Please provide either a `shape` or `batchShape` argument to Input, but not both.");let e=t.batchShape;null!=t.shape&&null==e&&(e=[null].concat(t.shape));let n=t.dtype;return null==n&&(n="float32"),new Od({batchInputShape:e,name:t.name,dtype:n,sparse:t.sparse}).inboundNodes[0].outputTensors[0]}({batchShape:t.batchInputShape,dtype:t.dtype,name:t.name+"_input"});t.apply(e)}if(e)this.outputs=n.outputs,this.inputs=n.inputs;else{if(1!==t.inboundNodes.length)throw new Cc(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${t.name} which has ${t.inboundNodes.length} pre-existing inbound connections.`);if(1!==t.inboundNodes[0].outputTensors.length)throw new Cc("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(t),this.outputs=[t.inboundNodes[0].outputTensors[0]],this.inputs=Cd(this.outputs[0])}this.inboundNodes=[],new Fd({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:Rc(null,this.inputs.length),outputMasks:[null],inputShapes:this.inputs.map((t=>t.shape)),outputShapes:this.outputs[0].shape})}else{const e=t.apply(this.outputs[0]);if(Array.isArray(e))throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(t),this.outputs=[e],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}this.layers.push(t),this.built=!1}pop(){if(0===this.layers.length)throw new TypeError("There are no layers in the model.");if(this.layers.pop(),0===this.layers.length)this.outputs=[],this.inboundNodes=[],this.outboundNodes=[];else{const t=this.layers.length-1;this.layers[t].outboundNodes=[],this.outputs=[this.layers[t].output],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}}call(t,e){return null==this.model&&this.build(),this.model.call(t,e)}build(t){if(Id(t),0===this.inputs.length||0===this.outputs.length)throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");this.model=new Gf({inputs:this.inputs,outputs:this.outputs[0],name:this.name+"_model"}),this.model.trainable=this.trainable,this.supportsMasking=this.model.supportsMasking,this.inputLayers=this.model.inputLayers,this.inputLayersNodeIndices=this.model.inputLayersNodeIndices,this.inputLayersTensorIndices=this.model.inputLayersTensorIndices,this.outputLayers=this.model.outputLayers,this.outputLayersNodeIndices=this.model.outputLayersNodeIndices,this.outputLayersTensorIndices=this.model.outputLayersTensorIndices,this.nodesByDepth=this.model.nodesByDepth,this.containerNodes=this.model.containerNodes,this.outputNames=this.model.outputNames,this.inputNames=this.model.inputNames,this.built=!0}countParams(){return this.built||this.build(),super.countParams()}summary(t,e,n=console.log){this.built||this.build(),super.summary(t,e,n)}setWeights(t){null==this.model&&this.build(),this.model.setWeights(t)}evaluate(t,e,n={}){if(!this.built)throw new zc("The model needs to be compiled before being used.");return this.model.evaluate(t,e,n)}async evaluateDataset(t,e){if(!this.built)throw new zc("The model needs to be compiled before being used.");return this.model.evaluateDataset(t,e)}predict(t,e={}){return null==this.model&&this.build(),this.model.predict(t,e)}predictOnBatch(t){return null==this.model&&this.build(),this.model.predictOnBatch(t)}compile(t){this.build(),this.model.compile(t),this.optimizer_=this.model.optimizer,this.isOptimizerOwned=this.model.isOptimizerOwned,this.loss=this.model.loss,this.metrics=this.model.metrics,this.metricsTensors=this.model.metricsTensors,this.metricsNames=this.model.metricsNames}get optimizer(){return null==this.model?void 0:this.model.optimizer}set optimizer(t){this.model.optimizer=t}async fit(t,e,n={}){if(!this.built)throw new zc("The model needs to be compiled before being used.");return this.model.fit(t,e,n)}async fitDataset(t,e){if(!this.built)throw new zc("The model needs to be compiled before being used.");return this.model.fitDataset(t,e)}async trainOnBatch(t,e){return this.model.trainOnBatch(t,e)}static fromConfig(t,e,n={},s=!1){let r,a={};if(e instanceof Array){if(null==e[0].className||"Merge"===e[0].className)throw new Cc("Legacy serialization format not supported yet.");r=e}else v(null!=e.layers,(()=>"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field.")),r=e.layers,delete e.layers,a=e;const i=new t(a);if(!(i instanceof Jf))throw new Oc(`Sequential.fromConfig called on non-Sequential input: ${i}`);for(const t of r){const e=Kd(t,void 0,s);s&&e.setFastWeightInitDuringBuild(!0),i.add(e)}return i}set stopTraining(t){if(null==this.model)throw new Cc("Cannot set the stopTraining property of a sequential model before it is compiled.");this.model.stopTraining=t}get stopTraining(){if(null==this.model)throw new Cc("Cannot get the stopTraining property of a sequential model before it is compiled.");return this.model.stopTraining}getConfig(){const t=[];for(const e of this.layers){const n={};n.className=e.getClassName(),n.config=e.getConfig(),t.push(n)}return{name:this.name,layers:t}}}Jf.className="Sequential",Kr(Jf);class Zf extends qr{getConfig(){return{}}}class Yf extends Zf{apply(t,e=1){return function(t,e=1){if(1!==e)throw new Oc(`Support for alpha values other than 1 (${e}) is not implemented yet.`);return Ua(t)}(t,e)}}Yf.className="elu",Kr(Yf);class Xf extends Zf{apply(t){return Pi(t)}}Xf.className="selu",Kr(Xf);class Qf extends Zf{apply(t){return Bi(t)}}Qf.className="relu",Kr(Qf);class tm extends Zf{apply(t){return Xr((()=>gi(6,Bi(t))))}}tm.className="relu6",Kr(tm);class em extends Zf{apply(t){return t}}em.className="linear",Kr(em);class nm extends Zf{apply(t){return Ui(t)}}nm.className="sigmoid",Kr(nm);class sm extends Zf{apply(t){return function(t){return Xr((()=>{const e=aa(.5,ii(.2,t));return Da(e,0,1)}))}(t)}}sm.className="hardSigmoid",Kr(sm);class rm extends Zf{apply(t){return Zi(t)}}rm.className="softplus",Kr(rm);class am extends Zf{apply(t){return function(t){return Xr((()=>Va(t,ra(t).add(1))))}(t)}}am.className="softsign",Kr(am);class im extends Zf{apply(t){return eo(t)}}im.className="tanh",Kr(im);class om extends Zf{apply(t,e=-1){return Ji(t,e)}}om.className="softmax",Kr(om);class lm extends Zf{apply(t,e=-1){return ui(t,e)}}lm.className="logSoftmax",Kr(lm);class um extends Zf{apply(t,e=1){return Xr((()=>Ui(t.mul(e)).mul(t)))}}function hm(t){return t.getClassName()}function cm(t,e={}){return Kc(t,Gr.getMap().classNameMap,e,"activation")}function pm(t){if(null==t){return cm({className:"linear",config:{}})}if("string"==typeof t){const e={};return e.className=t,e.config={},cm(e)}return t instanceof Zf?t:cm(t)}um.className="swish",Kr(um);class dm extends qr{}class fm extends dm{constructor(t){super(),function(t){if(null!=t&&"object"!=typeof t)throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${t}`)}(t),this.l1=null==t||null==t.l1?.01:t.l1,this.l2=null==t||null==t.l2?.01:t.l2,this.hasL1=0!==this.l1,this.hasL2=0!==this.l2}apply(t){return Xr((()=>{let e=Di([1]);return this.hasL1&&(e=aa(e,li(ii(this.l1,ra(t))))),this.hasL2&&(e=aa(e,li(ii(this.l2,Hp(t))))),e.asScalar()}))}getConfig(){return{l1:this.l1,l2:this.l2}}static fromConfig(t,e){return new t({l1:e.l1,l2:e.l2})}}fm.className="L1L2",Kr(fm);const mm={l1l2:"L1L2"};function gm(t){return qc(t)}function ym(t,e={}){return Kc(t,Gr.getMap().classNameMap,e,"regularizer")}function bm(t){return null==t?null:"string"==typeof t?ym({className:t in mm?mm[t]:t,config:{}}):t instanceof dm?t:ym(t)}class km extends zd{constructor(t){super(null==t?{}:t),this.supportsMasking=!0,null!=t&&(this.maxValue=t.maxValue)}call(t,e){t=vd(t);let n=Bi(t);return null!=this.maxValue&&(n=Da(n,0,this.maxValue)),n}computeOutputShape(t){return t}getConfig(){const t={maxValue:this.maxValue},e=super.getConfig();return Object.assign(t,e),t}}km.className="ReLU",Kr(km);class wm extends zd{constructor(t){super(null==t?{}:t),this.DEFAULT_ALPHA=.3,null==t&&(t={}),this.alpha=null==t.alpha?this.DEFAULT_ALPHA:t.alpha}call(t,e){const n=vd(t);return ni(n,this.alpha)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},e=super.getConfig();return Object.assign(t,e),t}}wm.className="LeakyReLU",Kr(wm);class xm extends zd{constructor(t){if(super(null==t?{}:t),this.DEFAULT_ALPHA_INITIALIZER="zeros",null==t&&(t={}),this.supportsMasking=!0,this.alphaInitializer=gd(t.alphaInitializer||this.DEFAULT_ALPHA_INITIALIZER),this.alphaRegularizer=bm(t.alphaRegularizer),this.alphaConstraint=pp(t.alphaConstraint),null==t.sharedAxes)this.sharedAxes=null;else if(Array.isArray(t.sharedAxes))this.sharedAxes=t.sharedAxes;else{if("number"!=typeof t.sharedAxes)throw new Cc(`Expected sharedAxes to be a number or an array of numbers, but got ${t.sharedAxes}`);this.sharedAxes=[t.sharedAxes]}}build(t){const e=(t=Id(t)).slice(1);if(null!=this.sharedAxes)for(const t of this.sharedAxes)e[t-1]=1;this.alpha=this.addWeight("alpha",e,"float32",this.alphaInitializer,this.alphaRegularizer,!0,this.alphaConstraint);const n={};if(null!=this.sharedAxes)for(let e=1;e<t.length;++e)n[e]=t[e];this.inputSpec=[new Dd({ndim:t.length,axes:n})],this.built=!0}call(t,e){return t=vd(t),_i(t,this.alpha.read())}getConfig(){const t={alphaInitializer:md(this.alphaInitializer),alphaRegularizer:gm(this.alphaRegularizer),alphaConstraint:hp(this.alphaConstraint),sharedAxes:this.sharedAxes},e=super.getConfig();return Object.assign(t,e),t}}xm.className="PReLU",Kr(xm);class Nm extends zd{constructor(t){if(super(null==t?{}:t),this.DEFAULT_ALPHA=1,null==t&&(t={}),null!=t.alpha&&t.alpha!==this.DEFAULT_ALPHA)throw new Oc(`Non-default alpha value (${t.alpha}) is not supported by the ELU layer yet.`);this.alpha=null==t.alpha?this.DEFAULT_ALPHA:t.alpha}call(t,e){const n=vd(t);return Ua(n)}computeOutputShape(t){return t}getConfig(){const t={alpha:this.alpha},e=super.getConfig();return Object.assign(t,e),t}}Nm.className="ELU",Kr(Nm);class vm extends zd{constructor(t){super(null==t?{}:t),this.DEFAULT_THETA=1,null==t&&(t={}),this.theta=null==t.theta?this.DEFAULT_THETA:t.theta}call(t,e){const n=vd(t);return n.mul(_p(n.greater(this.theta),"float32"))}computeOutputShape(t){return t}getConfig(){const t={theta:this.theta},e=super.getConfig();return Object.assign(t,e),t}}vm.className="ThresholdedReLU",Kr(vm);class Im extends zd{constructor(t){super(null==t?{}:t),this.DEFAULT_AXIS=1,null==t&&(t={}),this.softmax=(new om).apply,this.axis=null==t.axis?this.DEFAULT_AXIS:t.axis}call(t,e){const n=vd(t);return this.softmax(n,this.axis)}computeOutputShape(t){return t}getConfig(){const t={axis:this.axis},e=super.getConfig();return Object.assign(t,e),t}}function Sm(t,e,n){if("number"==typeof t)return Rc(t,e);if(t.length!==e)throw new Cc(`The ${n} argument must be an integer or tuple of ${e} integers. Received: ${t.length} elements.`);for(let r=0;r<e;++r){const a=t[r];if((s=a)!==parseInt(s.toString(),10))throw new Cc(`The ${n} argument must be an integer or tuple of ${e} integers. Received: ${JSON.stringify(t)} including a non-integer number ${a}`)}return t;var s}function Tm(t,e,n,s,r=1){if(null==t)return t;let a;return a="same"===n?t:t-(e+(e-1)*(r-1))+1,Math.floor((a+s-1)/s)}function Em(t,e,n,s){if(null==t)return null;if("valid"===s)t=t*e+Mp([n-e,0]);else{if("same"!==s)throw new Cc(`Unsupport padding mode: ${s}.`);t*=e}return t}function Am(t,e){return Xr((()=>(kp(e),"channelsFirst"===e?uo(t,[0,2,3,1]):t)))}function Dm(t,e){return Xr((()=>(kp(e),"channelsFirst"===e?uo(t,[0,2,3,4,1]):t)))}function $m(t,e,n,s=[1,1],r="valid",a,i,o=null){return Xr((()=>{if(null==a&&(a="channelsLast"),kp(a),3!==t.rank&&4!==t.rank)throw new Cc(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${t.rank}.`);if(3!==e.rank&&4!==e.rank)throw new Cc(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${t.rank}.`);let l=Am(t,a);if("causal"===r)throw new Oc("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return l=So({x:l,filter:e,strides:s,pad:"same"===r?"same":"valid",dilations:i,dataFormat:"NHWC",bias:n,activation:o}),"channelsFirst"===a&&(l=uo(l,[0,3,1,2])),l}))}Im.className="Softmax",Kr(Im);class Mm extends zd{constructor(t,e){if(super(e),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",Mm.verifyArgs(e),this.rank=t,tp(this.rank,"rank"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new Oc(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=Sm(e.kernelSize,t,"kernelSize"),this.strides=Sm(null==e.strides?1:e.strides,t,"strides"),this.padding=null==e.padding?"valid":e.padding,wp(this.padding),this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,kp(this.dataFormat),this.activation=pm(e.activation),this.useBias=null==e.useBias||e.useBias,this.biasInitializer=gd(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=pp(e.biasConstraint),this.biasRegularizer=bm(e.biasRegularizer),this.activityRegularizer=bm(e.activityRegularizer),this.dilationRate=Sm(null==e.dilationRate?1:e.dilationRate,t,"dilationRate"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new Cc(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);if(2===this.rank){if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new Cc(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`)}else if(3===this.rank)if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new Cc(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`)}static verifyArgs(t){if(Bc("kernelSize"in t,"required key 'kernelSize' not in config"),"number"!=typeof t.kernelSize&&!Qc(t.kernelSize,"number",1,3))throw new Cc(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(t.kernelSize)}.`)}getConfig(){const t={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:hm(this.activation),useBias:this.useBias,biasInitializer:md(this.biasInitializer),biasRegularizer:gm(this.biasRegularizer),activityRegularizer:gm(this.activityRegularizer),biasConstraint:hp(this.biasConstraint)},e=super.getConfig();return Object.assign(t,e),t}}class Fm extends Mm{constructor(t,e){super(t,e),this.kernel=null,Fm.verifyArgs(e),this.filters=e.filters,tp(this.filters,"filters"),this.kernelInitializer=gd(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=pp(e.kernelConstraint),this.kernelRegularizer=bm(e.kernelRegularizer)}build(t){t=Id(t);const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e])throw new Cc(`The channel dimension of the input should be defined. Found ${t[e]}`);const n=t[e],s=this.kernelSize.concat([n,this.filters]);this.kernel=this.addWeight("kernel",s,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[e]:n}}],this.built=!0}call(t,e){return Xr((()=>{let e;t=vd(t);const n=null==this.bias?null:this.bias.read(),s=np(this.activation.getClassName());if(null!=s&&2===this.rank)e=$m(t,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate,s);else{if(1===this.rank)e=function(t,e,n,s=1,r="valid",a,i=1){return Xr((()=>{if(null==a&&(a="channelsLast"),kp(a),3!==t.shape.length)throw new Cc(`The input of a conv1dWithBias operation should be 3, but is ${t.shape.length} instead.`);if(3!==e.shape.length)throw new Cc(`The kernel for a conv1dWithBias operation should be 3, but is ${e.shape.length} instead`);if(null!=n&&1!==n.shape.length)throw new Cc(`The bias for a conv1dWithBias operation should be 1, but is ${e.shape.length} instead`);if("channelsFirst"===a&&(t=uo(t,[0,2,1])),"causal"===r)throw new Oc("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let o=Oa(t,e,s,"same"===r?"same":"valid","NWC",i);return null!=n&&(o=qp(o,n)),o}))}(t,this.kernel.read(),n,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)e=$m(t,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate);else{if(3!==this.rank)throw new Oc("convolutions greater than 3D are not implemented yet.");e=function(t,e,n,s=[1,1,1],r="valid",a,i){return Xr((()=>{if(null==a&&(a="channelsLast"),kp(a),4!==t.rank&&5!==t.rank)throw new Cc(`conv3dWithBias expects input to be of rank 4 or 5, but received ${t.rank}.`);if(4!==e.rank&&5!==e.rank)throw new Cc(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${t.rank}.`);let o=Dm(t,a);if("causal"===r)throw new Oc("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return o=Ba(o,e,s,"same"===r?"same":"valid","NDHWC",i),null!=n&&(o=qp(o,n)),"channelsFirst"===a&&(o=uo(o,[0,4,1,2,3])),o}))}(t,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate)}null!=this.activation&&(e=this.activation.apply(e))}return e}))}computeOutputShape(t){t=Id(t);const e=[],n="channelsLast"===this.dataFormat?t.slice(1,t.length-1):t.slice(2);for(let t=0;t<n.length;++t){const s=Tm(n[t],this.kernelSize[t],this.padding,this.strides[t],"number"==typeof this.dilationRate?this.dilationRate:this.dilationRate[t]);e.push(s)}let s=[t[0]];return"channelsLast"===this.dataFormat?(s=s.concat(e),s.push(this.filters)):(s.push(this.filters),s=s.concat(e)),s}getConfig(){const t={filters:this.filters,kernelInitializer:md(this.kernelInitializer),kernelRegularizer:gm(this.kernelRegularizer),kernelConstraint:hp(this.kernelConstraint)},e=super.getConfig();return Object.assign(t,e),t}static verifyArgs(t){if(!("filters"in t)||"number"!=typeof t.filters||t.filters<1)throw new Cc(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(t.filters)}`)}}class _m extends Fm{constructor(t){super(2,t),_m.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if("number"!=typeof t.kernelSize&&!Qc(t.kernelSize,"number",1,2))throw new Cc(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(t.kernelSize)}.`)}}_m.className="Conv2D",Kr(_m);class zm extends Fm{constructor(t){super(3,t),zm.verifyArgs(t)}getConfig(){const t=super.getConfig();return delete t.rank,t}static verifyArgs(t){if("number"!=typeof t.kernelSize&&(!Array.isArray(t.kernelSize)||1!==t.kernelSize.length&&3!==t.kernelSize.length))throw new Cc(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(t.kernelSize)}.`)}}zm.className="Conv3D",Kr(zm);class Cm extends _m{constructor(t){if(super(t),this.inputSpec=[new Dd({ndim:4})],"same"!==this.padding&&"valid"!==this.padding)throw new Cc(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(t){if(4!==(t=Id(t)).length)throw new Cc("Input should have rank 4; Received input shape: "+JSON.stringify(t));const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e])throw new Cc("The channel dimension of the inputs should be defined. Found `None`.");const n=t[e],s=this.kernelSize.concat([this.filters,n]);this.kernel=this.addWeight("kernel",s,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new Dd({ndim:4,axes:{[e]:n}})],this.built=!0}call(t,e){return Xr((()=>{let e=vd(t);if(4!==e.shape.length)throw new Cc(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${e.shape.length}`);const n=e.shape,s=n[0];let r,a;"channelsFirst"===this.dataFormat?(r=2,a=3):(r=1,a=2);const i=n[r],o=n[a],l=this.kernelSize[0],u=this.kernelSize[1],h=this.strides[0],c=this.strides[1],p=[s,Em(i,h,l,this.padding),Em(o,c,u,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(e=uo(e,[0,2,3,1]));let d=Ra(e,this.kernel.read(),p,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(d=uo(d,[0,3,1,2])),null!=this.bias&&(d=qp(d,this.bias.read(),this.dataFormat)),null!=this.activation&&(d=this.activation.apply(d)),d}))}computeOutputShape(t){const e=(t=Id(t)).slice();let n,s,r;"channelsFirst"===this.dataFormat?(n=1,s=2,r=3):(n=3,s=1,r=2);const a=this.kernelSize[0],i=this.kernelSize[1],o=this.strides[0],l=this.strides[1];return e[n]=this.filters,e[s]=Em(e[s],o,a,this.padding),e[r]=Em(e[r],l,i,this.padding),e}getConfig(){const t=super.getConfig();return delete t.dilationRate,t}}Cm.className="Conv2DTranspose",Kr(Cm);class Om extends Fm{constructor(t,e){if(super(t,e),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,null==e.filters)throw new Cc("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(null!=e.kernelInitializer||null!=e.kernelRegularizer||null!=e.kernelConstraint)throw new Cc("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(null!=e.padding&&"same"!==e.padding&&"valid"!==e.padding)throw new Cc(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(e.padding)}`);this.depthMultiplier=null==e.depthMultiplier?1:e.depthMultiplier,this.depthwiseInitializer=gd(e.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=bm(e.depthwiseRegularizer),this.depthwiseConstraint=pp(e.depthwiseConstraint),this.pointwiseInitializer=gd(e.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=bm(e.pointwiseRegularizer),this.pointwiseConstraint=pp(e.pointwiseConstraint)}build(t){if((t=Id(t)).length<this.rank+2)throw new Cc(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank+2}, but received input shape: ${JSON.stringify(t)}`);const e="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[e]||t[e]<0)throw new Cc(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(t[e])}`);const n=t[e],s=this.kernelSize.concat([n,this.depthMultiplier]),r=[];for(let t=0;t<this.rank;++t)r.push(1);r.push(n*this.depthMultiplier,this.filters);const a=!0;this.depthwiseKernel=this.addWeight("depthwise_kernel",s,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,a,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",r,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,a,this.pointwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,a,this.biasConstraint):this.bias=null,this.inputSpec=[new Dd({ndim:this.rank+2,axes:{[e]:n}})],this.built=!0}call(t,e){return Xr((()=>{let e;if(t=vd(t),1===this.rank)throw new Oc("1D separable convolution is not implemented yet.");return 2===this.rank&&("channelsFirst"===this.dataFormat&&(t=uo(t,[0,2,3,1])),e=Vi(t,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(e=qp(e,this.bias.read(),this.dataFormat)),null!=this.activation&&(e=this.activation.apply(e)),"channelsFirst"===this.dataFormat&&(e=uo(e,[0,3,1,2])),e}))}getConfig(){const t=super.getConfig();return delete t.rank,delete t.kernelInitializer,delete t.kernelRegularizer,delete t.kernelConstraint,t.depthwiseInitializer=md(this.depthwiseInitializer),t.pointwiseInitializer=md(this.pointwiseInitializer),t.depthwiseRegularizer=gm(this.depthwiseRegularizer),t.pointwiseRegularizer=gm(this.pointwiseRegularizer),t.depthwiseConstraint=hp(this.depthwiseConstraint),t.pointwiseConstraint=hp(this.pointwiseConstraint),t}}Om.className="SeparableConv";class Lm extends Om{constructor(t){super(2,t)}}Lm.className="SeparableConv2D",Kr(Lm);class Rm extends Fm{constructor(t){super(1,t),Rm.verifyArgs(t),this.inputSpec=[{ndim:3}]}getConfig(){const t=super.getConfig();return delete t.rank,delete t.dataFormat,t}static verifyArgs(t){if("number"!=typeof t.kernelSize&&!Qc(t.kernelSize,"number",1,1))throw new Cc(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(t.kernelSize)}.`)}}Rm.className="Conv1D",Kr(Rm);class Bm extends zd{constructor(t){super(t),"number"==typeof t.cropping?this.cropping=[[t.cropping,t.cropping],[t.cropping,t.cropping]]:"number"==typeof t.cropping[0]?this.cropping=[[t.cropping[0],t.cropping[0]],[t.cropping[1],t.cropping[1]]]:this.cropping=t.cropping,this.dataFormat=void 0===t.dataFormat?"channelsLast":t.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(t){return"channelsFirst"===this.dataFormat?[t[0],t[1],t[2]-this.cropping[0][0]-this.cropping[0][1],t[3]-this.cropping[1][0]-this.cropping[1][1]]:[t[0],t[1]-this.cropping[0][0]-this.cropping[0][1],t[2]-this.cropping[1][0]-this.cropping[1][1],t[3]]}call(t,e){return Xr((()=>{if(t=vd(t),"channelsLast"===this.dataFormat){const e=Lp(t,this.cropping[0][0],t.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return Lp(e,this.cropping[1][0],t.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{const e=Lp(t,this.cropping[0][0],t.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return Lp(e,this.cropping[1][0],t.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}}))}getConfig(){const t={cropping:this.cropping,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}Bm.className="Cropping2D",Kr(Bm);class Wm extends zd{constructor(t){var e;super(t),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==t.size?this.DEFAULT_SIZE:t.size,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,kp(this.dataFormat),this.interpolation=null==t.interpolation?"nearest":t.interpolation,e=this.interpolation,Xc(fp,"InterpolationFormat",e)}computeOutputShape(t){if("channelsFirst"===this.dataFormat){const e=null==t[2]?null:this.size[0]*t[2],n=null==t[3]?null:this.size[1]*t[3];return[t[0],t[1],e,n]}{const e=null==t[1]?null:this.size[0]*t[1],n=null==t[2]?null:this.size[1]*t[2];return[t[0],e,n,t[3]]}}call(t,e){return Xr((()=>{let e=vd(t);const n=e.shape;if("channelsFirst"===this.dataFormat){e=uo(e,[0,2,3,1]);const t=this.size[0]*n[2],s=this.size[1]*n[3],r="nearest"===this.interpolation?e.resizeNearestNeighbor([t,s]):e.resizeBilinear([t,s]);return uo(r,[0,3,1,2])}{const t=this.size[0]*n[1],s=this.size[1]*n[2];return"nearest"===this.interpolation?e.resizeNearestNeighbor([t,s]):e.resizeBilinear([t,s])}}))}getConfig(){const t={size:this.size,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}Wm.className="UpSampling2D",Kr(Wm);class Pm extends Mm{constructor(t){super(2,t),this.depthwiseKernel=null,this.depthMultiplier=null==t.depthMultiplier?1:t.depthMultiplier,this.depthwiseInitializer=gd(t.depthwiseInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.depthwiseConstraint=pp(t.depthwiseConstraint),this.depthwiseRegularizer=bm(t.depthwiseRegularizer)}build(t){if((t=Id(t)).length<4)throw new Cc(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(t)}.`);const e="channelsFirst"===this.dataFormat?1:3;if(null==t[e]||t[e]<0)throw new Cc(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${t[e]}).`);const n=t[e],s=[this.kernelSize[0],this.kernelSize[1],n,this.depthMultiplier];this.depthwiseKernel=this.addWeight("depthwise_kernel",s,null,this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[n*this.depthMultiplier],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return Xr((()=>{let e=function(t,e,n=[1,1],s="valid",r,a){return Xr((()=>{null==r&&(r="channelsLast"),kp(r);let i=Am(t,r);if(4!==t.rank)throw new Cc(`Input for depthwiseConv2d is required to be 4-D, but is instead ${t.rank}-D`);if(4!==e.rank)throw new Cc(`depthwiseKernel is required to be 4-D, but is instead ${e.rank}-D`);return i=Wa(i,e,n,"same"===s?"same":"valid","NHWC",a),"channelsFirst"===r&&(i=uo(i,[0,3,1,2])),i}))}(t=vd(t),this.depthwiseKernel.read(),this.strides,this.padding,this.dataFormat,null);return this.useBias&&(e=qp(e,this.bias.read(),this.dataFormat)),null!=this.activation&&(e=this.activation.apply(e)),e}))}computeOutputShape(t){t=Id(t);const e="channelsFirst"===this.dataFormat?t[2]:t[1],n="channelsFirst"===this.dataFormat?t[3]:t[2],s="channelsFirst"===this.dataFormat?t[1]*this.depthMultiplier:t[3]*this.depthMultiplier,r=Tm(e,this.kernelSize[0],this.padding,this.strides[0]),a=Tm(n,this.kernelSize[1],this.padding,this.strides[1]);return"channelsFirst"===this.dataFormat?[t[0],s,r,a]:[t[0],r,a,s]}getConfig(){const t=super.getConfig();return t.depthMultiplier=this.depthMultiplier,t.depthwiseInitializer=md(this.depthwiseInitializer),t.depthwiseRegularizer=gm(this.depthwiseRegularizer),t.depthwiseConstraint=hp(this.depthwiseRegularizer),t}}function Vm(t,e,n,s){if(Array.isArray(t)){if(null!=e||null!=n)throw new Cc("When inputs is an array, neither initialState or constants should be provided");null!=s&&(n=t.slice(t.length-s,t.length),t=t.slice(0,t.length-s)),t.length>1&&(e=t.slice(1,t.length)),t=t[0]}function r(t){return null==t||Array.isArray(t)?t:[t]}return{inputs:t,initialState:e=r(e),constants:n=r(n)}}function Um(t,e,n,s=!1,r,a,i=!1,o=!1){return Xr((()=>{const l=e.shape.length;if(l<3)throw new Cc(`Input should be at least 3D, but is ${l}D.`);const u=[1,0].concat(Fp(2,l));if(e=uo(e,u),null!=a)throw new Oc("The rnn() functoin of the deeplearn.js backend does not support constants yet.");i&&console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."),null!=r&&((r=r.asType("bool").asType("float32")).rank===l-1&&(r=Ka(r,-1)),r=uo(r,u)),s&&(e=Wi(e,0),null!=r&&(r=Wi(r,0)));const h=[];let c,p=n;const d=e.shape[0],f=ao(e);let m,g;null!=r&&(m=ao(r));for(let e=0;e<d;++e){const n=f[e],s=Xr((()=>t(n,p)));if(null==r)c=s[0],p=s[1];else{const t=Xr((()=>{const t=m[e],n=Mi(t).sub(t);return{output:s[0].mul(t).add(p[0].mul(n)),newStates:p.map(((e,r)=>s[1][r].mul(t).add(e.mul(n))))}}));c=t.output,p=t.newStates}o&&h.push(c)}return o&&(g=to(h,1)),[c,g,p]}))}Pm.className="DepthwiseConv2D",Kr(Pm);class Hm extends zd{constructor(t){let e;if(super(t),null==t.cell)throw new Cc("cell property is missing for the constructor of RNN.");if(e=Array.isArray(t.cell)?new Xm({cells:t.cell}):t.cell,null==e.stateSize)throw new Cc("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");this.cell=e,this.returnSequences=null!=t.returnSequences&&t.returnSequences,this.returnState=null!=t.returnState&&t.returnState,this.goBackwards=null!=t.goBackwards&&t.goBackwards,this._stateful=null!=t.stateful&&t.stateful,this.unroll=null!=t.unroll&&t.unroll,this.supportsMasking=!0,this.inputSpec=[new Dd({ndim:3})],this.stateSpec=null,this.states_=null,this.numConstants=null,this.keptStates=[]}getStates(){return null==this.states_?Fp(0,Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1).map((t=>null)):this.states_}setStates(t){this.states_=t}computeOutputShape(t){xd(t)&&(t=t[0]),t=t;let e=this.cell.stateSize;Array.isArray(e)||(e=[e]);const n=e[0];let s;if(s=this.returnSequences?[t[0],t[1],n]:[t[0],n],this.returnState){const n=[];for(const s of e)n.push([t[0],s]);return[s].concat(n)}return s}computeMask(t,e){return Xr((()=>{Array.isArray(e)&&(e=e[0]);const t=this.returnSequences?e:null;if(this.returnState){const e=this.states.map((t=>null));return[t].concat(e)}return t}))}get states(){if(null==this.states_){const t=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1,e=[];for(let n=0;n<t;++n)e.push(null);return e}return this.states_}set states(t){this.states_=t}build(t){if(null!=this.numConstants)throw new Oc("Constants support is not implemented in RNN yet.");xd(t)&&(t=t[0]),t=t;const e=this.stateful?t[0]:null,n=t.slice(2);this.inputSpec[0]=new Dd({shape:[e,null,...n]});const s=[t[0]].concat(t.slice(2));let r;if(this.cell.build(s),r=Array.isArray(this.cell.stateSize)?this.cell.stateSize:[this.cell.stateSize],null!=this.stateSpec){if(!A(this.stateSpec.map((t=>t.shape[t.shape.length-1])),r))throw new Cc(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`)}else this.stateSpec=r.map((t=>new Dd({shape:[null,t]})));this.stateful&&this.resetStates()}resetStates(t,e=!1){Xr((()=>{if(!this.stateful)throw new _c("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape[0];if(null==n)throw new Cc("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.states_)Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((t=>Di([n,t]))):this.states_=[Di([n,this.cell.stateSize])];else if(null==t)Qr(this.states_),null!=this.keptStates&&(Qr(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((t=>Di([n,t]))):this.states_[0]=Di([n,this.cell.stateSize]);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new Cc(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);!0===e?this.keptStates.push(this.states_.slice()):Qr(this.states_);for(let e=0;e<this.states_.length;++e){const s=t[e],r=Array.isArray(this.cell.stateSize)?this.cell.stateSize[e]:this.cell.stateSize,a=[n,r];if(!A(s.shape,a))throw new Cc(`State ${e} is incompatible with layer ${this.name}: expected shape=${a}, received shape=${s.shape}`);this.states_[e]=s}}this.states_=this.states_.map((t=>ta(t.clone())))}))}apply(t,e){let n=null==e?null:e.initialState,s=null==e?null:e.constants;null==e&&(e={});const r=Vm(t,n,s,this.numConstants);t=r.inputs,n=r.initialState,s=r.constants;let a=[],i=[];if(null!=n){e.initialState=n,a=a.concat(n),this.stateSpec=[];for(const t of n)this.stateSpec.push(new Dd({shape:t.shape}));i=i.concat(this.stateSpec)}if(null!=s&&(e.constants=s,a=a.concat(s),this.numConstants=s.length),a[0]instanceof $d){const n=[t].concat(a),s=this.inputSpec.concat(i),r=this.inputSpec;this.inputSpec=s;const o=super.apply(n,e);return this.inputSpec=r,o}return super.apply(t,e)}call(t,e){return Xr((()=>{const n=null==e?null:e.mask,s=null==e?null:e.training;let r=null==e?null:e.initialState;t=vd(t),null==r&&(r=this.stateful?this.states_:this.getInitialState(t));const a=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;if(r.length!==a)throw new Cc(`RNN Layer has ${a} state(s) but was passed ${r.length} initial state(s).`);this.unroll&&console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");const i={training:s},o=Um(((t,e)=>{const n=this.cell.call([t].concat(e),i);return[n[0],n.slice(1)]}),t,r,this.goBackwards,n,null,this.unroll,this.returnSequences),l=o[0],u=o[1],h=o[2];this.stateful&&this.resetStates(h,s);const c=this.returnSequences?u:l;return this.returnState?[c].concat(h):c}))}getInitialState(t){return Xr((()=>{let e=Di(t.shape);return e=li(e,[1,2]),e=zp(e),Array.isArray(this.cell.stateSize)?this.cell.stateSize.map((t=>t>1?Wp(e,[1,t]):e)):this.cell.stateSize>1?[Wp(e,[1,this.cell.stateSize])]:[e]}))}get trainableWeights(){return this.trainable?this.cell.trainableWeights:[]}get nonTrainableWeights(){return this.trainable?this.cell.nonTrainableWeights:this.cell.weights}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.cell&&this.cell.setFastWeightInitDuringBuild(t)}getConfig(){const t=super.getConfig(),e={returnSequences:this.returnSequences,returnState:this.returnState,goBackwards:this.goBackwards,stateful:this.stateful,unroll:this.unroll};null!=this.numConstants&&(e.numConstants=this.numConstants);const n=this.cell.getConfig();return this.getClassName()===Hm.className&&(e.cell={className:this.cell.getClassName(),config:n}),Object.assign({},n,t,e)}static fromConfig(t,e,n={}){const s=Kd(e.cell,n);return new t(Object.assign(e,{cell:s}))}}Hm.className="RNN",Kr(Hm);class jm extends zd{}class qm extends jm{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,tp(this.units,"units"),this.activation=pm(null==t.activation?this.DEFAULT_ACTIVATION:t.activation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=gd(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=gd(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=gd(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=bm(t.kernelRegularizer),this.recurrentRegularizer=bm(t.recurrentRegularizer),this.biasRegularizer=bm(t.biasRegularizer),this.kernelConstraint=pp(t.kernelConstraint),this.recurrentConstraint=pp(t.recurrentConstraint),this.biasConstraint=pp(t.biasConstraint),this.dropout=$p([1,Mp([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=$p([1,Mp([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){t=Id(t),this.kernel=this.addWeight("kernel",[t[t.length-1],this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return Xr((()=>{if(2!==(t=t).length)throw new Cc(`SimpleRNNCell expects 2 input Tensors, got ${t.length}.`);let n=t[1];t=t[0];const s=null!=e.training&&e.training;let r;0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=Qm({ones:()=>Mi(t),rate:this.dropout,training:s})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=Qm({ones:()=>Mi(n),rate:this.recurrentDropout,training:s}));const a=this.dropoutMask,i=this.recurrentDropoutMask;r=Vp(null!=a?ii(t,a):t,this.kernel.read()),null!=this.bias&&(r=qp(r,this.bias.read())),null!=i&&(n=ii(n,i));let o=aa(r,Vp(n,this.recurrentKernel.read()));return null!=this.activation&&(o=this.activation.apply(o)),[o,o]}))}getConfig(){const t=super.getConfig(),e={units:this.units,activation:hm(this.activation),useBias:this.useBias,kernelInitializer:md(this.kernelInitializer),recurrentInitializer:md(this.recurrentInitializer),biasInitializer:md(this.biasInitializer),kernelRegularizer:gm(this.kernelRegularizer),recurrentRegularizer:gm(this.recurrentRegularizer),biasRegularizer:gm(this.biasRegularizer),activityRegularizer:gm(this.activityRegularizer),kernelConstraint:hp(this.kernelConstraint),recurrentConstraint:hp(this.recurrentConstraint),biasConstraint:hp(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout};return Object.assign({},t,e)}}qm.className="SimpleRNNCell",Kr(qm);class Gm extends Hm{constructor(t){t.cell=new qm(t),super(t)}call(t,e){return Xr((()=>{null!=this.cell.dropoutMask&&(Qr(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(Qr(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const n=null==e?null:e.mask,s=null==e?null:e.training,r=null==e?null:e.initialState;return super.call(t,{mask:n,training:s,initialState:r})}))}static fromConfig(t,e){return new t(e)}}Gm.className="SimpleRNN",Kr(Gm);class Km extends jm{constructor(t){if(super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",t.resetAfter)throw new Cc("GRUCell does not support reset_after parameter set to true.");this.units=t.units,tp(this.units,"units"),this.activation=pm(void 0===t.activation?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=pm(void 0===t.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=gd(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=gd(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=gd(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=bm(t.kernelRegularizer),this.recurrentRegularizer=bm(t.recurrentRegularizer),this.biasRegularizer=bm(t.biasRegularizer),this.kernelConstraint=pp(t.kernelConstraint),this.recurrentConstraint=pp(t.recurrentConstraint),this.biasConstraint=pp(t.biasConstraint),this.dropout=$p([1,Mp([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=$p([1,Mp([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.implementation=t.implementation,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){const e=(t=Id(t))[t.length-1];this.kernel=this.addWeight("kernel",[e,3*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,3*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias?this.bias=this.addWeight("bias",[3*this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.built=!0}call(t,e){return Xr((()=>{if(2!==(t=t).length)throw new Cc(`GRUCell expects 2 input Tensors (inputs, h, c), got ${t.length}.`);const n=null!=e.training&&e.training;let s=t[1];t=t[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=Qm({ones:()=>Mi(t),rate:this.dropout,training:n,count:3})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=Qm({ones:()=>Mi(s),rate:this.recurrentDropout,training:n,count:3}));const r=this.dropoutMask,a=this.recurrentDropoutMask;let i,o,l;0<this.dropout&&this.dropout<1&&(t=ii(t,r[0]));let u=Vp(t,this.kernel.read());this.useBias&&(u=qp(u,this.bias.read())),0<this.recurrentDropout&&this.recurrentDropout<1&&(s=ii(s,a[0]));const h=this.recurrentKernel.read(),[c,p]=Yi(h,[2*this.units,this.units],h.rank-1),d=Vp(s,c),[f,m,g]=Yi(u,3,u.rank-1),[y,b]=Yi(d,2,d.rank-1);i=this.recurrentActivation.apply(aa(f,y)),o=this.recurrentActivation.apply(aa(m,b));const k=Vp(ii(o,s),p);l=this.activation.apply(aa(g,k));const w=aa(ii(i,s),ii(aa(1,Ti(i)),l));return[w,w]}))}getConfig(){const t=super.getConfig(),e={units:this.units,activation:hm(this.activation),recurrentActivation:hm(this.recurrentActivation),useBias:this.useBias,kernelInitializer:md(this.kernelInitializer),recurrentInitializer:md(this.recurrentInitializer),biasInitializer:md(this.biasInitializer),kernelRegularizer:gm(this.kernelRegularizer),recurrentRegularizer:gm(this.recurrentRegularizer),biasRegularizer:gm(this.biasRegularizer),activityRegularizer:gm(this.activityRegularizer),kernelConstraint:hp(this.kernelConstraint),recurrentConstraint:hp(this.recurrentConstraint),biasConstraint:hp(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation,resetAfter:!1};return Object.assign({},t,e)}}Km.className="GRUCell",Kr(Km);class Jm extends Hm{constructor(t){0===t.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new Km(t),super(t)}call(t,e){return Xr((()=>{null!=this.cell.dropoutMask&&(Qr(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(Qr(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const n=null==e?null:e.mask,s=null==e?null:e.training,r=null==e?null:e.initialState;return super.call(t,{mask:n,training:s,initialState:r})}))}static fromConfig(t,e){return 0===e.implmentation&&(e.implementation=1),new t(e)}}Jm.className="GRU",Kr(Jm);class Zm extends jm{constructor(t){super(t),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=t.units,tp(this.units,"units"),this.activation=pm(void 0===t.activation?this.DEFAULT_ACTIVATION:t.activation),this.recurrentActivation=pm(void 0===t.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:t.recurrentActivation),this.useBias=null==t.useBias||t.useBias,this.kernelInitializer=gd(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=gd(t.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=gd(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.unitForgetBias=t.unitForgetBias,this.kernelRegularizer=bm(t.kernelRegularizer),this.recurrentRegularizer=bm(t.recurrentRegularizer),this.biasRegularizer=bm(t.biasRegularizer),this.kernelConstraint=pp(t.kernelConstraint),this.recurrentConstraint=pp(t.recurrentConstraint),this.biasConstraint=pp(t.biasConstraint),this.dropout=$p([1,Mp([0,null==t.dropout?0:t.dropout])]),this.recurrentDropout=$p([1,Mp([0,null==t.recurrentDropout?0:t.recurrentDropout])]),this.implementation=t.implementation,this.stateSize=[this.units,this.units],this.dropoutMask=null,this.recurrentDropoutMask=null}build(t){var e;const n=(t=Id(t))[t.length-1];let s;if(this.kernel=this.addWeight("kernel",[n,4*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,4*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){if(this.unitForgetBias){const t=this.biasInitializer,n=this.units;s=new((e=class extends Yp{apply(e,s){const r=t.apply([n]),a=(new Qp).apply([n]),i=t.apply([2*n]);return Bp(Bp(r,a),i)}}).className="CustomInit",e)}else s=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.units],null,s,this.biasRegularizer,!0,this.biasConstraint)}else this.bias=null;this.built=!0}call(t,e){return Xr((()=>{const n=null!=e.training&&e.training;if(3!==(t=t).length)throw new Cc(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);let s=t[1];const r=t[2];t=t[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=Qm({ones:()=>Mi(t),rate:this.dropout,training:n,count:4})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=Qm({ones:()=>Mi(s),rate:this.recurrentDropout,training:n,count:4}));const a=this.dropoutMask,i=this.recurrentDropoutMask;let o,l,u,h;0<this.dropout&&this.dropout<1&&(t=ii(t,a[0]));let c=Vp(t,this.kernel.read());0<this.recurrentDropout&&this.recurrentDropout<1&&(s=ii(s,i[0])),c=aa(c,Vp(s,this.recurrentKernel.read())),this.useBias&&(c=qp(c,this.bias.read()));const[p,d,f,m]=Yi(c,4,c.rank-1);o=this.recurrentActivation.apply(p),l=this.recurrentActivation.apply(d),u=aa(ii(l,r),ii(o,this.activation.apply(f))),h=this.recurrentActivation.apply(m);const g=ii(h,this.activation.apply(u));return[g,g,u]}))}getConfig(){const t=super.getConfig(),e={units:this.units,activation:hm(this.activation),recurrentActivation:hm(this.recurrentActivation),useBias:this.useBias,kernelInitializer:md(this.kernelInitializer),recurrentInitializer:md(this.recurrentInitializer),biasInitializer:md(this.biasInitializer),unitForgetBias:this.unitForgetBias,kernelRegularizer:gm(this.kernelRegularizer),recurrentRegularizer:gm(this.recurrentRegularizer),biasRegularizer:gm(this.biasRegularizer),activityRegularizer:gm(this.activityRegularizer),kernelConstraint:hp(this.kernelConstraint),recurrentConstraint:hp(this.recurrentConstraint),biasConstraint:hp(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation};return Object.assign({},t,e)}}Zm.className="LSTMCell",Kr(Zm);class Ym extends Hm{constructor(t){0===t.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),t.cell=new Zm(t),super(t)}call(t,e){return Xr((()=>{null!=this.cell.dropoutMask&&(Qr(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(Qr(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null);const n=null==e?null:e.mask,s=null==e?null:e.training,r=null==e?null:e.initialState;return super.call(t,{mask:n,training:s,initialState:r})}))}static fromConfig(t,e){return 0===e.implmentation&&(e.implementation=1),new t(e)}}Ym.className="LSTM",Kr(Ym);class Xm extends jm{constructor(t){super(t),this.cells=t.cells}get stateSize(){const t=[];for(const e of this.cells.slice().reverse())Array.isArray(e.stateSize)?t.push(...e.stateSize):t.push(e.stateSize);return t}call(t,e){return Xr((()=>{let n=(t=t).slice(1);const s=[];for(const t of this.cells.slice().reverse())Array.isArray(t.stateSize)?s.push(n.splice(0,t.stateSize.length)):s.push(n.splice(0,1));s.reverse();const r=[];let a;for(let i=0;i<this.cells.length;++i){const o=this.cells[i];n=s[i],a=0===i?[t[0]].concat(n):[a[0]].concat(n),a=o.call(a,e),r.push(a.slice(1))}n=[];for(const t of r.slice().reverse())n.push(...t);return[a[0]].concat(n)}))}build(t){let e;xd(t)&&(t=t[0]),t=t,this.cells.forEach(((n,s)=>{vp(`RNNCell_${s}`,(()=>{n.build(t),e=Array.isArray(n.stateSize)?n.stateSize[0]:n.stateSize,t=[t[0],e]}))})),this.built=!0}getConfig(){const t=super.getConfig(),e={cells:this.cells.map((t=>({className:t.getClassName(),config:t.getConfig()})))};return Object.assign({},t,e)}static fromConfig(t,e,n={}){const s=[];for(const t of e.cells)s.push(Kd(t,n));return new t({cells:s})}get trainableWeights(){if(!this.trainable)return[];const t=[];for(const e of this.cells)t.push(...e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.cells)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const t of this.cells)e.push(...t.trainableWeights);return e.concat(t)}return t}getWeights(){const t=[];for(const e of this.cells)t.push(...e.weights);return Ed(t)}setWeights(t){const e=[];for(const n of this.cells){const s=n.weights.length,r=t.splice(s);for(let t=0;t<n.weights.length;++t)e.push([n.weights[t],r[t]])}Ad(e)}}function Qm(t){const{ones:e,rate:n,training:s=!1,count:r=1}=t,a=()=>Gp(e(),n),i=()=>Kp(a,e,s);return!r||r<=1?ta(i().clone()):Array(r).fill(void 0).map(i).map((t=>ta(t.clone())))}Xm.className="StackedRNNCells",Kr(Xm);class tg extends Hm{constructor(t){if(t.unroll)throw new Oc("Unrolling is not possible with convolutional RNNs.");if(Array.isArray(t.cell))throw new Oc("It is not possible at the moment to stack convolutional cells.");super(t),this.inputSpec=[new Dd({ndim:5})]}call(t,e){return Xr((()=>{if(null!=this.cell.dropoutMask&&(Qr(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(Qr(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),e&&e.constants)throw new Cc("ConvRNN2D cell does not support constants");const n=null==e?null:e.mask,s=null==e?null:e.training,r=null==e?null:e.initialState;return super.call(t,{mask:n,training:s,initialState:r})}))}computeOutputShape(t){let e=this.computeSingleOutputShape(t);return this.returnSequences||(e=[e[0],...e.slice(2)]),this.returnState&&(e=[e,...Array(2).fill([t[0],...e.slice(-3)])]),e}getInitialState(t){return Xr((()=>{const{stateSize:e}=this.cell,n=t.shape,s=this.computeSingleOutputShape(n),r=Di([s[0],...s.slice(2)]);return Array.isArray(e)?Array(e.length).fill(r):[r]}))}resetStates(t,e=!1){Xr((()=>{if(!this.stateful)throw new _c("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape,s=this.computeSingleOutputShape(n),r=[s[0],...s.slice(2)];if(null==n[0])throw new Cc("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.getStates())Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((()=>Di(r))):this.states_=[Di(r)];else if(null==t)Qr(this.states_),null!=this.keptStates&&(Qr(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map((()=>Di(r))):this.states_[0]=Di(r);else{if(Array.isArray(t)||(t=[t]),t.length!==this.states_.length)throw new Cc(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t.length} state value(s). Input received: ${t}`);e?this.keptStates.push(this.states_.slice()):Qr(this.states_);for(let e=0;e<this.states_.length;++e){const n=t[e],s=r;if(!A(n.shape,s))throw new Cc(`State ${e} is incompatible with layer ${this.name}: expected shape=${s}, received shape=${n.shape}`);this.states_[e]=n}}this.states_=this.states_.map((t=>ta(t.clone())))}))}computeSingleOutputShape(t){const{dataFormat:e,filters:n,kernelSize:s,padding:r,strides:a,dilationRate:i}=this.cell,o="channelsFirst"===e,l=t[o?3:2],u=t[o?4:3],h=Tm(l,s[0],r,a[0],i[0]),c=Tm(u,s[1],r,a[1],i[1]);return[...t.slice(0,2),...o?[n,h,c]:[h,c,n]]}}tg.className="ConvRNN2D";class eg extends Zm{constructor(t){const{filters:e,kernelSize:n,strides:s,padding:r,dataFormat:a,dilationRate:i}=t;super(Object.assign({},t,{units:e})),this.filters=e,tp(this.filters,"filters"),this.kernelSize=Sm(n,2,"kernelSize"),this.kernelSize.forEach((t=>tp(t,"kernelSize"))),this.strides=Sm(s||1,2,"strides"),this.strides.forEach((t=>tp(t,"strides"))),this.padding=r||"valid",wp(this.padding),this.dataFormat=a||"channelsLast",kp(this.dataFormat),this.dilationRate=Sm(i||1,2,"dilationRate"),this.dilationRate.forEach((t=>tp(t,"dilationRate")))}build(t){var e;t=Id(t);const n="channelsFirst"===this.dataFormat?1:t.length-1;if(null==t[n])throw new Cc(`The channel dimension of the input should be defined. Found ${t[n]}`);const s=t[n],r=this.kernelSize.concat([s,4*this.filters]);this.kernel=this.addWeight("kernel",r,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint);const a=this.kernelSize.concat([this.filters,4*this.filters]);if(this.recurrentKernel=this.addWeight("recurrent_kernel",a,null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){let t;if(this.unitForgetBias){const n=this.biasInitializer,s=this.filters;t=new((e=class extends Yp{apply(t,e){return Rp([n.apply([s]),$i([s]),n.apply([2*s])])}}).className="CustomInit",e)}else t=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.filters],null,t,this.biasRegularizer,!0,this.biasConstraint)}this.built=!0}call(t,e){return Xr((()=>{if(3!==t.length)throw new Cc(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${t.length}.`);const n=e.training||!1,s=t[0],r=t[1],a=t[2];0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=Qm({ones:()=>Mi(s),rate:this.dropout,training:n,count:4}));const i=this.dropoutMask,o=(t,e,n)=>e&&e[n]?ii(e[n],t):t;let l=o(s,i,0),u=o(s,i,1),h=o(s,i,2),c=o(s,i,3);0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=Qm({ones:()=>Mi(r),rate:this.recurrentDropout,training:n,count:4}));const p=this.recurrentDropoutMask;let d=o(r,p,0),f=o(r,p,1),m=o(r,p,2),g=o(r,p,3);const[y,b,k,w]=Yi(this.kernel.read(),4,3),[x,N,v,I]=this.useBias?Yi(this.bias.read(),4):[null,null,null,null];l=this.inputConv(l,y,x,this.padding),u=this.inputConv(u,b,N,this.padding),h=this.inputConv(h,k,v,this.padding),c=this.inputConv(c,w,I,this.padding);const[S,T,E,A]=Yi(this.recurrentKernel.read(),4,3);d=this.recurrentConv(d,S),f=this.recurrentConv(f,T),m=this.recurrentConv(m,E),g=this.recurrentConv(g,A);const D=this.recurrentActivation.apply(aa(l,d)),$=this.recurrentActivation.apply(aa(u,f)),M=aa(ii($,a),ii(D,this.activation.apply(aa(h,m)))),F=ii(this.recurrentActivation.apply(aa(c,g)),this.activation.apply(M));return[F,F,M]}))}getConfig(){const t=super.getConfig(),{units:e}=t,n=function(t,e){var n={};for(var s in t)Object.prototype.hasOwnProperty.call(t,s)&&e.indexOf(s)<0&&(n[s]=t[s]);if(null!=t&&"function"==typeof Object.getOwnPropertySymbols){var r=0;for(s=Object.getOwnPropertySymbols(t);r<s.length;r++)e.indexOf(s[r])<0&&Object.prototype.propertyIsEnumerable.call(t,s[r])&&(n[s[r]]=t[s[r]])}return n}(t,["units"]),s={filters:this.filters,kernelSize:this.kernelSize,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,strides:this.strides};return Object.assign({},n,s)}inputConv(t,e,n,s){const r=Ca(t,e,this.strides,s||"valid","channelsFirst"===this.dataFormat?"NCHW":"NHWC",this.dilationRate);return n?qp(r,n,this.dataFormat):r}recurrentConv(t,e){return Ca(t,e,1,"same","channelsFirst"===this.dataFormat?"NCHW":"NHWC")}}eg.className="ConvLSTM2DCell",Kr(eg);class ng extends tg{constructor(t){const e=new eg(t);super(Object.assign({},t,{cell:e}))}static fromConfig(t,e){return new t(e)}}ng.className="ConvLSTM2D",Kr(ng);class sg extends zd{constructor(t){super(t),this.rate=Math.max(Math.min(t.rate,1),0),this.noiseShape=t.noiseShape,this.seed=t.seed,this.supportsMasking=!0}getNoiseShape(t){if(null==this.noiseShape)return this.noiseShape;const e=t.shape,n=[];for(let t=0;t<this.noiseShape.length;++t)n.push(null==this.noiseShape[t]?e[t]:this.noiseShape[t]);return n}call(t,e){return Xr((()=>{this.invokeCallHook(t,e);const n=vd(t);if(0<this.rate&&this.rate<1){const t=null!=e.training&&e.training,s=this.getNoiseShape(n);return Kp((()=>Gp(n,this.rate,s,this.seed)),(()=>n),t)}return t}))}getConfig(){const t={rate:this.rate,noiseShape:this.noiseShape,seed:this.seed},e=super.getConfig();return Object.assign(t,e),t}dispose(){return super.dispose()}}sg.className="Dropout",Kr(sg);class rg extends sg{constructor(t){super(t),this.inputSpec=[{ndim:3}]}getNoiseShape(t){const e=t.shape;return[e[0],1,e[2]]}}rg.className="SpatialDropout1D",Kr(rg);class ag extends zd{constructor(t){if(super(t),this.activation=null,this.useBias=!0,this.kernel=null,this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",null==t.batchInputShape&&null==t.inputShape&&null!=t.inputDim){let e=null;null!=t.batchSize&&(e=t.batchSize),this.batchInputShape=[e,t.inputDim]}this.units=t.units,tp(this.units,"units"),this.activation=pm(t.activation),null!=t.useBias&&(this.useBias=t.useBias),this.kernelInitializer=gd(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.biasInitializer=gd(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelConstraint=pp(t.kernelConstraint),this.biasConstraint=pp(t.biasConstraint),this.kernelRegularizer=bm(t.kernelRegularizer),this.biasRegularizer=bm(t.biasRegularizer),this.activityRegularizer=bm(t.activityRegularizer),this.supportsMasking=!0,this.inputSpec=[{minNDim:2}]}build(t){const e=(t=Id(t))[t.length-1];null==this.kernel&&(this.kernel=this.addWeight("kernel",[e,this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint))),this.inputSpec=[{minNDim:2,axes:{[-1]:e}}],this.built=!0}computeOutputShape(t){const e=(t=Id(t)).slice();return e[e.length-1]=this.units,e}call(t,e){return Xr((()=>{this.invokeCallHook(t,e);const n=vd(t),s=np(this.activation.getClassName());let r;return null!=s?r=Vp(n,this.kernel.read(),s,this.bias?this.bias.read():null):(r=Vp(n,this.kernel.read()),null!=this.bias&&(r=qp(r,this.bias.read())),null!=this.activation&&(r=this.activation.apply(r))),r}))}getConfig(){const t={units:this.units,activation:hm(this.activation),useBias:this.useBias,kernelInitializer:md(this.kernelInitializer),biasInitializer:md(this.biasInitializer),kernelRegularizer:gm(this.kernelRegularizer),biasRegularizer:gm(this.biasRegularizer),activityRegularizer:gm(this.activityRegularizer),kernelConstraint:hp(this.kernelConstraint),biasConstraint:hp(this.biasConstraint)},e=super.getConfig();return Object.assign(t,e),t}}ag.className="Dense",Kr(ag);class ig extends zd{constructor(t){super(t=t||{}),this.inputSpec=[{minNDim:3}],this.dataFormat=t.dataFormat}computeOutputShape(t){t=Id(t);for(const e of t.slice(1))if(null==e)throw new Cc(`The shape of the input to "Flatten" is not fully defined (got ${t.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);return[t[0],Ap(t,1)]}call(t,e){return Xr((()=>{this.invokeCallHook(t,e);let n=vd(t);if("channelsFirst"===this.dataFormat&&n.rank>1){const t=[0];for(let e=2;e<n.rank;++e)t.push(e);t.push(1),n=n.transpose(t)}return function(t){if(t.rank<=1)throw new Cc(`batchFlatten requires a minimum rank of 2. Got rank: ${t.rank}.`);const e=[t.shape[0],Ap(t.shape,1)];return t.reshape(e)}(n)}))}getConfig(){const t={};null!=this.dataFormat&&(t.dataFormat=this.dataFormat);const e=super.getConfig();return Object.assign(t,e),t}}ig.className="Flatten",Kr(ig);class og extends zd{constructor(t){super(t),this.supportsMasking=!0,this.activation=pm(t.activation)}call(t,e){return Xr((()=>{this.invokeCallHook(t,e);const n=vd(t);return this.activation.apply(n)}))}getConfig(){const t={activation:hm(this.activation)},e=super.getConfig();return Object.assign(t,e),t}}og.className="Activation",Kr(og);class lg extends zd{constructor(t){super(t),this.n=t.n,this.inputSpec=[{ndim:2}]}computeOutputShape(t){return[t[0],this.n,t[1]]}call(t,e){return Xr((()=>{return t=vd(t),e=t,n=this.n,Xr((()=>{if(2!==e.shape.length)throw new Cc(`repeat() expects a rank-2 tensor, but received a rank-${e.shape.length} tensor.`);return Wp(zp(e,1),[1,n,1])}));var e,n}))}getConfig(){const t={n:this.n},e=super.getConfig();return Object.assign(t,e),t}}lg.className="RepeatVector",Kr(lg);class ug extends zd{constructor(t){super(t),this.targetShape=t.targetShape;for(let t=0;t<this.targetShape.length;++t)this.isUnknown(this.targetShape[t])&&(this.targetShape[t]=null)}isUnknown(t){return t<0||null==t}fixUnknownDimension(t,e){const n="Total size of new array must be unchanged.",s=e.slice();let r=1,a=null;for(let t=0;t<s.length;++t){const e=s[t];if(this.isUnknown(e)){if(null!==a)throw new Cc("Can only specifiy one unknown dimension.");a=t}else r*=e}const i=Ap(t);if(null!==a){if(0===r||i%r!=0)throw new Cc(n);s[a]=i/r}else if(i!==r)throw new Cc(n);return s}computeOutputShape(t){let e=!1;for(let n=0;n<t.length;++n)if(this.isUnknown(t[n])){e=!0;break}return e?t.slice(0,1).concat(this.targetShape):t.slice(0,1).concat(this.fixUnknownDimension(t.slice(1),this.targetShape))}call(t,e){return Xr((()=>{this.invokeCallHook(t,e);const n=vd(t),s=n.shape,r=s.slice(0,1).concat(this.fixUnknownDimension(s.slice(1),this.targetShape));return n.reshape(r)}))}getConfig(){const t={targetShape:this.targetShape},e=super.getConfig();return Object.assign(t,e),t}}ug.className="Reshape",Kr(ug);class hg extends zd{constructor(t){if(super(t),null==t.dims)throw new Error("Required configuration field `dims` is missing during Permute constructor call.");if(!Array.isArray(t.dims))throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${t.dims} instead.`);const e=Fp(1,t.dims.length+1);if(!A(t.dims.slice().sort(),e))throw new Error("Invalid permutation `dims`: "+JSON.stringify(t.dims)+" `dims` must contain consecutive integers starting from 1.");this.dims=t.dims,this.dimsIncludingBatch=[0].concat(this.dims),this.inputSpec=[new Dd({ndim:this.dims.length+1})]}computeOutputShape(t){const e=(t=Id(t)).slice();return this.dims.forEach(((n,s)=>{e[s+1]=t[n]})),e}call(t,e){return uo(vd(t),this.dimsIncludingBatch)}getConfig(){const t={dims:this.dims},e=super.getConfig();return Object.assign(t,e),t}}hg.className="Permute",Kr(hg);class cg extends zd{constructor(t){super(null==t?{}:t),this.supportsMasking=!0,this.maskValue=null!=t?null==t.maskValue?0:t.maskValue:0}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={maskValue:this.maskValue};return Object.assign(e,t),e}computeMask(t,e){const n=vd(t);return oa(Ei(n,this.maskValue),-1)}call(t,e){return Xr((()=>{this.invokeCallHook(t,e);const n=vd(t),s=oa(Ei(n,this.maskValue),-1,!0);return n.mul(s.asType(n.dtype))}))}}cg.className="Masking",Kr(cg);class pg extends zd{constructor(t){if(super(t),this.embeddings=null,this.DEFAULT_EMBEDDINGS_INITIALIZER="randomUniform",null==t.batchInputShape&&null==t.inputShape){let e=null;null!=t.batchSize&&(e=t.batchSize),null==t.inputLength?this.batchInputShape=[e,null]:this.batchInputShape=[e].concat(Vc(t.inputLength))}this.inputDim=t.inputDim,tp(this.inputDim,"inputDim"),this.outputDim=t.outputDim,tp(this.outputDim,"outputDim"),this.embeddingsInitializer=gd(t.embeddingsInitializer||this.DEFAULT_EMBEDDINGS_INITIALIZER),this.embeddingsRegularizer=bm(t.embeddingsRegularizer),this.activityRegularizer=bm(t.activityRegularizer),this.embeddingsConstraint=pp(t.embeddingsConstraint),this.maskZero=t.maskZero,this.supportsMasking=t.maskZero,this.inputLength=t.inputLength}build(t){this.embeddings=this.addWeight("embeddings",[this.inputDim,this.outputDim],this.dtype,this.embeddingsInitializer,this.embeddingsRegularizer,!0,this.embeddingsConstraint),this.built=!0}warnOnIncompatibleInputShape(t){}computeMask(t,e){return Xr((()=>this.maskZero?(t=vd(t),Ei(t,lo(t))):null))}computeOutputShape(t){if(t=Id(t),null==this.inputLength)return[...t,this.outputDim];const e=Vc(this.inputLength);if(e.length!==t.length-1)throw new Cc(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);{let n=0;for(let s=0;s<e.length;++s){const r=e[s],a=t[s+1];if(null!=r&&null!=a&&r!==a)throw new Cc(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t}`);null==r&&(e[n]=a),n++}}return[t[0],...e,this.outputDim]}call(t,e){return Xr((()=>{this.invokeCallHook(t,e);let n=vd(t);return"int32"!==n.dtype&&(n=_p(n,"int32")),Up(this.embeddings.read(),n.as1D()).reshape(Id(this.computeOutputShape(n.shape)))}))}getConfig(){const t={inputDim:this.inputDim,outputDim:this.outputDim,embeddingsInitializer:md(this.embeddingsInitializer),embeddingsRegularizer:gm(this.embeddingsRegularizer),activityRegularizer:gm(this.activityRegularizer),embeddingsConstraint:hp(this.embeddingsConstraint),maskZero:this.maskZero,inputLength:this.inputLength},e=super.getConfig();return Object.assign(t,e),t}}pg.className="Embedding",Kr(pg);class dg extends zd{constructor(t){super(t||{}),this.supportsMasking=!0}mergeFunction(t){throw new Oc}computeElementwiseOpOutputShape(t,e){if(null==t||null==e)return null;if(t.length<e.length)return this.computeElementwiseOpOutputShape(e,t);if(0===e.length)return t;const n=t.slice(0,t.length-e.length);for(let s=0;s<e.length;++s){const r=t[t.length-e.length+s],a=e[s];if(null==r||null==a||r<0||a<0)n.push(null);else if(1===r)n.push(a);else if(1===a)n.push(r);else{if(r!==a)throw new Cc("Operands could not be broadcast together with shapes "+JSON.stringify(t)+" "+JSON.stringify(e));n.push(r)}}return n}build(t){if(Array.isArray(t)&&!Array.isArray(t[0])&&(t=[Id(t)]),(t=t).length<2)throw new Cc(`A merge layer should be called on an Array of at least 2 inputs. Got ${t.length} input(s).`);let e=[];for(const n of t)null!=n&&null!==n[0]&&e.push(n[0]);if(e=Zc(e),e.length>1)throw new Cc(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(t)}.`);let n=null==t[0]?null:t[0].slice(1);for(let e=1;e<t.length;++e){const s=null==t[e]?null:t[e].slice(1);n=this.computeElementwiseOpOutputShape(n,s)}const s=t.map((t=>t.length));-1===t.indexOf(null)&&1===Zc(s).length?this.reshapeRequired=!1:this.reshapeRequired=!0}call(t,e){return Xr((()=>{if(t=t,this.reshapeRequired){const e=[],n=t.map((t=>t.rank));if(-1===n.indexOf(null)){const s=Mp(n);for(let n of t){const t=n.rank;for(let e=0;e<s-t;++e)n=zp(n,1);e.push(n)}return this.mergeFunction(e)}{let n=!1;for(const s of t){const t=s.rank;if(null==t){const t=s.shape,r=t[0],a=t.slice(1).concat([r]);let i=s.reshape([r].concat(Ap(t.slice(1))));i=uo(i,[1,0]),i=i.reshape(a),e.push(i),n=!0}else if(t>1){const r=Fp(1,t).concat([0]);e.push(uo(s,r)),n=!0}else e.push(s)}let s=this.mergeFunction(e);const r=s.rank;if(n)if(null==r){const t=s.shape,e=t[t.length-1],n=[e].concat(t.slice(0,t.length-1));s=uo(s.reshape([-1,e]),[1,0]).reshape(n)}else if(r>1){const t=[r-1].concat(Fp(0,r-1));s=uo(s,t)}return s}}return this.mergeFunction(t)}))}computeOutputShape(t){let e;e=null==(t=t)[0]?null:t[0].slice(1);for(let n=1;n<t.length;++n){const s=null==t[n]?null:t[n].slice(1);e=this.computeElementwiseOpOutputShape(e,s)}let n=[];for(const e of t)null!=e&&null!==e[0]&&n.push(e[0]);return n=Zc(n),e=1===n.length?n.concat(e):[null].concat(e),e}computeMask(t,e){return Xr((()=>{if(null==e)return null;if(!Array.isArray(e))throw new Cc("`mask` should be an Array");if(!Array.isArray(t))throw new Cc("`inputs` should be an Array");if(e.length!==t.length)throw new Cc(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${t.length} vs ${e.length})`);if(e.every((t=>null==t)))return null;let n=(e=e.map((t=>null==t?t:Ka(t,0))))[0];for(let t=1;t<e.length-1;++t)n=hi(n,e[t]);return n}))}}class fg extends dg{constructor(t){super(t)}mergeFunction(t){return Xr((()=>{let e=t[0].clone();for(let n=1;n<t.length;++n)e=aa(e,t[n]);return e}))}}fg.className="Add",Kr(fg);class mg extends dg{constructor(t){super(t)}mergeFunction(t){return Xr((()=>{let e=t[0].clone();for(let n=1;n<t.length;++n)e=ii(e,t[n]);return e}))}}mg.className="Multiply",Kr(mg);class gg extends dg{constructor(t){super(t)}mergeFunction(t){return Xr((()=>{let e=t[0].clone();for(let n=1;n<t.length;++n)e=aa(e,t[n]);return ii(1/t.length,e)}))}}gg.className="Average",Kr(gg);class yg extends dg{constructor(t){super(t)}mergeFunction(t){return Xr((()=>{let e=t[0];for(let n=1;n<t.length;++n)e=di(e,t[n]);return e}))}}yg.className="Maximum",Kr(yg);class bg extends dg{constructor(t){super(t)}mergeFunction(t){return Xr((()=>{let e=t[0];for(let n=1;n<t.length;++n)e=gi(e,t[n]);return e}))}}bg.className="Minimum",Kr(bg);class kg extends dg{constructor(t){super(t),this.DEFAULT_AXIS=-1,null==t&&(t={}),this.axis=null==t.axis?this.DEFAULT_AXIS:t.axis,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){if(!Array.isArray(t)||!Array.isArray(t[0])||1===t.length)throw new Cc("A `Concatenate` layer should be called on a list of at least 2 inputs");t=t;let e=!0;for(const n of t)if(null!=n){e=!1;break}if(e)return;const n=[];for(let e=0;e<t.length;++e){const s=t[e].slice();s.splice(this.axis,1);let r=!1;for(const t of n)if(A(t,s)){r=!0;break}r||n.push(s)}if(n.length>1)throw new Cc("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: "+JSON.stringify(t))}mergeFunction(t){return Xr((()=>Rp(t,this.axis)))}computeOutputShape(t){if(!Array.isArray(t)||!Array.isArray(t[0]))throw new Cc("A `Concatenate` layer should be called on a list of inputs.");const e=t,n=e[0].slice(),s=this.axis<0?n.length+this.axis:this.axis;for(const t of e.slice(1)){if(null==n[s]||null==t[s]){n[s]=null;break}n[s]+=t[s]}return n}computeMask(t,e){if(null==e)return null;if(!Array.isArray(e))throw new Cc("`mask` should be an array for Concatenate");if(!Array.isArray(t))throw new Cc("`inputs` should be an array for Concatenate");if(e.length!==t.length)throw new Cc(`Mismatch in the length of mask (${e.length}) and the legnth of inputs (${t.length})`);return Xr((()=>{let n=!0;if(e.forEach((t=>{null==t||(n=!1)})),n)return null;const s=[];for(let n=0;n<t.length;++n)null==e[n]?s.push(Mi(t[n]).asType("bool")):e[n].rank<t[n].rank?s.push(Ka(e[n],-1)):s.push(e[n]);const r=$a(s,this.axis);return ia(r,-1,!1)}))}getConfig(){const t={axis:this.axis},e=super.getConfig();return Object.assign(t,e),t}}function wg(t,e){for(;t<0;)t+=e;return t}kg.className="Concatenate",Kr(kg);class xg extends dg{constructor(t){super(t),this.axes=t.axes,this.normalize=null!=t.normalize&&t.normalize,this.supportsMasking=!0,this.reshapeRequired=!1}build(t){v(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),(()=>"A `Dot` layer should be called on a list of exactly 2 inputs."));const e=t[0],n=t[1];if(e.length>3||n.length>3)throw new Oc("Dot layer does not support tensors of 4D or higher rank yet.");const s=this.interpretAxes(e,n);if(e[s[0]]!==n[s[1]])throw new Cc(`Dimension incompatibility: ${e[s[0]]} !== ${n[s[1]]}`)}mergeFunction(t){if(2!==t.length)throw new Cc(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${t.length} input(s).`);let e,n=t[0],s=t[1];return e=Array.isArray(this.axes)?this.axes.map(((e,n)=>wg(e,t[n].shape.length))):[wg(this.axes,n.shape.length),wg(this.axes,s.shape.length)],this.normalize&&(n=Jd(n,e[0]),s=Jd(s,e[1])),function(t,e,n){if(t.shape.length>3||e.shape.length>3)throw new Oc("batchDot is not implemented for tensors of 4D or higher rank yet");if(v(t.shape.length>=2,(()=>`batchDot requires the rank of x to be >= 2, but got ${t.shape.length}`)),v(t.shape.length>=2,(()=>`batchDot requires the rank of y to be >= 2, but got ${e.shape.length}`)),"number"==typeof n&&(n=[n,n]),"complex64"===t.dtype||"complex64"===e.dtype)throw new Oc("batchDot is not implemented for complex64-type Tensors yet.");const s=t.shape.length,r=e.shape.length;null==n&&(n=[s-1,r-2]);const a=n;return Xr((()=>{let n,i;if(s>r){n=s-r;const t=[];for(let e=0;e<n;++e)t.push(1);e=e.reshape(e.shape.concat(t))}else if(r>s){n=r-s;const e=[];for(let t=0;t<n;++t)e.push(1);t=t.reshape(t.shape.concat(e))}else n=0;if(2===t.shape.length&&2===e.shape.length)i=a[0]===a[1]?t.mul(e).sum(a[0]):t.transpose([1,0]).mul(e).sum(a[1]);else{const n=a[0]!==t.shape.length-1,s=a[1]===e.shape.length-1;i=t.matMul(e,n,s)}if(n>0){let t;t=s>r?s+r-3:s-1;const e=[];for(let s=t;s<t+n;++s)e.push(s);i=i.squeeze(e)}return 1===i.shape.length&&(i=i.expandDims(1)),i}))}(n,s,e)}interpretAxes(t,e){let n;return n=Array.isArray(this.axes)?this.axes:[wg(this.axes,t.length),wg(this.axes,e.length)],n}computeOutputShape(t){v(Array.isArray(t)&&2===t.length&&Array.isArray(t[0])&&Array.isArray(t[1]),(()=>"A `Dot` layer should be called on a list of exactly 2 inputs."));const e=t[0].slice(),n=t[1].slice();if(e.length>3||n.length>3)throw new Oc("Dot layer does not support tensors of 4D or higher rank yet.");const s=this.interpretAxes(e,n);e.splice(s[0],1),n.splice(s[1],1),n.splice(0,1);const r=e.concat(n);return 1===r.length&&r.push(1),r}computeMask(t,e){return null}getConfig(){const t={axes:this.axes,normalize:this.normalize},e=super.getConfig();return Object.assign(t,e),t}}xg.className="Dot",Kr(xg);class Ng extends zd{constructor(t){super(t),this.supportsMasking=!0,this.stddev=t.stddev}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={stddev:this.stddev};return Object.assign(e,t),e}call(t,e){return Xr((()=>{this.invokeCallHook(t,e);const n=vd(t);return Kp((()=>Pp(n.shape,0,this.stddev).add(n)),(()=>n),e.training||!1)}))}}Ng.className="GaussianNoise",Kr(Ng);class vg extends zd{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return Xr((()=>{this.invokeCallHook(t,e);const n=vd(t);return this.rate>0&&this.rate<1?Kp((()=>{const t=Math.sqrt(this.rate/(1-this.rate));return n.mul(Pp(n.shape,1,t))}),(()=>n),e.training||!1):n}))}}vg.className="GaussianDropout",Kr(vg);class Ig extends zd{constructor(t){super(t),this.supportsMasking=!0,this.rate=t.rate,this.noiseShape=t.noiseShape}_getNoiseShape(t){return this.noiseShape||vd(t).shape}computeOutputShape(t){return t}getConfig(){const t=super.getConfig(),e={rate:this.rate};return Object.assign(e,t),e}call(t,e){return Xr((()=>{if(this.rate<1&&this.rate>0){const n=this._getNoiseShape(t);return Kp((()=>{const e=vd(t),s=-1.7580993408473766;let r=ei(Ri(n),this.rate);r=_p(r,"float32");const a=((1-this.rate)*(1+this.rate*s**2))**-.5,i=-a*s*this.rate;return e.mul(r).add(r.add(-1).mul(s)).mul(a).add(i)}),(()=>vd(t)),e.training||!1)}return t}))}}function Sg(t,e,n,s,r,a=.001){let i;if(2===t.rank)i=Ta(t,e,n,s,r,a);else if(3===t.rank)i=Ea(t,e,n,s,r,a);else{if(4!==t.rank)throw new Oc(`batchNormalization is not implemented for array of rank ${t.rank} yet`);i=Aa(t,e,n,s,r,a)}return i}Ig.className="AlphaDropout",Kr(Ig);class Tg extends zd{constructor(t){null==t&&(t={}),super(t),this.supportsMasking=!0,this.axis=null==t.axis?-1:t.axis,this.momentum=null==t.momentum?.99:t.momentum,this.epsilon=null==t.epsilon?.001:t.epsilon,this.center=null==t.center||t.center,this.scale=null==t.scale||t.scale,this.betaInitializer=gd(t.betaInitializer||"zeros"),this.gammaInitializer=gd(t.gammaInitializer||"ones"),this.movingMeanInitializer=gd(t.movingMeanInitializer||"zeros"),this.movingVarianceInitializer=gd(t.movingVarianceInitializer||"ones"),this.betaConstraint=pp(t.betaConstraint),this.gammaConstraint=pp(t.gammaConstraint),this.betaRegularizer=bm(t.betaRegularizer),this.gammaRegularizer=bm(t.gammaRegularizer)}build(t){t=Id(t);const e=this.axis>=0?this.axis:this.axis+t.length,n=t[e];if(null==n)throw new Cc(`Axis ${e} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(t)}.`);this.inputSpec=[new Dd({ndim:t.length,axes:{[e]:n}})];const s=[n];this.scale&&(this.gamma=this.addWeight("gamma",s,null,this.gammaInitializer,this.gammaRegularizer,!0,this.gammaConstraint)),this.center&&(this.beta=this.addWeight("beta",s,null,this.betaInitializer,this.betaRegularizer,!0,this.betaConstraint)),this.movingMean=this.addWeight("moving_mean",s,null,this.movingMeanInitializer,null,!1),this.movingVariance=this.addWeight("moving_variance",s,null,this.movingVarianceInitializer,null,!1),this.built=!0}call(t,e){return Xr((()=>{const n=null!=e.training&&e.training,s=vd(t),r=s.shape,a=r.length,i=Fp(0,a),o=this.axis>=0?this.axis:this.axis+a;i.splice(o,1);const l=Rc(1,a);l[o]=r[o];const u=i.slice();u.sort();const h=!A(u,Fp(0,a).slice(0,a-1));if(!n)return(()=>{if(h){const t=this.movingMean.read().reshape(l),e=this.movingVariance.read().reshape(l),n=this.center?this.beta.read().reshape(l):null,r=this.scale?this.gamma.read().reshape(l):null;return Sg(s,t,e,n,r,this.epsilon)}return Sg(s,this.movingMean.read(),this.movingVariance.read(),null==this.beta?null:this.beta.read(),null==this.gamma?null:this.gamma.read(),this.epsilon)})();const[c,p,d]=function(t,e,n,s,r=.001){return A(s.slice().sort(),Fp(0,t.rank-1))?function(t,e,n,s,r=.001){return Xr((()=>{const a=Si(t,s),i=a.mean,o=a.variance;return[Sg(t,i,o,n,e,r),i,o]}))}(t,e,n,s,r):function(t,e,n,s,r=.001){return Xr((()=>{const a=Si(t,s),i=a.mean,o=a.variance,l=[];for(const e of Fp(0,t.rank))-1!==s.indexOf(e)?l.push(1):l.push(t.shape[e]);const u=i.reshape(l),h=o.reshape(l),c=null==e?null:e.reshape(l),p=null==n?null:n.reshape(l);return[Sg(t,u,h,p,c,r),i,o]}))}(t,e,n,s,r)}(s,this.gamma.read(),this.beta.read(),i,this.epsilon),f=(t,e,n)=>{Xr((()=>{const s=1-n,r=t.read(),a=r.sub(e).mul(s);t.write(r.sub(a))}))};return(()=>{f(this.movingMean,p,this.momentum),f(this.movingVariance,d,this.momentum)})(),c}))}getConfig(){const t={axis:this.axis,momentum:this.momentum,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:md(this.betaInitializer),gammaInitializer:md(this.gammaInitializer),movingMeanInitializer:md(this.movingMeanInitializer),movingVarianceInitializer:md(this.movingVarianceInitializer),betaRegularizer:gm(this.betaRegularizer),gammaRegularizer:gm(this.gammaRegularizer),betaConstraint:hp(this.betaConstraint),gammaConstraint:hp(this.gammaConstraint)},e=super.getConfig();return Object.assign(t,e),t}}Tg.className="BatchNormalization",Kr(Tg);class Eg extends zd{constructor(t){if(null==t&&(t={}),super(t),this.axis=null==t.axis?-1:t.axis,"number"==typeof this.axis){if(!Number.isInteger(this.axis))throw new Error(`Expected axis to be an integer, but received ${this.axis}`)}else{if(!Array.isArray(this.axis))throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);for(const t of this.axis)if(!Number.isInteger(t))throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`)}this.epsilon=null==t.epsilon?.001:t.epsilon,this.center=null==t.center||t.center,this.scale=null==t.scale||t.scale,this.betaInitializer=gd(t.betaInitializer||"zeros"),this.gammaInitializer=gd(t.gammaInitializer||"ones"),this.betaRegularizer=bm(t.betaRegularizer),this.gammaRegularizer=bm(t.gammaRegularizer),this.supportsMasking=!0}build(t){const e=(t=Id(t)).length;"number"==typeof this.axis&&(this.axis=[this.axis]);for(let t=0;t<this.axis.length;++t)this.axis[t]<0&&(this.axis[t]+=e);for(const t of this.axis)if(t<0||t>=e)throw new Error(`Invalid axis: ${t}`);if(this.axis.length!==Zc(this.axis).length)throw new Error(`Found duplicate axes in: ${this.axis}`);const n=this.axis.map((e=>t[e]));this.scale?this.gamma=this.addWeight("gamma",n,"float32",this.gammaInitializer,this.gammaRegularizer,!0):this.gamma=null,this.center?this.beta=this.addWeight("beta",n,"float32",this.betaInitializer,this.betaRegularizer,!0):this.beta=null,this.built=!0}call(t,e){const n=vd(t),s=n.shape,r=s.length;return Xr((()=>{let{mean:t,variance:e}=Si(n,this.axis,!0);const a=Rc(1,r);for(const t of this.axis)a[t]=s[t];const i=t=>null!=t&&t.shape.length!==r&&this.axis!==[r-1]?t.reshape(a):t;let o=i(this.gamma.read()),l=i(this.beta.read());const u=[],h=[];for(let t=0;t<r;++t)-1!==this.axis.indexOf(t)?(u.push(s[t]),h.push(1)):(u.push(1),h.push(s[t]));return t=t.tile(u),e=e.tile(u),o=o.tile(h),l=l.tile(h),Sg(n,t,e,l,o,this.epsilon)}))}getConfig(){const t={axis:this.axis,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:md(this.betaInitializer),gammaInitializer:md(this.gammaInitializer),betaRegularizer:gm(this.betaRegularizer),gammaRegularizer:gm(this.gammaRegularizer)},e=super.getConfig();return Object.assign(t,e),t}}Eg.className="LayerNormalization",Kr(Eg);class Ag extends zd{constructor(t){if(null==t&&(t={}),super(t),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,null==t.padding)this.padding=[[1,1],[1,1]];else if("number"==typeof t.padding)this.padding=[[t.padding,t.padding],[t.padding,t.padding]];else{if(t.padding=t.padding,2!==t.padding.length)throw new Cc(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${t.padding.length} array.`);let e,n;if("number"==typeof t.padding[0])e=[t.padding[0],t.padding[0]],n=[t.padding[1],t.padding[1]];else{if(t.padding=t.padding,2!==t.padding[0].length)throw new Cc(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${t.padding[0].length} array.`);if(e=t.padding[0],2!==t.padding[1].length)throw new Cc(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${t.padding[1].length} array.`);n=t.padding[1]}this.padding=[e,n]}this.inputSpec=[new Dd({ndim:4})]}computeOutputShape(t){let e,n;return t=Id(t),"channelsFirst"===this.dataFormat?(e=null!=t[2]&&t[2]>=0?t[2]+this.padding[0][0]+this.padding[0][1]:null,n=null!=t[3]&&t[3]>=0?t[3]+this.padding[1][0]+this.padding[1][1]:null,[t[0],t[1],e,n]):(e=null!=t[1]&&t[1]>=0?t[1]+this.padding[0][0]+this.padding[0][1]:null,n=null!=t[2]&&t[2]>=0?t[2]+this.padding[1][0]+this.padding[1][1]:null,[t[0],e,n,t[3]])}call(t,e){return Xr((()=>{return e=vd(t),n=this.padding,s=this.dataFormat,Xr((()=>{if(4!==e.rank)throw new Cc(`temporalPadding expects input tensor to be 4-D, but received a ${e.rank}-D tensor.`);if(null==n&&(n=[[1,1],[1,1]]),2!==n.length||2!==n[0].length||2!==n[1].length)throw new Cc("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");if(null==s&&(s="channelsLast"),"channelsLast"!==s&&"channelsFirst"!==s)throw new Cc(`Unknown data format: ${s}. Supported data formats are 'channelsLast' and 'channelsFirst.`);let t;return t="channelsFirst"===s?[[0,0],[0,0],n[0],n[1]]:[[0,0],n[0],n[1],[0,0]],Fi(e,t)}));var e,n,s}))}getConfig(){const t={padding:this.padding,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}function Dg(t,e,n,s,r,a){return Xr((()=>{let i;kp(r),xp(a),wp(s),null==n&&(n=[1,1]),null==s&&(s="valid"),null==r&&(r="channelsLast"),null==a&&(a="max"),t=Am(t,r);const o="same"===s?"same":"valid";return i="max"===a?ci(t,e,n,o):va(t,e,n,o),"channelsFirst"===r&&(i=uo(i,[0,3,1,2])),i}))}function $g(t,e,n,s,r,a){return Xr((()=>{let i;kp(r),xp(a),wp(s),null==n&&(n=[1,1,1]),null==s&&(s="valid"),null==r&&(r="channelsLast"),null==a&&(a="max"),t=Dm(t,r);const o="same"===s?"same":"valid";return i="max"===a?pi(t,e,n,o):Ia(t,e,n,o),"channelsFirst"===r&&(i=uo(i,[0,4,1,2,3])),i}))}Ag.className="ZeroPadding2D",Kr(Ag);class Mg extends zd{constructor(t){if(null==t.poolSize&&(t.poolSize=2),super(t),"number"==typeof t.poolSize)this.poolSize=[t.poolSize];else{if(!Array.isArray(t.poolSize)||1!==t.poolSize.length||"number"!=typeof t.poolSize[0])throw new Cc(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.poolSize)}`);this.poolSize=t.poolSize}if(tp(this.poolSize,"poolSize"),null==t.strides)this.strides=this.poolSize;else if("number"==typeof t.strides)this.strides=[t.strides];else{if(!Array.isArray(t.strides)||1!==t.strides.length||"number"!=typeof t.strides[0])throw new Cc(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t.strides)}`);this.strides=t.strides}tp(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,wp(this.padding),this.inputSpec=[new Dd({ndim:3})]}computeOutputShape(t){const e=Tm((t=Id(t))[1],this.poolSize[0],this.padding,this.strides[0]);return[t[0],e,t[2]]}call(t,e){return Xr((()=>{this.invokeCallHook(t,e),t=zp(vd(t),2);const n=this.poolingFunction(vd(t),[this.poolSize[0],1],[this.strides[0],1],this.padding,"channelsLast");return Qi(n,[2])}))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides},e=super.getConfig();return Object.assign(t,e),t}}class Fg extends Mg{constructor(t){super(t)}poolingFunction(t,e,n,s,r){return kp(r),wp(s),Dg(t,e,n,s,r,"max")}}Fg.className="MaxPooling1D",Kr(Fg);class _g extends Mg{constructor(t){super(t)}poolingFunction(t,e,n,s,r){return kp(r),wp(s),Dg(t,e,n,s,r,"avg")}}_g.className="AveragePooling1D",Kr(_g);class zg extends zd{constructor(t){if(null==t.poolSize&&(t.poolSize=[2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize],null==t.strides)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(2!==t.strides.length)throw new Cc(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${t.strides.length}.`);this.strides=t.strides}else this.strides=[t.strides,t.strides];tp(this.poolSize,"poolSize"),tp(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,kp(this.dataFormat),wp(this.padding),this.inputSpec=[new Dd({ndim:4})]}computeOutputShape(t){t=Id(t);let e="channelsFirst"===this.dataFormat?t[2]:t[1],n="channelsFirst"===this.dataFormat?t[3]:t[2];return e=Tm(e,this.poolSize[0],this.padding,this.strides[0]),n=Tm(n,this.poolSize[1],this.padding,this.strides[1]),"channelsFirst"===this.dataFormat?[t[0],t[1],e,n]:[t[0],e,n,t[3]]}call(t,e){return Xr((()=>(this.invokeCallHook(t,e),this.poolingFunction(vd(t),this.poolSize,this.strides,this.padding,this.dataFormat))))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class Cg extends zg{constructor(t){super(t)}poolingFunction(t,e,n,s,r){return kp(r),wp(s),Dg(t,e,n,s,r,"max")}}Cg.className="MaxPooling2D",Kr(Cg);class Og extends zg{constructor(t){super(t)}poolingFunction(t,e,n,s,r){return kp(r),wp(s),Dg(t,e,n,s,r,"avg")}}Og.className="AveragePooling2D",Kr(Og);class Lg extends zd{constructor(t){if(null==t.poolSize&&(t.poolSize=[2,2,2]),super(t),this.poolSize=Array.isArray(t.poolSize)?t.poolSize:[t.poolSize,t.poolSize,t.poolSize],null==t.strides)this.strides=this.poolSize;else if(Array.isArray(t.strides)){if(3!==t.strides.length)throw new Cc(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${t.strides.length}.`);this.strides=t.strides}else this.strides=[t.strides,t.strides,t.strides];tp(this.poolSize,"poolSize"),tp(this.strides,"strides"),this.padding=null==t.padding?"valid":t.padding,this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,kp(this.dataFormat),wp(this.padding),this.inputSpec=[new Dd({ndim:5})]}computeOutputShape(t){t=Id(t);let e="channelsFirst"===this.dataFormat?t[2]:t[1],n="channelsFirst"===this.dataFormat?t[3]:t[2],s="channelsFirst"===this.dataFormat?t[4]:t[3];return e=Tm(e,this.poolSize[0],this.padding,this.strides[0]),n=Tm(n,this.poolSize[1],this.padding,this.strides[1]),s=Tm(s,this.poolSize[2],this.padding,this.strides[2]),"channelsFirst"===this.dataFormat?[t[0],t[1],e,n,s]:[t[0],e,n,s,t[4]]}call(t,e){return Xr((()=>(this.invokeCallHook(t,e),this.poolingFunction(vd(t),this.poolSize,this.strides,this.padding,this.dataFormat))))}getConfig(){const t={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class Rg extends Lg{constructor(t){super(t)}poolingFunction(t,e,n,s,r){return kp(r),wp(s),$g(t,e,n,s,r,"max")}}Rg.className="MaxPooling3D",Kr(Rg);class Bg extends Lg{constructor(t){super(t)}poolingFunction(t,e,n,s,r){return kp(r),wp(s),$g(t,e,n,s,r,"avg")}}Bg.className="AveragePooling3D",Kr(Bg);class Wg extends zd{constructor(t){super(t),this.inputSpec=[new Dd({ndim:3})]}computeOutputShape(t){return[t[0],t[2]]}call(t,e){throw new Oc}}class Pg extends Wg{constructor(t){super(t||{})}call(t,e){return Xr((()=>{const e=vd(t);return fi(e,1)}))}}Pg.className="GlobalAveragePooling1D",Kr(Pg);class Vg extends Wg{constructor(t){super(t||{})}call(t,e){return Xr((()=>{const e=vd(t);return ai(e,1)}))}}Vg.className="GlobalMaxPooling1D",Kr(Vg);class Ug extends zd{constructor(t){super(t),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,kp(this.dataFormat),this.inputSpec=[new Dd({ndim:4})]}computeOutputShape(t){return t=t,"channelsLast"===this.dataFormat?[t[0],t[3]]:[t[0],t[1]]}call(t,e){throw new Oc}getConfig(){const t={dataFormat:this.dataFormat},e=super.getConfig();return Object.assign(t,e),t}}class Hg extends Ug{call(t,e){return Xr((()=>{const e=vd(t);return"channelsLast"===this.dataFormat?fi(e,[1,2]):fi(e,[2,3])}))}}Hg.className="GlobalAveragePooling2D",Kr(Hg);class jg extends Ug{call(t,e){return Xr((()=>{const e=vd(t);return"channelsLast"===this.dataFormat?ai(e,[1,2]):ai(e,[2,3])}))}}jg.className="GlobalMaxPooling2D",Kr(jg);class qg extends zd{constructor(t){super(t),this.layer=t.layer}build(t){this.built=!0}get trainable(){return null!=this.layer&&this.layer.trainable}set trainable(t){null!=this.layer&&(this.layer.trainable=t)}get trainableWeights(){return this.layer.trainableWeights}get nonTrainableWeights(){return this.layer.nonTrainableWeights}get updates(){return this.layer._updates}get losses(){return this.layer.losses}getWeights(){return this.layer.getWeights()}setWeights(t){this.layer.setWeights(t)}getConfig(){const t={layer:{className:this.layer.getClassName(),config:this.layer.getConfig()}},e=super.getConfig();return Object.assign(t,e),t}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.layer&&this.layer.setFastWeightInitDuringBuild(t)}static fromConfig(t,e,n={}){const s=Kd(e.layer,n);delete e.layer;const r={layer:s};return Object.assign(r,e),new t(r)}}class Gg extends qg{constructor(t){super(t),this.supportsMasking=!0}build(t){if((t=Id(t)).length<3)throw new Cc(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(t)}`);this.inputSpec=[{shape:t}];const e=[t[0]].concat(t.slice(2));this.layer.built||(this.layer.build(e),this.layer.built=!0),super.build(t)}computeOutputShape(t){const e=[(t=Id(t))[0]].concat(t.slice(2)),n=this.layer.computeOutputShape(e),s=t[1];return[n[0],s].concat(n.slice(1))}call(t,e){return Xr((()=>Um(((t,n)=>[vd(this.layer.call(t,e)),[]]),t=vd(t),[],!1,null,null,!1,!0)[1]))}}Gg.className="TimeDistributed",Kr(Gg);class Kg extends qg{constructor(t){super(t);const e=t.layer.getConfig(),n={};n.className=t.layer.getClassName(),n.config=e,this.forwardLayer=Kd(n),e.goBackwards=!0!==e.goBackwards;const s={};var r;if(s.className=t.layer.getClassName(),s.config=e,this.backwardLayer=Kd(s),this.forwardLayer.name="forward_"+this.forwardLayer.name,this.backwardLayer.name="backward_"+this.backwardLayer.name,this.mergeMode=void 0===t.mergeMode?"concat":t.mergeMode,r=this.mergeMode,Xc(yp,"BidirectionalMergeMode",r),t.weights)throw new Oc("weights support is not implemented for Bidirectional layer yet.");this._stateful=t.layer.stateful,this.returnSequences=t.layer.returnSequences,this.returnState=t.layer.returnState,this.supportsMasking=!0,this._trainable=!0,this.inputSpec=t.layer.inputSpec,this.numConstants=null}get trainable(){return this._trainable}set trainable(t){this._trainable=t,null!=this.forwardLayer&&(this.forwardLayer.trainable=t),null!=this.backwardLayer&&(this.backwardLayer.trainable=t)}getWeights(){return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights())}setWeights(t){const e=t.length,n=Math.floor(e/2);this.forwardLayer.setWeights(t.slice(0,n)),this.backwardLayer.setWeights(t.slice(n))}computeOutputShape(t){let e,n,s,r=this.forwardLayer.computeOutputShape(t);return Array.isArray(r)&&Array.isArray(r[0])||(r=[r]),r=r,this.returnState?(s=r.slice(1),e=r[0]):e=r[0],e=e,"concat"===this.mergeMode?(e[e.length-1]*=2,n=[e]):n=null==this.mergeMode?[e,e.slice()]:[e],this.returnState?null==this.mergeMode?n.concat(s).concat(s.slice()):[e].concat(s).concat(s.slice()):Pc(n)}apply(t,e){let n=null==e?null:e.initialState,s=null==e?null:e.constants;null==e&&(e={});const r=Vm(t,n,s,this.numConstants);if(t=r.inputs,n=r.initialState,s=r.constants,Array.isArray(t)&&(n=t.slice(1),t=t[0]),(null==n||0===n.length)&&null==s)return super.apply(t,e);const a=[],i=[];if(null!=n){const t=n.length;if(t%2>0)throw new Cc("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");e.initialState=n,a.push(...n);const s=n.map((t=>new Dd({shape:t.shape})));this.forwardLayer.stateSpec=s.slice(0,t/2),this.backwardLayer.stateSpec=s.slice(t/2),i.push(...s)}if(null!=s)throw new Oc("Support for constants in Bidirectional layers is not implemented yet.");const o=a[0]instanceof $d;for(const t of a)if(t instanceof $d!==o)throw new Cc("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");if(o){const n=[t].concat(a),s=this.inputSpec.concat(i),r=this.inputSpec;this.inputSpec=s;const o=super.apply(n,e);return this.inputSpec=r,o}return super.apply(t,e)}call(t,e){return Xr((()=>{const n=e.initialState;let s,r,a,i;if(null==n)s=this.forwardLayer.call(t,e),r=this.backwardLayer.call(t,e);else{const a=n.slice(0,n.length/2),i=n.slice(n.length/2);s=this.forwardLayer.call(t,Object.assign(e,{initialState:a})),r=this.backwardLayer.call(t,Object.assign(e,{initialState:i}))}return this.returnState&&(Array.isArray(s)&&(a=s.slice(1).concat(r.slice(1))),s=s[0],r=r[0]),this.returnSequences&&(r=Wi(r,1)),"concat"===this.mergeMode?i=Rp([s,r]):"sum"===this.mergeMode?i=aa(s,r):"ave"===this.mergeMode?i=ii(.5,aa(s,r)):"mul"===this.mergeMode?i=ii(s,r):null==this.mergeMode&&(i=[s,r]),this.returnState?null==this.mergeMode?i.concat(a):[i].concat(a):i}))}resetStates(t){this.forwardLayer.resetStates(),this.backwardLayer.resetStates()}build(t){vp(this.forwardLayer.name,(()=>{this.forwardLayer.build(t)})),vp(this.backwardLayer.name,(()=>{this.backwardLayer.build(t)})),this.built=!0}computeMask(t,e){let n;if(Array.isArray(e)&&(e=e[0]),n=this.returnSequences?null==this.mergeMode?[e,e]:e:null==this.mergeMode?[null,null]:null,this.returnState){const t=this.forwardLayer.states.map((t=>null));return Array.isArray(n)?n.concat(t).concat(t):[n].concat(t).concat(t)}return n}get trainableWeights(){return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights)}get nonTrainableWeights(){return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights)}setFastWeightInitDuringBuild(t){super.setFastWeightInitDuringBuild(t),null!=this.forwardLayer&&this.forwardLayer.setFastWeightInitDuringBuild(t),null!=this.backwardLayer&&this.backwardLayer.setFastWeightInitDuringBuild(t)}getConfig(){const t={mergeMode:this.mergeMode},e=super.getConfig();return Object.assign(t,e),t}static fromConfig(t,e){const n=Kd(e.layer);if(delete e.layer,null!=e.numConstants)throw new Oc("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");const s=e;return s.layer=n,new t(s)}}function Jg(t,e){Array.isArray(t)||(t=[t]),t.forEach((t=>{null!=t&&v("complex64"!==t.dtype,(()=>`${e} does not support complex64 tensors in the CPU backend.`))}))}Kg.className="Bidirectional",Kr(Kg);const Zg=Cl;class Yg extends k{constructor(){super(),this.blockSize=48,this.firstUse=!0,this.data=new b(this,Zr())}write(t,e,n){this.firstUse&&(this.firstUse=!1,Z().get("IS_NODE")&&function(...t){Z().getBool("IS_TEST")||console.warn(...t)}("\n============================\nHi there . Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.\n============================"));const s={};return this.data.set(s,{values:t,dtype:n,refCount:1}),s}makeTensorInfo(t,e,n){let s;if("string"===e&&null!=n&&n.length>0&&C(n[0])){const r=n.map((t=>us(t)));s=this.write(r,t,e)}else s=this.write(n,t,e);return{dataId:s,shape:t,dtype:e}}incRef(t){this.data.get(t).refCount++}decRef(t){this.data.has(t)&&this.data.get(t).refCount--}move(t,e,n,s){this.data.set(t,{values:e,dtype:s,refCount:1})}numDataIds(){return this.data.numDataIds()}async read(t){return this.readSync(t)}readSync(t){const{dtype:e,complexTensorInfos:n}=this.data.get(t);return"complex64"===e?$l(this.readSync(n.real.dataId),this.readSync(n.imag.dataId)):this.data.get(t).values}bufferSync(t){const e=this.readSync(t.dataId);let n=e;if("string"===t.dtype)try{n=e.map((t=>hs(t)))}catch(t){throw new Error("Failed to decode encoded string bytes into utf-8")}return vr(t.shape,t.dtype,n)}makeOutput(t,e,n){const s=this.write(t,e,n);return Zr().makeTensorFromDataId(s,e,n,this)}disposeData(t){if(this.data.has(t)){const{complexTensorInfos:e}=this.data.get(t);null!=e&&(this.disposeData(e.real.dataId),this.disposeData(e.imag.dataId)),this.data.delete(t)}}disposeIntermediateTensorInfo(t){const e=t.dataId;if(this.data.has(e)){const t=this.data.get(e);t.refCount--,t.refCount<1&&this.disposeData(e)}}async time(t){const e=ls();return t(),{kernelMs:ls()-e}}memory(){return{unreliable:!0,reasons:["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]}}where(t){Jg([t],"where");const e=this.readSync(t.dataId);return Zg(t.shape,e)}dispose(){}floatPrecision(){return 32}epsilon(){return super.epsilon()}}function Xg(t,e,n){return({inputs:s,attrs:r,backend:a})=>{const{x:i}=s;if(Jg(i,t),"string"===i.dtype||"string"===n)throw new Error("unaryKernelFunc does not support string input/output");const o=a,l=o.data.get(i.dataId).values,u=E(i.shape),h=n||i.dtype,c=_(h,u);for(let t=0;t<u;++t)c[t]=e(l[t],r);return o.makeTensorInfo(i.shape,h,c)}}function Qg(t,e,n){return({inputs:s,attrs:r,backend:a})=>{const{x:i}=s;if(Jg(i,t),"string"===i.dtype||"string"===n)throw new Error("unaryKernelFunc does not support string input/output");const o=a,l=o.data.get(i.dataId).values,u=n||i.dtype,h=e(l,u,r);return o.makeTensorInfo(i.shape,u,h)}}!function(t,e,n=1){$s.registerBackend(t,e,n)}("cpu",(()=>new Yg),1);const ty=Xg(jt,(t=>t>=0?t:Math.exp(t)-1)),ey={kernelName:jt,backendName:"cpu",kernelFunc:ty};function ny(t){const{inputs:e,backend:n}=t,{x:s}=e;return n.incRef(s.dataId),{dataId:s.dataId,shape:s.shape,dtype:s.dtype}}const sy={kernelName:oe,backendName:"cpu",kernelFunc:ny};function ry(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{alpha:a}=s;Jg([r],"leakyRelu");const i=E(r.shape),o=n.data.get(r.dataId).values,l=F("float32",i);for(let t=0;t<o.length;t++)l[t]=o[t]<0?a*o[t]:o[t];return n.makeTensorInfo(r.shape,"float32",l)}const ay={kernelName:de,backendName:"cpu",kernelFunc:ry};function iy(t){return(e,n,s,r,a)=>{const i=qa(e,n),o=i.length,l=B(i),u=F(a,E(i)),h=e.length,c=n.length,p=B(e),d=B(n),f=Ha(e,i),m=Ha(n,i);if(f.length+m.length===0)for(let e=0;e<u.length;++e)u[e]=t(s[e%s.length],r[e%r.length]);else for(let e=0;e<u.length;++e){const n=G(e,o,l),a=n.slice(-h);f.forEach((t=>a[t]=0));const i=q(a,h,p),g=n.slice(-c);m.forEach((t=>g[t]=0));const y=q(g,c,d);u[e]=t(s[i],r[y])}return[u,i]}}const oy=iy(((t,e)=>t<0?e*t:t));function ly(t){const{inputs:e,backend:n}=t,{x:s,alpha:r}=e;Jg([s,r],"prelu");const a=n.data.get(s.dataId).values,i=n.data.get(r.dataId).values,[o,l]=oy(s.shape,r.shape,a,i,s.dtype);return n.makeTensorInfo(l,s.dtype,o)}const uy={kernelName:Ke,backendName:"cpu",kernelFunc:ly},hy=Xg(Qe,(t=>Math.max(0,t))),cy={kernelName:Qe,backendName:"cpu",kernelFunc:hy},py=Xg(an,(t=>Math.min(Math.max(0,t),6))),dy={kernelName:an,backendName:"cpu",kernelFunc:py};function fy(t,e,n,s,r){if("linear"===n)return ny({inputs:{x:e},backend:t});if("relu"===n)return hy({inputs:{x:e},backend:t});if("elu"===n)return ty({inputs:{x:e},backend:t});if("relu6"===n)return py({inputs:{x:e},backend:t});if("prelu"===n)return ly({inputs:{x:e,alpha:s},backend:t});if("leakyrelu"===n)return ry({inputs:{x:e},backend:t,attrs:{alpha:r}});throw new Error(`Activation ${n} has not been implemented for the CPU backend.`)}function my(t){const{inputs:e,backend:n}=t,{real:s,imag:r}=e,a=n.data.get(s.dataId).values,i=n.data.get(r.dataId).values,o=n.makeTensorInfo(s.shape,"complex64");return n.data.get(o.dataId).complexTensorInfos={real:n.makeTensorInfo(s.shape,"float32",a),imag:n.makeTensorInfo(r.shape,"float32",i)},o}const gy={kernelName:vt,backendName:"cpu",kernelFunc:my};function yy(t,e,n="float32"){if("complex64"===n)return my({inputs:{real:yy(t,e,"float32"),imag:yy(t,e,"float32")},backend:t});const s=U(E(e),n);return t.makeTensorInfo(e,n,s)}function by(t){const{inputs:e,backend:n}=t,{input:s}=e,r=n.data.get(s.dataId).complexTensorInfos.real,a=n.data.get(r.dataId).values;return n.makeTensorInfo(r.shape,r.dtype,a)}const ky={kernelName:Ye,backendName:"cpu",kernelFunc:by};function wy(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{dtype:a}=s;if("complex64"===a){if("complex64"===r.dtype)return ny({inputs:{x:r},backend:n});const t=yy(n,r.shape,r.dtype),e=wy({inputs:{x:r},backend:n,attrs:{dtype:"float32"}}),s=my({inputs:{real:e,imag:t},backend:n});return n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(e),s}if("complex64"===r.dtype){const t=by({inputs:{input:r},backend:n}),e=wy({inputs:{x:t},backend:n,attrs:{dtype:a}});return n.disposeIntermediateTensorInfo(t),e}if(i=r.dtype,"complex64"===(o=a)||"float32"===o&&"complex64"!==i||"int32"===o&&"float32"!==i&&"complex64"!==i||"bool"===o&&"bool"===i){const t=ny({inputs:{x:r},backend:n});return{dataId:t.dataId,shape:t.shape,dtype:a}}var i,o;if("int32"===a){const t=n.data.get(r.dataId).values,e=Int32Array.from(t);return n.makeTensorInfo(r.shape,"int32",e)}if("bool"===a){const t=n.data.get(r.dataId).values,e=os([0],r.dtype),[s,a]=iy(((t,e)=>t!==e?1:0))(r.shape,[],t,e,"bool");return n.makeTensorInfo(a,"bool",s)}throw new Error(`Error in Cast: failed to cast ${r.dtype} to ${a}`)}const xy={kernelName:wt,backendName:"cpu",kernelFunc:wy};function Ny(t,e,n,s){return null==n?({inputs:n,backend:r})=>{const{a,b:i}=n,o=r;Jg([a,i],t);const l=o.data.get(a.dataId).values,u=o.data.get(i.dataId).values,h=s||a.dtype,[c,p]=e(a.shape,i.shape,l,u,h);return o.makeTensorInfo(p,h,c)}:({inputs:t,backend:r})=>{const{a,b:i}=t,o=r;if("complex64"===a.dtype||"complex64"===i.dtype){const t=wy({inputs:{x:a},backend:o,attrs:{dtype:"complex64"}}),e=o.data.get(t.dataId),s=e.complexTensorInfos.real,r=e.complexTensorInfos.imag,l=o.data.get(s.dataId).values,u=o.data.get(r.dataId).values,h=wy({inputs:{x:i},backend:o,attrs:{dtype:"complex64"}}),c=o.data.get(h.dataId),p=c.complexTensorInfos.real,d=c.complexTensorInfos.imag,f=o.data.get(p.dataId).values,m=o.data.get(d.dataId).values,[g,y,b]=n(a.shape,i.shape,l,u,f,m),k=o.makeTensorInfo(b,"float32",g),w=o.makeTensorInfo(b,"float32",y),x=my({inputs:{real:k,imag:w},backend:o});return o.disposeIntermediateTensorInfo(t),o.disposeIntermediateTensorInfo(h),o.disposeIntermediateTensorInfo(k),o.disposeIntermediateTensorInfo(w),x}{const t=o.data.get(a.dataId).values,n=o.data.get(i.dataId).values,r=s||a.dtype,[l,u]=e(a.shape,i.shape,t,n,r);return o.makeTensorInfo(u,r,l)}}}function vy(t){return(e,n,s,r,a,i)=>{const o=qa(e,n),l=E(o),u=o.length,h=B(o),c=F("float32",l),p=F("float32",l),d=Ha(e,o),f=Ha(n,o),m=$l(s,r),g=$l(a,i),y=e.length,b=B(e),k=n.length,w=B(n);if(d.length+f.length===0)for(let e=0;e<c.length;e++){const n=e%m.length,s=e%g.length,r=t(m[2*n],m[2*n+1],g[2*s],g[2*s+1]);c[e]=r.real,p[e]=r.imag}else for(let e=0;e<c.length;e++){const n=G(e,u,h),s=n.slice(-y);d.forEach((t=>s[t]=0));const r=q(s,y,b),a=n.slice(-k);f.forEach((t=>a[t]=0));const i=q(a,k,w),o=t(m[2*r],m[2*r+1],g[2*i],g[2*i+1]);c[e]=o.real,p[e]=o.imag}return[c,p,o]}}const Iy=iy(((t,e)=>t+e)),Sy=vy(((t,e,n,s)=>({real:t+n,imag:e+s}))),Ty=Ny(rt,Iy,Sy),Ey={kernelName:rt,backendName:"cpu",kernelFunc:Ty};function Ay(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{shape:a}=s,i=E(r.shape),o=function(t,e){let n=1,s=-1;for(let e=0;e<t.length;++e)if(t[e]>=0)n*=t[e];else if(-1===t[e]){if(-1!==s)throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${s} and dim ${e}`);s=e}else if(t[e]<0)throw Error(`Shapes can not be < 0. Found ${t[e]} at dim ${e}`);if(-1===s){if(e>0&&e!==n)throw Error(`Size(${e}) must match the product of shape ${t}`);return t}if(0===n)throw Error(`Cannot infer the missing size in [${t}] when there are 0 elements`);if(e%n!=0)throw Error(`The implicit shape can't be a fractional number. Got ${e} / ${n}`);const r=t.slice();return r[s]=e/n,r}(a,i),l=E(o);v(i===l,(()=>`The new shape (${o}) has ${l} elements and the old shape (${r.shape}) has ${i} elements. The new shape and old shape must have the same number of elements.`)),n.incRef(r.dataId);const u=n.data.get(r.dataId);if(null!=u.complexTensorInfos){const t=u.complexTensorInfos.real,e=u.complexTensorInfos.imag;t.shape=o,e.shape=o}return{dataId:r.dataId,shape:o,dtype:r.dtype}}const Dy={kernelName:tn,backendName:"cpu",kernelFunc:Ay};function $y(t){const{inputs:e,backend:n,attrs:s}=t,{a:r,b:a}=e,{transposeA:i,transposeB:o}=s;Jg([r,a],"matMul");const l=r.shape.length,u=a.shape.length,h=i?r.shape[l-2]:r.shape[l-1],c=o?a.shape[u-1]:a.shape[u-2],p=i?r.shape[l-1]:r.shape[l-2],d=o?a.shape[u-2]:a.shape[u-1],f=r.shape.slice(0,-2),m=a.shape.slice(0,-2),g=E(f),y=E(m);v(l>=2&&u>=2&&(g===y||1===g||1===y),(()=>`Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (${f}) and (${m}).`));const b=(g>y?r.shape.slice(0,-2):a.shape.slice(0,-2)).concat([p,d]);v(h===c,(()=>`Error in matMul: inner shapes (${h}) and (${c}) of Tensors with shapes ${r.shape} and ${a.shape} and transposeA=${i} and transposeB=${o} must match.`));const k=o?[y,d,c]:[y,c,d],w=Ay({inputs:{x:r},backend:n,attrs:{shape:i?[g,h,p]:[g,p,h]}}),x=Ay({inputs:{x:a},backend:n,attrs:{shape:k}}),N=i?w.shape[1]:w.shape[2],I=i?w.shape[2]:w.shape[1],S=o?x.shape[1]:x.shape[2],T=Math.max(g,y),A=n.data.get(w.dataId).values,D=n.data.get(x.dataId).values,$=B(w.shape),M=B(x.shape),[F,_,z]=i?[$[0],1,$[1]]:[$[0],$[1],1],[C,O,L]=o?[1,M[1],M[0]]:[M[1],1,M[0]],R=I*S,W=vr([T,I,S],w.dtype),P=W.values,V=n.blockSize;for(let t=0;t<T;t++)for(let e=0;e<I;e+=V)for(let n=0;n<S;n+=V)for(let s=0;s<N;s+=V){const r=Math.min(e+V,I),a=Math.min(n+V,S),i=Math.min(s+V,N);for(let o=e;o<r;o++)for(let e=n;e<a;e++){let n=0;for(let r=s;r<i;r++){const s=Math.min(t,g-1)*F,a=Math.min(t,y-1)*L;n+=A[s+o*_+r*z]*D[r*C+e*O+a]}P[t*R+(o*S+e)]+=n}}return n.disposeIntermediateTensorInfo(w),n.disposeIntermediateTensorInfo(x),n.makeTensorInfo(b,W.dtype,W.values)}const My={kernelName:yt,backendName:"cpu",kernelFunc:$y},Fy={kernelName:Pn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{a:r,b:a,bias:i,preluActivationWeights:o}=e,{transposeA:l,transposeB:u,activation:h,leakyreluAlpha:c}=s;let p,d,f;const m=[];p=$y({inputs:{a:r,b:a},attrs:{transposeA:l,transposeB:u},backend:n}),i&&(d=Ty({inputs:{a:p,b:i},backend:n}),m.push(p),p=d),h&&(f=fy(n,p,h,o,c),m.push(p),p=f);for(const t of m)n.disposeIntermediateTensorInfo(t);return p}},_y={kernelName:et,backendName:"cpu",kernelFunc:t=>{const{x:e}=t.inputs,n=t.backend;Jg(e,"abs");let s=new Float32Array(E(e.shape));return s=function(t){const e=new Float32Array(t.length);for(let n=0;n<t.length;++n)e[n]=Math.abs(t[n]);return e}(n.data.get(e.dataId).values),n.makeOutput(s,e.shape,"float32")}},zy=Xg(nt,(t=>Math.acos(t))),Cy={kernelName:nt,backendName:"cpu",kernelFunc:zy},Oy=Xg(st,(t=>Math.acosh(t))),Ly={kernelName:st,backendName:"cpu",kernelFunc:Oy},Ry={kernelName:at,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n}=t,s=e;Jg(e,"addN");const r=s.map((t=>n.data.get(t.dataId).values)),a=vr(s[0].shape,s[0].dtype),i=a.values;for(let t=0;t<s.length;t++){const e=r[t];for(let t=0;t<i.length;t++)i[t]+=e[t]}return n.makeTensorInfo(a.shape,a.dtype,a.values)}};function By(t,e,n,s,r){const a=e.length,i=E(e),o=B(e),l=B(r),u=F(n,E(r));for(let e=0;e<i;++e){const n=G(e,a,o),r=new Array(n.length);for(let t=0;t<r.length;t++)r[t]=n[s[t]];u[q(r,a,l)]=t[e]}return u}function Wy(t){const{inputs:e,attrs:n,backend:s}=t,{x:r}=e,{perm:a}=n;Jg(r,"transpose");const i=r.shape.length,o=new Array(i);for(let t=0;t<o.length;t++)o[t]=r.shape[a[t]];const l=By(s.data.get(r.dataId).values,r.shape,r.dtype,a,o);return{dataId:s.write(l,o,r.dtype),shape:o,dtype:r.dtype}}const Py={kernelName:_n,backendName:"cpu",kernelFunc:Wy},Vy={kernelName:"All",backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{axis:a,keepDims:i}=s;Jg(r,"all");const o=M(a,r.shape);let l=o;const u=xi(l,r.shape.length);let h=r;null!=u&&(h=Wy({inputs:{x:r},backend:n,attrs:{perm:u}}),l=vi(l.length,r.shape.length)),wi("all",l,h.shape.length);const[c,p]=bi(h.shape,l),d=E(p),f=U(E(c),h.dtype),m=n.data.get(h.dataId).values;for(let t=0;t<f.length;++t){const e=t*d;let n=m[e];for(let t=0;t<d;++t){const s=m[e+t];n=n&&s}f[t]=n}null!=u&&n.disposeIntermediateTensorInfo(h);const g=n.makeTensorInfo(c,h.dtype,f);if(i){const t=Ay({inputs:{x:g},backend:n,attrs:{shape:ki(c,o)}});return n.disposeIntermediateTensorInfo(g),t}return g}},Uy={kernelName:"Any",backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{axis:a,keepDims:i}=s;Jg(r,"any");const o=M(a,r.shape);let l=o;const u=xi(l,r.shape.length);let h=r;null!=u&&(h=Wy({inputs:{x:r},backend:n,attrs:{perm:u}}),l=vi(l.length,r.shape.length)),wi("any",l,h.shape.length);const[c,p]=bi(h.shape,l),d=E(p),f=U(E(c),h.dtype),m=n.data.get(h.dataId).values;for(let t=0;t<f.length;++t){const e=t*d;let n=m[e];for(let t=0;t<d;++t){const s=m[e+t];n=n||s}f[t]=n}null!=u&&n.disposeIntermediateTensorInfo(h);const g=n.makeTensorInfo(c,h.dtype,f);if(i){const t=Ay({inputs:{x:g},backend:n,attrs:{shape:ki(c,o)}});return n.disposeIntermediateTensorInfo(g),t}return g}},Hy={kernelName:it,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{axis:a}=s;Jg(r,"argMax");let i=M(a,r.shape);const o=xi(i,r.shape.length);let l=r;const u=[];null!=o&&(l=Wy({inputs:{x:r},backend:n,attrs:{perm:o}}),u.push(l),i=vi(i.length,l.shape.length)),i=[i[0]],wi("argMax",i,l.shape.length);const[h,c]=bi(l.shape,i),p=U(E(h),"int32"),d=E(c),f=n.data.get(l.dataId).values;for(let t=0;t<p.length;++t){const e=t*d;let n=f[e],s=0;for(let t=0;t<d;++t){const r=f[e+t];r>n&&(n=r,s=t)}p[t]=s}return u.forEach((t=>n.disposeIntermediateTensorInfo(t))),n.makeTensorInfo(h,"int32",p)}},jy={kernelName:ot,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{axis:a}=s;Jg(r,"argMin");let i=M(a,r.shape);const o=xi(i,r.shape.length);let l=r;const u=[];null!=o&&(l=Wy({inputs:{x:r},backend:n,attrs:{perm:o}}),u.push(l),i=vi(i.length,l.shape.length)),i=[i[0]],wi("argMin",i,l.shape.length);const[h,c]=bi(l.shape,i),p=U(E(h),"int32"),d=E(c),f=n.data.get(l.dataId).values;for(let t=0;t<p.length;++t){const e=t*d;let n=f[e],s=0;for(let t=0;t<d;++t){const r=f[e+t];r<n&&(n=r,s=t)}p[t]=s}return u.forEach((t=>n.disposeIntermediateTensorInfo(t))),n.makeTensorInfo(h,"int32",p)}},qy=Xg(lt,(t=>Math.asin(t))),Gy={kernelName:lt,backendName:"cpu",kernelFunc:qy},Ky=Xg(ut,(t=>Math.asinh(t))),Jy={kernelName:ut,backendName:"cpu",kernelFunc:Ky},Zy=Xg(ht,(t=>Math.atan(t))),Yy={kernelName:ht,backendName:"cpu",kernelFunc:Zy},Xy=iy(((t,e)=>Math.atan2(t,e))),Qy=Ny(pt,Xy),tb={kernelName:pt,backendName:"cpu",kernelFunc:Qy},eb=Xg(ct,(t=>Math.atanh(t))),nb={kernelName:ct,backendName:"cpu",kernelFunc:eb};function sb(t,e,n,s,r,a){const i=r.strideHeight,o=r.strideWidth,l=r.dilationHeight,u=r.dilationWidth,h=r.effectiveFilterHeight,c=r.effectiveFilterWidth,p=r.padInfo.top,d=r.padInfo.left,f="max"===a?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,m=vr(r.outShape,n),g=m.values,y=r.outShape[1]*r.outShape[2]*r.outShape[3],b=r.outShape[2]*r.outShape[3],k=r.outShape[3];for(let e=0;e<r.batchSize;++e){const n=e*y,m=e*s[0];for(let e=0;e<r.inChannels;++e)for(let y=0;y<r.outHeight;++y){const w=y*i-p,x=Math.max(0,w),N=Math.min(r.inHeight,h+w),v=n+y*b;for(let n=0;n<r.outWidth;++n){const i=n*o-d,h=Math.max(0,i),p=Math.min(r.inWidth,c+i);let y=f,b=0,w=0;for(let n=x;n<N;n+=l){const r=m+n*s[1];for(let n=h;n<p;n+=u){const i=t[r+n*s[2]+e];"max"===a&&i>y?y=i:"avg"===a&&(b+=i,w++)}if(isNaN(y))break}g[v+n*k+e]="avg"===a?b/w:y}}}return m}function rb(t,e,n,s,r=!1,a=!1){const i=vr(s.outShape,"int32"),o=s.strideHeight,l=s.strideWidth,u=s.dilationHeight,h=s.dilationWidth,c=s.effectiveFilterHeight,p=s.effectiveFilterWidth,d=s.padInfo.top,f=s.padInfo.left,m=vr(e,n,t);for(let t=0;t<s.batchSize;++t)for(let e=0;e<s.inChannels;++e)for(let n=0;n<s.outHeight;++n){const g=n*o-d;let y=g;for(;y<0;)y+=u;const b=Math.min(s.inHeight,c+g);for(let o=0;o<s.outWidth;++o){const c=o*l-f;let d=c;for(;d<0;)d+=h;const k=Math.min(s.inWidth,p+c);let w=Number.NEGATIVE_INFINITY,x=-1;for(let n=y;n<b;n+=u){const i=n-g;for(let o=d;o<k;o+=h){const l=o-c,u=m.get(t,n,o,e);u>w&&(w=u,x=r?a?((t*s.inHeight+n)*s.inWidth+o)*s.inChannels+e:(n*s.inWidth+o)*s.inChannels+e:i*p+l)}}i.set(x,t,n,o,e)}}return i}function ab(t,e,n,s,r,a){const i=r.strideDepth,o=r.strideHeight,l=r.strideWidth,u=r.dilationDepth,h=r.dilationHeight,c=r.dilationWidth,p=r.effectiveFilterDepth,d=r.effectiveFilterHeight,f=r.effectiveFilterWidth,m=r.padInfo.front,g=r.padInfo.top,y=r.padInfo.left,b="max"===a?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,k=vr(r.outShape,n),w=k.values,x=r.outShape[1]*r.outShape[2]*r.outShape[3]*r.outShape[4],N=r.outShape[2]*r.outShape[3]*r.outShape[4],v=r.outShape[3]*r.outShape[4],I=r.outShape[4];for(let e=0;e<r.batchSize;++e){const n=e*x,k=e*s[0];for(let e=0;e<r.inChannels;++e)for(let x=0;x<r.outDepth;++x){const S=x*i-m;let T=S;for(;T<0;)T+=u;const E=Math.min(r.inDepth,p+S),A=n+x*N;for(let n=0;n<r.outHeight;++n){const i=n*o-g;let p=i;for(;p<0;)p+=h;const m=Math.min(r.inHeight,d+i),x=A+n*v;for(let n=0;n<r.outWidth;++n){const i=n*l-y;let o=i;for(;o<0;)o+=c;const d=Math.min(r.inWidth,f+i),g=x+n*I;let N=b,v=0,S=0;for(let n=T;n<E;n+=u){const r=k+n*s[1];for(let n=p;n<m;n+=h){const i=r+n*s[2];for(let n=o;n<d;n+=c){const r=t[i+n*s[3]+e];if("max"===a&&r>N?N=r:"avg"===a&&(v+=r,S++),isNaN(N))break}if(isNaN(N))break}if(isNaN(N))break}w[g+e]="avg"===a?v/S:N}}}}return k}const ib={kernelName:dt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e;Jg(r,"avgPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:l}=s;v(wa(i,1),(()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));const u=ha(r.shape,a,i,1,o,l);let h;if(1===u.filterWidth&&1===u.filterHeight&&A(u.inShape,u.outShape))h=ny({inputs:{x:r},backend:n});else{const t=n.data.get(r.dataId).values,e=B(r.shape),s=sb(t,r.shape,r.dtype,e,u,"avg");h=n.makeTensorInfo(u.outShape,r.dtype,s.values)}return h}},ob={kernelName:mt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{filterSize:a,strides:i,pad:o,dimRoundingMode:l,dataFormat:u,dilations:h}=s;Jg(r,"avgPool3d");let c=h;null==c&&(c=[1,1,1]);const p=ca(r.shape,a,i,c,o,l,u),d=ab(n.data.get(r.dataId).values,r.shape,r.dtype,B(r.shape),p,"avg");return n.makeTensorInfo(d.shape,"float32",d.values)}},lb={kernelName:gt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,input:a}=e,{filterSize:i,strides:o,pad:l,dilations:u,dimRoundingMode:h}=s;Jg([r,a],"avgPool3DGrad");const c=ca(a.shape,i,o,u,l,h),p=c.strideDepth,d=c.strideHeight,f=c.strideWidth,m=c.filterDepth,g=c.filterHeight,y=c.filterWidth,b=c.dilationDepth,k=c.dilationHeight,w=c.dilationWidth,x=c.effectiveFilterDepth,N=c.effectiveFilterHeight,v=c.effectiveFilterWidth,I=x-1-c.padInfo.front,S=v-1-c.padInfo.left,T=N-1-c.padInfo.top,E=vr(a.shape,"float32"),A=1/(m*g*y),D=n.bufferSync(r);for(let t=0;t<c.batchSize;++t)for(let e=0;e<c.inChannels;++e)for(let n=0;n<c.inDepth;++n)for(let s=0;s<c.inHeight;++s)for(let r=0;r<c.inWidth;++r){const a=n-I,i=s-T,o=r-S;let l=0;for(let n=0;n<x;n+=b){const s=(a+n)/p;if(!(s<0||s>=c.outDepth||Math.floor(s)!==s))for(let n=0;n<N;n+=k){const r=(i+n)/d;if(!(r<0||r>=c.outHeight||Math.floor(r)!==r))for(let n=0;n<v;n+=w){const a=(o+n)/f;a<0||a>=c.outWidth||Math.floor(a)!==a||(l+=D.get(t,s,r,a,e))}}}E.set(l*A,t,n,s,r,e)}return n.makeTensorInfo(E.shape,E.dtype,E.values)}},ub={kernelName:ft,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,input:a}=e,i=a;Jg([r,a],"avgPoolGrad");const{filterSize:o,strides:l,pad:u}=s,h=ha(i.shape,o,l,1,u),c=h.strideHeight,p=h.strideWidth,d=h.filterHeight,f=h.filterWidth,m=h.dilationHeight,g=h.dilationWidth,y=h.effectiveFilterHeight,b=h.effectiveFilterWidth,k=b-1-h.padInfo.left,w=y-1-h.padInfo.top,x=vr(i.shape,"float32"),N=1/(d*f),v=n.data.get(r.dataId).values,I=vr(r.shape,"float32",v);for(let t=0;t<h.batchSize;++t)for(let e=0;e<h.inChannels;++e)for(let n=0;n<h.inHeight;++n)for(let s=0;s<h.inWidth;++s){const r=n-w,a=s-k;let i=0;for(let n=0;n<y;n+=m){const s=(r+n)/c;if(!(s<0||s>=h.outHeight||Math.floor(s)!==s))for(let n=0;n<b;n+=g){const r=(a+n)/p;r<0||r>=h.outWidth||Math.floor(r)!==r||(i+=I.get(t,s,r,e))}}x.set(i*N,t,n,s,e)}return n.makeTensorInfo(x.shape,x.dtype,x.values)}},hb={kernelName:ne,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,scale:a,offset:i,mean:o,variance:l}=e;v(o.shape.length===l.shape.length,(()=>"Batch normalization gradient requires mean and variance to have equal ranks.")),v(null==i||o.shape.length===i.shape.length,(()=>"Batch normalization gradient requires mean and offset to have equal ranks.")),v(null==a||o.shape.length===a.shape.length,(()=>"Batch normalization gradient requires mean and scale to have equal ranks.")),Jg([r,o,l,a,i],"batchNorm");let{varianceEpsilon:u}=s;null==u&&(u=.001);const h=n.data.get(r.dataId).values,c=n.data.get(o.dataId).values,p=n.data.get(l.dataId).values,d=a?n.data.get(a.dataId).values:new Float32Array([1]),f=i?n.data.get(i.dataId).values:new Float32Array([0]),m=new Float32Array(h.length),g=f.length,y=d.length,b=p.length,k=c.length;let w=0,x=0,N=0,I=0;for(let t=0;t<h.length;++t)m[t]=f[w++]+(h[t]-c[x++])*d[N++]/Math.sqrt(p[I++]+u),w>=g&&(w=0),x>=k&&(x=0),N>=y&&(N=0),I>=b&&(I=0);return n.makeTensorInfo(r.shape,r.dtype,m)}};function cb(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{begin:a,size:i}=s;Jg(r,"slice");const[o,l]=Hr(r,a,i);!function(t,e,n){const s=t.shape.length;v(s===e.length,(()=>`Error in slice${s}D: Length of begin ${e} must match the rank of the array (${s}).`)),v(s===n.length,(()=>`Error in slice${s}D: Length of size ${n} must match the rank of the array (${s}).`));for(let r=0;r<s;++r)v(e[r]+n[r]<=t.shape[r],(()=>`Error in slice${s}D: begin[${r}] + size[${r}] (${e[r]+n[r]}) would overflow input.shape[${r}] (${t.shape[r]})`))}(r,o,l);const u=function(t,e,n,s,r){const a=function(t,e,n){let s=n.length;for(let t=0;t<n.length;t++)if(n[t]>1){s=t;break}for(let r=s+1;r<n.length;r++)if(e[r]>0||n[r]!==t[r])return!1;return!0}(s,e,n),i=E(n),o=B(s);if(a){const n=function(t,e){let n=t.length>0?t[t.length-1]:1;for(let s=0;s<t.length-1;s++)n+=t[s]*e[s];return n}(e,o);return"string"===r?t.slice(n,n+i):t.subarray(n,n+i)}const l=vr(s,r,"string"===r?zl(t):t),u=vr(n,r);for(let t=0;t<u.size;++t){const n=u.indexToLoc(t),s=n.map(((t,n)=>t+e[n]));u.set(l.get(...s),...n)}return"string"===r?u.values.map((t=>us(t))):u.values}(n.data.get(r.dataId).values,o,l,r.shape,r.dtype);return n.makeTensorInfo(l,r.dtype,u)}const pb={kernelName:dn,backendName:"cpu",kernelFunc:cb},db={kernelName:bt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{blockShape:a,crops:i}=s;Jg([r],"batchToSpaceND");const o=a.reduce(((t,e)=>t*e)),l=Tl(r.shape,a,o),u=El(l.length,a.length),h=Al(r.shape,a,o),c=function(t,e){const n=[0];for(let s=0;s<e;++s)n.push(t[s][0]);return n}(i,a.length),p=function(t,e,n){const s=t.slice(0,1);for(let r=0;r<n;++r)s.push(t[r+1]-e[r][0]-e[r][1]);return s}(h,i,a.length),d=Ay({inputs:{x:r},backend:n,attrs:{shape:l}}),f=Wy({inputs:{x:d},backend:n,attrs:{perm:u}}),m=Ay({inputs:{x:f},backend:n,attrs:{shape:h}}),g=cb({inputs:{x:m},backend:n,attrs:{begin:c,size:p}});return n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),n.disposeIntermediateTensorInfo(m),g}};function fb(t,e,n,s,r){const a=E(s),i=U(r,n);for(let n=0;n<t.length;n++){const s=t[n];if(s<0)throw new Error("Input x must be non-negative!");s>=r||(i[s]+=a>0?e[n]:1)}return i}const mb={kernelName:kt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,weights:a}=e,{size:i}=s,o=fb(n.data.get(r.dataId).values,n.data.get(a.dataId).values,a.dtype,a.shape,i);return n.makeTensorInfo([i],a.dtype,o)}};function gb(t){return(e,n,s)=>{const r=F(n,e.length);for(let n=0;n<e.length;++n)r[n]=t(e[n],s);return r}}const yb=gb((t=>Math.ceil(t))),bb=Qg(xt,yb),kb={kernelName:xt,backendName:"cpu",kernelFunc:bb},wb=Xg(Nt,((t,e)=>{const n=e;return t>n.clipValueMax?n.clipValueMax:t<n.clipValueMin?n.clipValueMin:t})),xb={kernelName:Nt,backendName:"cpu",kernelFunc:wb},Nb={kernelName:It,backendName:"cpu",kernelFunc:t=>{const{x:e}=t.inputs,n=t.backend,s=new Float32Array(E(e.shape)),r=n.data.get(e.dataId),a=r.complexTensorInfos.real,i=r.complexTensorInfos.imag,o=n.data.get(a.dataId).values,l=n.data.get(i.dataId).values;for(let t=0;t<o.length;t++){const e=o[t],n=l[t];s[t]=Math.hypot(e,n)}return n.makeOutput(s,e.shape,"float32")}};function vb(t){const{inputs:e,backend:n}=t,{input:s}=e,r=n.data.get(s.dataId).complexTensorInfos.imag,a=n.data.get(r.dataId).values;return n.makeTensorInfo(r.shape,r.dtype,a)}const Ib={kernelName:ue,backendName:"cpu",kernelFunc:vb};function Sb(t){const{inputs:e,backend:n,attrs:s}=t,{axis:r}=s,a=M(r,e[0].shape)[0];let i=Sl(e.map((t=>t.shape)),a);if(0===E(i))return n.makeTensorInfo(i,e[0].dtype,[]);const o=e.filter((t=>E(t.shape)>0));if(1===o.length)return ny({inputs:{x:o[0]},backend:n});if(function(t,e){const n=t[0].length;t.forEach(((t,e)=>{v(t.length===n,(()=>`Error in concat${n}D: rank of tensors[${e}] must be the same as the rank of the rest (${n})`))})),v(e>=0&&e<n,(()=>`Error in concat${n}D: axis must be between 0 and ${n-1}.`));const s=t[0];t.forEach(((t,r)=>{for(let a=0;a<n;a++)v(a===e||t[a]===s[a],(()=>`Error in concat${n}D: Shape of tensors[${r}] (${t}) does not match the shape of the rest (${s}) along the non-concatenated axis ${r}.`))}))}(o.map((t=>t.shape)),a),"complex64"===o[0].dtype){const t=o.map((t=>by({inputs:{input:t},backend:n}))),e=o.map((t=>vb({inputs:{input:t},backend:n}))),s=Sb({inputs:t,backend:n,attrs:{axis:a}}),r=Sb({inputs:e,backend:n,attrs:{axis:a}}),i=my({inputs:{real:s,imag:r},backend:n});return t.forEach((t=>n.disposeIntermediateTensorInfo(t))),e.forEach((t=>n.disposeIntermediateTensorInfo(t))),n.disposeIntermediateTensorInfo(s),n.disposeIntermediateTensorInfo(r),i}const l=o.map((t=>{const e=E(t.shape.slice(a));return Ay({inputs:{x:t},backend:n,attrs:{shape:[-1,e]}})})),u=l.map((t=>({vals:n.data.get(t.dataId).values,shape:t.shape})));i=Sl(l.map((t=>t.shape)),1);const h=1===l[0].shape[0],c=function(t,e,n,s){const r=_(n,E(e));if(s&&"string"!==n){let e=0;t.forEach((t=>{const n=E(t.shape);r.set(t.vals,e),e+=n}))}else{let s=0;t.forEach((t=>{const a="string"===n?zl(t.vals):t.vals;let i=0;for(let n=0;n<t.shape[0];++n){const o=n*e[1]+s;for(let e=0;e<t.shape[1];++e)r[o+e]=a[i++]}s+=t.shape[1]}))}return r}(u,i,e[0].dtype,h),p=Sl(o.map((t=>t.shape)),a),d=n.makeTensorInfo(p,e[0].dtype,c);return l.forEach((t=>n.disposeIntermediateTensorInfo(t))),d}const Tb={kernelName:St,backendName:"cpu",kernelFunc:Sb};function Eb(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,filter:a}=e,{strides:i,pad:o,dataFormat:l,dilations:u,dimRoundingMode:h}=s;Jg([r,a],"conv2d");const c=xa(l),p=pa(r.shape,a.shape,i,u,o,h,!1,c),d=p.filterHeight,f=p.filterWidth,m=p.dilationHeight,g=p.dilationWidth,y=p.padInfo.left,b=p.padInfo.top,k="channelsLast"===p.dataFormat,w=new cs(p.outShape,r.dtype),x=B(r.shape),N=B(a.shape),v=x[0],I=k?x[1]:x[2],S=k?x[2]:1,T=k?1:x[1],E=w.strides[0],A=k?w.strides[1]:w.strides[2],D=k?w.strides[2]:1,$=k?1:w.strides[1],M=n.data.get(r.dataId).values,F=n.data.get(a.dataId).values,_=w.values;for(let t=0;t<p.batchSize;++t){const e=t*v,n=t*E;for(let t=0;t<p.outHeight;++t){const s=n+t*A,r=t*p.strideHeight-b;for(let t=0;t<d;++t){const n=r+t*m;if(n<0||n>=p.inHeight)continue;const a=t*N[0],i=e+n*I;for(let t=0;t<p.outWidth;++t){const e=s+t*D,n=t*p.strideWidth-y;for(let t=0;t<f;++t){const s=n+t*g;if(s<0||s>=p.inWidth)continue;const r=i+s*S;let o=a+t*N[1];for(let t=0;t<p.inChannels;++t){const n=M[r+t*T];for(let t=0;t<p.outChannels;++t)_[e+t*$]+=n*F[o+t];o+=p.outChannels}}}}}}return n.makeTensorInfo(w.shape,w.dtype,_)}const Ab={kernelName:Tt,backendName:"cpu",kernelFunc:Eb},Db={kernelName:Et,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,dy:a}=e,{strides:i,pad:o,dataFormat:l,dimRoundingMode:u,filterShape:h}=s;Jg([r,a],"conv2dBackpropFilter");const c=xa(l),p=pa(r.shape,h,i,1,o,u,!1,c),{strideHeight:d,strideWidth:f,filterHeight:m,filterWidth:g}=p,y="channelsLast"===p.dataFormat,b=new cs(p.filterShape,"float32"),k=p.padInfo.left,w=p.padInfo.top,x=n.data.get(r.dataId).values,N=n.data.get(a.dataId).values,v=new cs(r.shape,r.dtype,x),I=new cs(a.shape,a.dtype,N);for(let t=0;t<m;++t){const e=Math.max(0,Math.ceil((w-t)/d)),n=Math.min(p.outHeight,(p.inHeight+w-t)/d);for(let s=0;s<g;++s){const r=Math.max(0,Math.ceil((k-s)/f)),a=Math.min(p.outWidth,(p.inWidth+k-s)/f);for(let i=0;i<p.inChannels;++i)for(let o=0;o<p.outChannels;++o){let l=0;for(let u=0;u<p.batchSize;++u)for(let h=e;h<n;++h){const e=t+h*d-w;for(let t=r;t<a;++t){const n=s+t*f-k;l+=y?v.get(u,e,n,i)*I.get(u,h,t,o):v.get(u,i,e,n)*I.get(u,o,h,t)}}b.set(l,t,s,i,o)}}}return n.makeTensorInfo(b.shape,b.dtype,b.values)}},$b={kernelName:At,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,filter:a}=e,{inputShape:i,strides:o,pad:l,dataFormat:u,dimRoundingMode:h}=s;Jg([r,a],"conv2dBackpropInput");const c=B(a.shape),p=B(r.shape);let d=xa(u);const f=pa(i,a.shape,o,1,l,h,!1,d),m=new cs(f.inShape,"float32"),g=m.values,y=n.data.get(r.dataId).values,b=n.data.get(a.dataId).values,[k,w,x]=c,{batchSize:N,filterHeight:v,filterWidth:I,inChannels:S,inHeight:T,inWidth:E,outChannels:A,outHeight:D,outWidth:$,strideHeight:M,strideWidth:F}=f;d=f.dataFormat;const _=v-1-f.padInfo.top,z=I-1-f.padInfo.left,C="channelsLast"===d,O=m.strides[0],L=C?m.strides[1]:m.strides[2],R=C?m.strides[2]:1,W=C?1:m.strides[1],P=p[0],V=C?p[1]:p[2],U=C?p[2]:1,H=C?1:p[1];for(let t=0;t<N;++t)for(let e=0;e<S;++e)for(let n=0;n<T;++n){const s=n-_,r=Math.max(0,Math.ceil(s/M)),a=Math.min(D,(v+s)/M);for(let i=0;i<E;++i){const o=i-z,l=Math.max(0,Math.ceil(o/F)),u=Math.min($,(I+o)/F);let h=0;for(let n=r;n<a;++n){const r=n*M-s;for(let s=l;s<u;++s){const a=P*t+V*n+U*s,i=k*(v-1-r)+w*(I-1-(s*F-o))+x*e;for(let t=0;t<A;++t)h+=y[a+H*t]*b[i+t]}}g[O*t+L*n+R*i+W*e]=h}}return n.makeTensorInfo(m.shape,m.dtype,m.values)}},Mb={kernelName:Dt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,filter:a}=e,{strides:i,pad:o,dilations:l}=s;Jg([r,a],"conv3d");const u=da(r.shape,a.shape,i,l,o),{filterDepth:h,filterHeight:c,filterWidth:p,dilationDepth:d,dilationHeight:f,dilationWidth:m,padInfo:g}=u,y=g.front,b=g.left,k=g.top,w=new cs(u.outShape,r.dtype),x=n.data.get(r.dataId).values,N=n.data.get(a.dataId).values,v=w.values,I=B(r.shape),S=B(a.shape);for(let t=0;t<u.batchSize;++t){const e=t*I[0],n=t*w.strides[0];for(let t=0;t<u.outDepth;++t){const s=n+t*w.strides[1],r=t*u.strideDepth-y;for(let t=0;t<h;++t){const n=r+t*d;if(n<0||n>=u.inDepth)continue;const a=t*S[0],i=e+n*I[1];for(let t=0;t<u.outHeight;++t){const e=s+t*w.strides[2],n=t*u.strideHeight-k;for(let t=0;t<c;++t){const s=n+t*f;if(s<0||s>=u.inHeight)continue;const r=a+t*S[1],o=i+s*I[2];for(let t=0;t<u.outWidth;++t){const n=e+t*u.outChannels,s=t*u.strideWidth-b;for(let t=0;t<p;++t){const e=s+t*m;if(e<0||e>=u.inWidth)continue;const a=r+t*S[2],i=o+e*u.inChannels;let l=a;for(let t=0;t<u.inChannels;++t){const e=x[i+t];for(let t=0;t<u.outChannels;++t)v[n+t]+=e*N[l+t];l+=u.outChannels}}}}}}}}return n.makeTensorInfo(w.shape,w.dtype,w.values)}},Fb={kernelName:$t,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,dy:a}=e,{strides:i,pad:o,filterShape:l}=s;Jg([r,a],"conv3dBackpropFilterV2");const u=B(r.shape),h=B(a.shape),c=da(r.shape,l,i,1,o),p=c.strideDepth,d=c.strideHeight,f=c.strideWidth,m=c.filterDepth,g=c.filterHeight,y=c.filterWidth,b=new cs(c.filterShape,"float32"),k=b.values,[w,x,N,v]=b.strides,I=n.data.get(a.dataId).values,[S,T,E,A]=h,D=n.data.get(r.dataId).values,[$,M,F,_]=u,z=c.padInfo.front,C=c.padInfo.left,O=c.padInfo.top;for(let t=0;t<m;++t){const e=Math.max(0,Math.ceil((z-t)/p)),n=Math.min(c.outDepth,(c.inDepth+z-t)/p),s=t*w;for(let r=0;r<g;++r){const a=Math.max(0,Math.ceil((O-r)/d)),i=Math.min(c.outHeight,(c.inHeight+O-r)/d),o=r*x+s;for(let s=0;s<y;++s){const l=Math.max(0,Math.ceil((C-s)/f)),u=Math.min(c.outWidth,(c.inWidth+C-s)/f),h=s*N+o;for(let o=0;o<c.inChannels;++o){const m=o*v+h;for(let h=0;h<c.outChannels;++h){let g=0;for(let m=0;m<c.batchSize;++m){const c=m*$,y=m*S;for(let m=e;m<n;++m){const e=(t+m*p-z)*M+c,n=m*T+y;for(let t=a;t<i;++t){const a=(r+t*d-O)*F+e,i=t*E+n;for(let t=l;t<u;++t){const e=t*A+i;g+=D[(s+t*f-C)*_+a+o]*I[e+h]}}}}k[m+h]=g}}}}}return n.makeTensorInfo(b.shape,b.dtype,b.values)}},_b={kernelName:Mt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,filter:a}=e,{pad:i,strides:o,inputShape:l}=s;Jg([r],"conv3dBackpropInputV2");const u=B(r.shape),h=B(a.shape),c=da(l,a.shape,o,1,i),p=new cs(c.inShape,"float32"),d=p.values,[f,m,g,y]=p.strides,b=n.data.get(r.dataId).values,[k,w,x,N]=u,v=n.data.get(a.dataId).values,[I,S,T,E]=h,{batchSize:A,filterDepth:D,filterHeight:$,filterWidth:M,inChannels:F,inDepth:_,inHeight:z,inWidth:C,outChannels:O,outDepth:L,outHeight:R,outWidth:W,strideDepth:P,strideHeight:V,strideWidth:U}=c,H=D-1-c.padInfo.front,j=$-1-c.padInfo.top,q=M-1-c.padInfo.left;for(let t=0;t<A;++t)for(let e=0;e<F;++e)for(let n=0;n<_;++n){const s=n-H,r=Math.max(0,Math.ceil(s/P)),a=Math.min(L,(D+s)/P);for(let i=0;i<z;++i){const o=i-j,l=Math.max(0,Math.ceil(o/V)),u=Math.min(R,($+o)/V);for(let h=0;h<C;++h){const c=h-q,p=Math.max(0,Math.ceil(c/U)),A=Math.min(W,(M+c)/U);let F=0;for(let n=r;n<a;++n){const r=n*P-s;for(let s=l;s<u;++s){const a=s*V-o;for(let i=p;i<A;++i){const o=k*t+w*n+x*s+N*i,l=I*(D-1-r)+S*($-1-a)+T*(M-1-(i*U-c))+E*e;for(let t=0;t<O;++t)F+=b[o+t]*v[l+t]}}}d[f*t+m*n+g*i+y*h+e]=F}}}return n.makeTensorInfo(p.shape,p.dtype,p.values)}},zb=Xg(Ft,(t=>Math.cos(t))),Cb={kernelName:Ft,backendName:"cpu",kernelFunc:zb},Ob=Xg(_t,(t=>Math.cosh(t))),Lb={kernelName:_t,backendName:"cpu",kernelFunc:Ob},Rb={kernelName:Ct,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{image:r,boxes:a,boxInd:i}=e,{cropSize:o,method:l,extrapolationValue:u}=s,[h,c,p,d]=r.shape,f=a.shape[0],[m,g]=o,y=vr([f,m,g,d],"float32"),b=n.data.get(a.dataId).values,k=n.data.get(i.dataId).values,w=n.data.get(r.dataId).values,x=B(r.shape),N=B(y.shape);for(let t=0;t<f;t++){const e=4*t,n=b[e],s=b[e+1],r=b[e+2],a=b[e+3],i=k[t];if(i>=h)continue;const o=m>1?(r-n)*(c-1)/(m-1):0,f=g>1?(a-s)*(p-1)/(g-1):0;for(let e=0;e<m;e++){const h=m>1?n*(c-1)+e*o:.5*(n+r)*(c-1);if(h<0||h>c-1)for(let n=0;n<g;n++)for(let s=0;s<d;s++){const r=s+n*N[2]+e*N[1]+t*N[0];y.values[r]=u}else if("bilinear"===l){const n=Math.floor(h),r=Math.ceil(h),o=h-n;for(let l=0;l<g;l++){const h=g>1?s*(p-1)+l*f:.5*(s+a)*(p-1);if(h<0||h>p-1){for(let n=0;n<d;n++){const s=n+l*N[2]+e*N[1]+t*N[0];y.values[s]=u}continue}const c=Math.floor(h),m=Math.ceil(h),b=h-c;for(let s=0;s<d;s++){let a=s+c*x[2]+n*x[1]+i*x[0];const u=w[a];a=s+m*x[2]+n*x[1]+i*x[0];const h=w[a];a=s+c*x[2]+r*x[1]+i*x[0];const p=w[a];a=s+m*x[2]+r*x[1]+i*x[0];const d=u+(h-u)*b,f=p+(w[a]-p)*b;a=s+l*N[2]+e*N[1]+t*N[0],y.values[a]=d+(f-d)*o}}}else for(let n=0;n<g;++n){const r=g>1?s*(p-1)+n*f:.5*(s+a)*(p-1);if(r<0||r>p-1){for(let s=0;s<d;s++){const r=s+n*N[2]+e*N[1]+t*N[0];y.values[r]=u}continue}const o=Math.round(r),l=Math.round(h);for(let s=0;s<d;s++){const r=s+o*x[2]+l*x[1]+i*x[0],a=s+n*N[2]+e*N[1]+t*N[0];y.values[a]=w[r]}}}}return n.makeTensorInfo(y.shape,y.dtype,y.values)}},Bb={kernelName:zt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{axis:a,exclusive:i,reverse:o}=s;Jg(r,"cumsum");const l=xi([a],r.shape.length);let u=r;null!=l&&(u=Wy({inputs:{x:r},backend:n,attrs:{perm:l}}));const h=vi(1,r.shape.length)[0];if(h!==u.shape.length-1)throw new Error(`backend.cumsum in CPU expects an inner-most axis=${u.shape.length-1} but got axis=${h}`);const c=vs(u.dtype,"int32"),p=U(E(u.shape),c),d=n.data.get(u.dataId).values,f=u.shape[u.shape.length-1],m=o?(t,e)=>t+f-e-1:(t,e)=>t+e;for(let t=0;t<d.length;t+=f)for(let e=0;e<f;e++){const n=m(t,e);if(0===e)p[n]=i?0:d[n];else{const s=m(t,e-1);p[n]=i?d[s]+p[s]:d[n]+p[s]}}const g=n.makeTensorInfo(u.shape,c,p);if(null!=l){const t=Wy({inputs:{x:g},backend:n,attrs:{perm:Ni(l)}});return n.disposeIntermediateTensorInfo(g),n.disposeIntermediateTensorInfo(u),t}return g}},Wb={kernelName:Ot,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,weights:a}=e,{size:i,binaryOutput:o}=s;if(1===r.shape.length){const t=fb(n.data.get(r.dataId).values,n.data.get(a.dataId).values,a.dtype,a.shape,i);return n.makeTensorInfo([i],a.dtype,t)}if(2===r.shape.length){const t=function(t,e,n,s=!1){const r=t.shape[0],a=t.shape[1],i=vr([r,n],e.dtype);for(let o=0;o<r;o++)for(let r=0;r<a;r++){const a=t.get(o,r);if(a<0)throw new Error("Input x must be non-negative!");a>=n||(s?i.set(1,o,a):e.size>0?i.set(i.get(o,a)+e.get(o,r),o,a):i.set(i.get(o,a)+1,o,a))}return i}(n.bufferSync(r),n.bufferSync(a),i,o);return n.makeTensorInfo(t.shape,a.dtype,t.values)}throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${r.shape.length}.`)}},Pb={kernelName:Lt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{blockSize:a,dataFormat:i}=s;v("NHWC"===i,(()=>`Only NHWC dataFormat supported on CPU for depthToSpace. Got ${i}`)),v(a>1,(()=>`blockSize should be > 1 for depthToSpace, but was: ${a}`));const o=r.shape[0],l=r.shape[1],u=r.shape[2],h=r.shape[3],c=l*a,p=u*a,d=h/(a*a),f=n.data.get(r.dataId).values,m=new Float32Array(o*c*p*d);let g=0;for(let t=0;t<o;++t)for(let e=0;e<c;++e){const n=Math.floor(e/a),s=e%a;for(let e=0;e<p;++e){const r=Math.floor(e/a),i=(s*a+e%a)*d;for(let e=0;e<d;++e){const s=e+i+h*(r+u*(n+l*t));m[g++]=f[s]}}}return n.makeTensorInfo([o,c,p,d],r.dtype,m)}};function Vb(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,filter:a}=e,{strides:i,pad:o,dilations:l,dimRoundingMode:u}=s;Jg([r,a],"depthwiseConv2DNative");const h=B(r.shape),c=B(a.shape);let p=l;null==p&&(p=[1,1]),v(wa(i,p),(()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${i} and dilations '${p}'`));const d=pa(r.shape,a.shape,i,p,o,u,!0),{filterHeight:f,filterWidth:m,dilationHeight:g,dilationWidth:y,padInfo:b}=d,k=b.left,w=b.top,x=d.outChannels/d.inChannels,N=new cs(d.outShape,r.dtype),I=n.data.get(r.dataId).values,S=n.data.get(a.dataId).values,T=N.values;for(let t=0;t<d.batchSize;++t){const e=t*h[0],n=t*N.strides[0];for(let t=0;t<d.outHeight;++t){const s=n+t*N.strides[1],r=t*d.strideHeight-k;for(let t=0;t<f;++t){const n=r+t*g;if(n<0||n>=d.inHeight)continue;const a=t*c[0],i=e+n*h[1];for(let t=0;t<d.outWidth;++t){const e=s+t*N.strides[2],n=t*d.strideWidth-w;for(let t=0;t<m;++t){const s=n+t*y;if(s<0||s>=d.inWidth)continue;const r=a+t*c[1],o=i+s*d.inChannels;let l=e,u=r;for(let t=0;t<d.inChannels;++t){const e=I[o+t];for(let t=0;t<x;++t)T[l+t]+=e*S[u+t];l+=x,u+=x}}}}}}return n.makeTensorInfo(N.shape,N.dtype,N.values)}const Ub={kernelName:Rt,backendName:"cpu",kernelFunc:Vb},Hb={kernelName:Bt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,dy:a}=e,{strides:i,dilations:o,pad:l,dimRoundingMode:u,filterShape:h}=s;Jg([r,a],"depthwiseConv2dNativeBackpropFilter");const c=pa(r.shape,h,i,o,l,u,!0),{strideHeight:p,strideWidth:d,filterHeight:f,filterWidth:m}=c,g=new cs(c.filterShape,"float32"),y=c.padInfo.left,b=c.padInfo.top,k=c.outChannels/c.inChannels,w=n.data.get(r.dataId).values,x=new cs(r.shape,r.dtype,w),N=n.data.get(a.dataId).values,v=new cs(a.shape,a.dtype,N);for(let t=0;t<f;++t){const e=Math.max(0,Math.ceil((b-t)/p)),n=Math.min(c.outHeight,(c.inHeight+b-t)/p);for(let s=0;s<m;++s){const r=Math.max(0,Math.ceil((y-s)/d)),a=Math.min(c.outWidth,(c.inWidth+y-s)/d);for(let i=0;i<c.outChannels;++i){const o=Math.trunc(i/k),l=i%k;let u=0;for(let l=0;l<c.batchSize;++l)for(let h=e;h<n;++h){const e=t+h*p-b;for(let t=r;t<a;++t){const n=s+t*d-y;u+=x.get(l,e,n,o)*v.get(l,h,t,i)}}g.set(u,t,s,o,l)}}}return n.makeTensorInfo(g.shape,g.dtype,g.values)}},jb={kernelName:Wt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,filter:a}=e,{strides:i,dilations:o,pad:l,dimRoundingMode:u,inputShape:h}=s;Jg([r,a],"depthwiseConv2DNativeBackpropInput");const c=B(r.shape),p=B(a.shape),d=pa(h,a.shape,i,o,l,u,!0),f=new cs(d.inShape,"float32"),m=f.values,[g,y,b]=f.strides,k=n.data.get(r.dataId).values,[w,x,N]=c,v=n.data.get(a.dataId).values,[I,S,T]=p,{batchSize:E,filterHeight:A,filterWidth:D,inChannels:$,inHeight:M,inWidth:F,outChannels:_,outHeight:z,outWidth:C,strideHeight:O,strideWidth:L}=d,R=A-1-d.padInfo.top,W=D-1-d.padInfo.left,P=_/$;for(let t=0;t<E;++t)for(let e=0;e<$;++e)for(let n=0;n<M;++n){const s=n-R,r=Math.max(0,Math.ceil(s/O)),a=Math.min(z,(A+s)/O);for(let i=0;i<F;++i){const o=i-W,l=Math.max(0,Math.ceil(o/L)),u=Math.min(C,(D+o)/L);let h=0;for(let n=r;n<a;++n){const r=n*O-s;for(let s=l;s<u;++s){const a=w*t+x*n+N*s,i=I*(A-1-r)+S*(D-1-(s*L-o))+T*e;for(let t=0;t<P;++t)h+=k[a+(e*P+t)]*v[i+t]}}m[g*t+y*n+b*i+e]=h}}return n.makeTensorInfo(f.shape,f.dtype,f.values)}},qb={kernelName:"Diag",backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n}=t,{x:s}=e,r=E(s.shape),a=n.data.get(s.dataId).values,i=vr([r,r],s.dtype),o=i.values;for(let t=0;t<a.length;t++)o[t*r+t]=a[t];const l=[...s.shape,...s.shape];return n.makeTensorInfo(l,i.dtype,i.values)}},Gb={kernelName:Pt,backendName:"cpu",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{x:s,filter:r}=t,{strides:a,pad:i,dilations:o}=n,l=e,u=l.data.get(s.dataId).values,h=s.shape.length,c=l.data.get(r.dataId).values,p=r.shape.length,{batchSize:d,inHeight:f,inWidth:m,inChannels:g,outHeight:y,outWidth:b,padInfo:k,strideHeight:w,strideWidth:x,filterHeight:N,filterWidth:v,dilationHeight:I,dilationWidth:S,outShape:T}=ua(s.shape,r.shape,a,i,"NHWC",o),A=E(T),D=T.length,$=_(s.dtype,A);for(let t=0;t<d;++t)for(let e=0;e<y;++e){const n=e*w-k.top;for(let a=0;a<b;++a){const i=a*x-k.left;for(let o=0;o<g;++o){let l=Number.MIN_SAFE_INTEGER;for(let e=0;e<N;++e){const a=n+e*I;if(a>=0&&a<f)for(let n=0;n<v;++n){const d=i+n*S;if(d>=0&&d<m){const i=q([t,a,d,o],h,B(s.shape)),f=q([e,n,o],p,B(r.shape)),m=u[i]+c[f];m>l&&(l=m)}}}$[q([t,e,a,o],D,B(T))]=l}}}return{dataId:l.write(os($,s.dtype),T,s.dtype),shape:T,dtype:s.dtype}}},Kb={kernelName:Ut,backendName:"cpu",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{x:s,filter:r,dy:a}=t,{strides:i,pad:o,dilations:l}=n,u=e,h=P(s.shape,u.data.get(s.dataId).values),c=P(r.shape,u.data.get(r.dataId).values),{batchSize:p,inHeight:d,inWidth:f,inChannels:m,outHeight:g,outWidth:y,padInfo:b,strideHeight:k,strideWidth:w,filterHeight:x,filterWidth:N,dilationHeight:I,dilationWidth:S,outShape:T}=ua(s.shape,r.shape,i,o,"NHWC",l);v(a.rank===T.length,(()=>`Error in Dilation2DBackpropFilter, dy must have the same rank as output ${T.length}, but got ${a.rank}`));const E=P(T,u.data.get(a.dataId).values),A=H(r.shape,r.dtype);for(let t=0;t<p;++t)for(let e=0;e<g;++e){const n=e*k-b.top;for(let s=0;s<y;++s){const r=s*w-b.left;for(let a=0;a<m;++a){let i=Number.MIN_SAFE_INTEGER,o=0,l=0;for(let e=0;e<x;++e){const s=n+e*I;if(s>=0&&s<d)for(let n=0;n<N;++n){const u=r+n*S;if(u>=0&&u<f){const r=h[t][s][u][a]+c[e][n][a];r>i&&(i=r,o=e,l=n)}}}A[o][l][a]+=E[t][e][s][a]}}}return{dataId:u.write(os(A,s.dtype),r.shape,r.dtype),shape:r.shape,dtype:r.dtype}}},Jb={kernelName:Vt,backendName:"cpu",kernelFunc:({inputs:t,backend:e,attrs:n})=>{const{x:s,filter:r,dy:a}=t,{strides:i,pad:o,dilations:l}=n,u=e,h=P(s.shape,u.data.get(s.dataId).values),c=P(r.shape,u.data.get(r.dataId).values),{batchSize:p,inHeight:d,inWidth:f,inChannels:m,outHeight:g,outWidth:y,padInfo:b,strideHeight:k,strideWidth:w,filterHeight:x,filterWidth:N,dilationHeight:I,dilationWidth:S,outShape:T}=ua(s.shape,r.shape,i,o,"NHWC",l);v(a.rank===T.length,(()=>`Error in Dilation2DBackpropInput, dy must have the same rank as output ${T.length}, but got ${a.rank}`));const E=P(T,u.data.get(a.dataId).values),A=H(s.shape,s.dtype);for(let t=0;t<p;++t)for(let e=0;e<g;++e){const n=e*k-b.top;for(let s=0;s<y;++s){const r=s*w-b.left;for(let a=0;a<m;++a){let i=Number.MIN_SAFE_INTEGER,o=n<0?0:n,l=r<0?0:r;for(let e=0;e<x;++e){const s=n+e*I;if(s>=0&&s<d)for(let n=0;n<N;++n){const u=r+n*S;if(u>=0&&u<f){const r=h[t][s][u][a]+c[e][n][a];r>i&&(i=r,o=s,l=u)}}}A[t][o][l][a]+=E[t][e][s][a]}}}return{dataId:u.write(os(A,s.dtype),s.shape,s.dtype),shape:s.shape,dtype:s.dtype}}},Zb={kernelName:qt,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n}=t,{dy:s,y:r}=e;Jg([s,r],"eluGrad");const a=new Float32Array(E(r.shape)),i=n.data.get(r.dataId).values,o=n.data.get(s.dataId).values;for(let t=0;t<i.length;++t){const e=i[t];a[t]=e>=1?o[t]:o[t]*(e+1)}return n.makeTensorInfo(r.shape,"float32",a)}},Yb=iy(((t,e)=>t===e?1:0)),Xb=Ny(Kt,Yb,null,"bool"),Qb={kernelName:Kt,backendName:"cpu",kernelFunc:Xb},tk=Xg(Gt,(t=>{const e=Math.sign(t),n=Math.abs(t),s=1/(1+.3275911*n);return e*(1-((((1.061405429*s-1.453152027)*s+1.421413741)*s-.284496736)*s+.254829592)*s*Math.exp(-n*n))})),ek={kernelName:Gt,backendName:"cpu",kernelFunc:tk},nk=gb((t=>Math.exp(t))),sk=Qg(Jt,nk),rk={kernelName:Jt,backendName:"cpu",kernelFunc:sk};function ak(t){const{inputs:e,backend:n,attrs:s}=t,{input:r}=e,{dim:a}=s,i=r.shape.length,o=r.shape.slice();let l=a;return a<0&&(v(-(i+1)<=a,(()=>`Axis must be in the interval [${-(i+1)}, ${i}]`)),l=i+a+1),o.splice(l,0,1),Ay({inputs:{x:r},backend:n,attrs:{shape:o}})}const ik={kernelName:Zt,backendName:"cpu",kernelFunc:ak},ok=gb((t=>Math.expm1(t))),lk=Qg(Yt,ok),uk={kernelName:Yt,backendName:"cpu",kernelFunc:lk},hk=iy(((t,e)=>t*e)),ck=vy(((t,e,n,s)=>({real:t*n-e*s,imag:t*s+e*n}))),pk=Ny(Le,hk,ck),dk={kernelName:Le,backendName:"cpu",kernelFunc:pk},fk=iy(((t,e)=>t/e)),mk=Ny(Ht,fk),gk={kernelName:Ht,backendName:"cpu",kernelFunc:mk},yk=iy(((t,e)=>t-e)),bk=vy(((t,e,n,s)=>({real:t-n,imag:e-s}))),kk=Ny(Tn,yk,bk),wk={kernelName:Tn,backendName:"cpu",kernelFunc:kk};function xk(t,e,n){const s=t.shape,r=s[0],a=s[1],i=n.data.get(t.dataId),o=i.complexTensorInfos.real,l=i.complexTensorInfos.imag,u=[r,a],h=E(u),c=F("float32",h),p=F("float32",h);for(let t=0;t<r;t++){const s=cb({inputs:{x:o},backend:n,attrs:{begin:[t,0],size:[1,a]}}),r=cb({inputs:{x:l},backend:n,attrs:{begin:[t,0],size:[1,a]}}),i=my({inputs:{real:s,imag:r},backend:n}),{real:u,imag:h}=Nk(i,e,n),d=$l(u,h);for(let e=0;e<a;e++){const n=Ml(d,e);c[t*a+e]=n.real,p[t*a+e]=n.imag}n.disposeIntermediateTensorInfo(s),n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(i)}const d=n.makeTensorInfo(u,"float32",c),f=n.makeTensorInfo(u,"float32",p),m=my({inputs:{real:d,imag:f},backend:n});return n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),m}function Nk(t,e,n){const s=E(t.shape),r=n.data.get(t.dataId),a=n.data.get(r.complexTensorInfos.real.dataId).values,i=n.data.get(r.complexTensorInfos.imag.dataId).values;if(0==((o=s)&o-1)){const r=vk(a,i,s,e,n),o=[t.shape[0],t.shape[1]];if(e){const t=n.makeTensorInfo(o,"float32",r.real),e=n.makeTensorInfo(o,"float32",r.imag),a=n.makeTensorInfo([],"float32",is(s,"float32")),i=ny({inputs:{x:a},backend:n}),l=gk.kernelFunc({inputs:{a:t,b:a},backend:n}),u=gk.kernelFunc({inputs:{a:e,b:i},backend:n}),h=n.data.get(l.dataId).values,c=n.data.get(u.dataId).values;return n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(l),n.disposeIntermediateTensorInfo(u),{real:h,imag:c}}return r}return function(t){const e=new Float32Array(t.length/2),n=new Float32Array(t.length/2);for(let s=0;s<t.length;s+=2)e[s/2]=t[s],n[s/2]=t[s+1];return{real:e,imag:n}}(function(t,e,n){const s=new Float32Array(2*e);for(let r=0;r<e;r++){let a=0,i=0;for(let s=0;s<e;s++){const o=_l(r*s,e,n),l=Ml(t,s);a+=l.real*o.real-l.imag*o.imag,i+=l.real*o.imag+l.imag*o.real}n&&(a/=e,i/=e),Fl(s,a,i,r)}return s}($l(a,i),s,e));var o}function vk(t,e,n,s,r){if(1===n)return{real:t,imag:e};const a=$l(t,e),i=n/2,o=function(t){const e=Math.ceil(t.length/4),n=new Float32Array(e),s=new Float32Array(e);for(let e=0;e<t.length;e+=4)n[Math.floor(e/4)]=t[e],s[Math.floor(e/4)]=t[e+1];return{real:n,imag:s}}(a),l=o.real,u=o.imag,h=[l.length],c=r.makeTensorInfo(h,"float32",l),p=r.makeTensorInfo(h,"float32",u),d=my({inputs:{real:c,imag:p},backend:r}),f=function(t){const e=Math.floor(t.length/4),n=new Float32Array(e),s=new Float32Array(e);for(let e=2;e<t.length;e+=4)n[Math.floor(e/4)]=t[e],s[Math.floor(e/4)]=t[e+1];return{real:n,imag:s}}(a),m=f.real,g=f.imag,y=[m.length],b=r.makeTensorInfo(y,"float32",m),k=r.makeTensorInfo(y,"float32",g),w=my({inputs:{real:b,imag:k},backend:r}),x=vk(l,u,i,s,r),N=x.real,v=x.imag,I=[N.length],S=r.makeTensorInfo(I,"float32",N),T=r.makeTensorInfo(I,"float32",v),E=my({inputs:{real:S,imag:T},backend:r}),A=vk(m,g,i,s,r),D=A.real,$=A.imag,M=[D.length],F=r.makeTensorInfo(M,"float32",D),_=r.makeTensorInfo(M,"float32",$),z=my({inputs:{real:F,imag:_},backend:r}),C=function(t,e){const n=new Float32Array(t/2),s=new Float32Array(t/2);for(let r=0;r<Math.ceil(t/2);r++){const a=(e?2:-2)*Math.PI*(r/t);n[r]=Math.cos(a),s[r]=Math.sin(a)}return{real:n,imag:s}}(n,s),O=[C.real.length],L=r.makeTensorInfo(O,"float32",C.real),R=r.makeTensorInfo(O,"float32",C.imag),B=my({inputs:{real:L,imag:R},backend:r}),W=pk({inputs:{a:B,b:z},backend:r}),P=Ty({inputs:{a:E,b:W},backend:r}),V=kk({inputs:{a:E,b:W},backend:r}),U=by({inputs:{input:P},backend:r}),H=by({inputs:{input:V},backend:r}),j=vb({inputs:{input:P},backend:r}),q=vb({inputs:{input:V},backend:r}),G=Sb({inputs:[U,H],backend:r,attrs:{axis:0}}),K=Sb({inputs:[j,q],backend:r,attrs:{axis:0}}),J=r.data.get(G.dataId).values,Z=r.data.get(K.dataId).values;return r.disposeIntermediateTensorInfo(c),r.disposeIntermediateTensorInfo(p),r.disposeIntermediateTensorInfo(d),r.disposeIntermediateTensorInfo(b),r.disposeIntermediateTensorInfo(k),r.disposeIntermediateTensorInfo(w),r.disposeIntermediateTensorInfo(S),r.disposeIntermediateTensorInfo(T),r.disposeIntermediateTensorInfo(E),r.disposeIntermediateTensorInfo(F),r.disposeIntermediateTensorInfo(_),r.disposeIntermediateTensorInfo(z),r.disposeIntermediateTensorInfo(L),r.disposeIntermediateTensorInfo(R),r.disposeIntermediateTensorInfo(B),r.disposeIntermediateTensorInfo(W),r.disposeIntermediateTensorInfo(P),r.disposeIntermediateTensorInfo(V),r.disposeIntermediateTensorInfo(U),r.disposeIntermediateTensorInfo(j),r.disposeIntermediateTensorInfo(H),r.disposeIntermediateTensorInfo(q),r.disposeIntermediateTensorInfo(G),r.disposeIntermediateTensorInfo(K),{real:J,imag:Z}}const Ik={kernelName:"FFT",backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n}=t,{input:s}=e,r=E(s.shape),a=s.shape[s.shape.length-1],i=Ay({inputs:{x:s},backend:n,attrs:{shape:[r/a,a]}}),o=xk(i,!1,n),l=Ay({inputs:{x:o},backend:n,attrs:{shape:s.shape}});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(o),l}};function Sk(t){const{backend:e,attrs:n}=t,{shape:s,value:r,dtype:a}=n,i=a||L(r),o=_(i,E(s));return function(t,e,n){t.fill(e)}(o,r),e.makeTensorInfo(s,i,o)}const Tk={kernelName:Xt,backendName:"cpu",kernelFunc:Sk},Ek={kernelName:Qt,backendName:"cpu",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{image:s}=t,r=n,a=F(s.dtype,E(s.shape)),[i,o,l,u]=s.shape,h=r.data.get(s.dataId).values;for(let t=0;t<i;t++){const e=t*l*o*u;for(let t=0;t<o;t++){const n=t*(l*u);for(let s=0;s<l;s++){const r=s*u;for(let o=0;o<u;o++){const c=[i,t,s,o][2],p=Math.round(l-c),d=e+n+r+o;let f=h[d];p>=0&&p<l&&(f=h[e+n+p*u+o]),a[d]=f}}}}return{dataId:r.write(a,s.shape,s.dtype),shape:s.shape,dtype:s.dtype}}},Ak=gb((t=>Math.floor(t))),Dk=Qg(te,Ak),$k={kernelName:te,backendName:"cpu",kernelFunc:Dk},Mk=iy(((t,e)=>Math.floor(t/e))),Fk=Ny(ee,Mk,null,"int32"),_k={kernelName:ee,backendName:"cpu",kernelFunc:Fk},zk={kernelName:Vn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,filter:a,bias:i,preluActivationWeights:o}=e,{strides:l,pad:u,dataFormat:h,dilations:c,dimRoundingMode:p,activation:d,leakyreluAlpha:f}=s;let m=Eb({inputs:{x:r,filter:a},backend:n,attrs:{strides:l,pad:u,dataFormat:h,dilations:c,dimRoundingMode:p}});if(i){const t=m;m=Ty({inputs:{a:m,b:i},backend:n}),n.disposeIntermediateTensorInfo(t)}if(d){const t=m;m=fy(n,m,d,o,f),n.disposeIntermediateTensorInfo(t)}return m}},Ck={kernelName:Un,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,filter:a,bias:i,preluActivationWeights:o}=e,{strides:l,pad:u,dataFormat:h,dilations:c,dimRoundingMode:p,activation:d,leakyreluAlpha:f}=s;let m=Vb({inputs:{x:r,filter:a},backend:n,attrs:{strides:l,pad:u,dataFormat:h,dilations:c,dimRoundingMode:p}});if(i){const t=m;m=Ty({inputs:{a:m,b:i},backend:n}),n.disposeIntermediateTensorInfo(t)}if(d){const t=m;m=fy(n,m,d,o,f),n.disposeIntermediateTensorInfo(t)}return m}},Ok={kernelName:re,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n}=t,{params:s,indices:r}=e,a=E(s.shape),i=r.shape,o=i[i.length-1],[l,u,h,c]=function(t,e){const n=t.shape.length,s=e.shape.length;if(n<1)throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${n}.`);if(s<1)throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${s}.`);if("int32"!==e.dtype)throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${e.dtype}.`);if(e.shape[s-1]>n)throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${e.shape[s-1]} vs. ${n}`);if(0===E(t.shape))throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${t.shape}.`);const r=e.shape,a=r[r.length-1];let i=1;for(let t=0;t<r.length-1;++t)i*=r[t];const o=t.shape,l=r.slice();l.pop();let u=1;for(let t=a;t<n;++t)u*=o[t],l.push(o[t]);const h=[...B(t.shape).map((t=>t/u)),1].slice(0,a);return[l,i,u,h]}(s,r);if(0===u)return n.makeTensorInfo(l,s.dtype,[]);const p=vr([u,h],s.dtype),d=n.data.get(r.dataId).values,f=n.data.get(s.dataId).values;for(let t=0;t<u;t++){const e=[];let n=0;for(let s=0;s<o;s++){const r=d[t*o+s];n+=r*c[s],e.push(r)}if(n<0||n>=a/h)throw new Error(`Invalid indices: ${e} does not index into ${s.shape}`);for(let e=0;e<h;e++)p.values[t*h+e]=f[n*h+e]}return n.makeTensorInfo(l,p.dtype,p.values)}},Lk={kernelName:se,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,indices:a}=e,{axis:i,batchDims:o}=s;Jg([r,a],"gatherV2");let l=o;null==o&&(l=0);const u=E(a.shape),h=function(t,e,n,s){const r=e.shape.length,a=t.shape.length;if(0!==s&&(s<-r||s>r))throw new Error(`Expect batchDims in the range of [-${r}, ${r}], but got ${s}`);if(s<0&&(s+=r),s>a)throw new Error(`batchDims (${s}) must be less than rank(x) (\n    ${a}).`);if(n<s)throw new Error(`batchDims (${s}) must be less than or equal to axis (${n}).`);for(let n=0;n<s;++n)if(t.shape[n]!==e.shape[n])throw new Error(`x.shape[${n}]: ${t.shape[n]} should be equal to indices.shape[${n}]: ${e.shape[n]}.`);const i=t.shape[n],o=[];let l=1,u=1,h=1;for(let e=0;e<s;++e)o.push(t.shape[e]),l*=t.shape[e];for(let e=s;e<n;e++)o.push(t.shape[e]),u*=t.shape[e];for(let t=s;t<r;t++)o.push(e.shape[t]);for(let e=n+1;e<a;e++)o.push(t.shape[e]),h*=t.shape[e];return{batchSize:l,sliceSize:h,outerSize:u,dimSize:i,outputShape:o}}(r,a,M(i,r.shape)[0],l),c=Ay({inputs:{x:r},backend:n,attrs:{shape:[h.batchSize,h.outerSize,h.dimSize,h.sliceSize]}}),p=Ay({inputs:{x:a},backend:n,attrs:{shape:[h.batchSize,u/h.batchSize]}}),d=[h.batchSize,h.outerSize,u/h.batchSize,h.sliceSize],f=n.bufferSync(p),m=function(t,e,n){const s=vr(n,t.dtype);for(let n=0;n<s.size;++n){const r=s.indexToLoc(n).slice(),a=r[0],i=r[2],o=e.locToIndex([a,i]);r[2]=e.values[o];const l=t.locToIndex(r);s.values[n]=t.values[l]}return s}(n.bufferSync(c),f,d);return n.disposeIntermediateTensorInfo(c),n.disposeIntermediateTensorInfo(p),n.makeTensorInfo(h.outputShape,m.dtype,m.values)}},Rk=iy(((t,e)=>t>e?1:0)),Bk=Ny(ae,Rk,null,"bool"),Wk={kernelName:ae,backendName:"cpu",kernelFunc:Bk},Pk=iy(((t,e)=>t>=e?1:0)),Vk=Ny(ie,Pk,null,"bool"),Uk={kernelName:ie,backendName:"cpu",kernelFunc:Vk},Hk={kernelName:le,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n}=t,{input:s}=e,r=E(s.shape),a=s.shape[s.shape.length-1],i=Ay({inputs:{x:s},backend:n,attrs:{shape:[r/a,a]}}),o=xk(i,!0,n),l=Ay({inputs:{x:o},backend:n,attrs:{shape:s.shape}});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(o),l}},jk=Xg(he,(t=>Number.isFinite(t)?1:0),"bool"),qk={kernelName:he,backendName:"cpu",kernelFunc:jk},Gk=Xg(ce,(t=>Math.abs(t)===1/0?1:0),"bool"),Kk={kernelName:ce,backendName:"cpu",kernelFunc:Gk},Jk=Xg(pe,(t=>Number.isNaN(t)?1:0),"bool"),Zk={kernelName:pe,backendName:"cpu",kernelFunc:Jk},Yk=iy(((t,e)=>t<e?1:0)),Xk=Ny(fe,Yk,null,"bool"),Qk={kernelName:fe,backendName:"cpu",kernelFunc:Xk},tw=iy(((t,e)=>t<=e?1:0)),ew=Ny(me,tw,null,"bool"),nw={kernelName:me,backendName:"cpu",kernelFunc:ew},sw={kernelName:ge,backendName:"cpu",kernelFunc:function(t){const{backend:e,attrs:n}=t,{start:s,stop:r,num:a}=n,i=function(t,e,n){const s=(e-t)/(n-1),r=U(n,"float32");r[0]=t;for(let t=1;t<r.length;t++)r[t]=r[t-1]+s;return r}(s,r,a);return e.makeTensorInfo([i.length],"float32",i)}},rw=gb((t=>Math.log(t))),aw=Qg(ye,rw),iw={kernelName:ye,backendName:"cpu",kernelFunc:aw},ow=Xg(be,(t=>Math.log1p(t))),lw={kernelName:be,backendName:"cpu",kernelFunc:ow},uw=iy(((t,e)=>t&&e)),hw=Ny(ke,uw,null,"bool"),cw={kernelName:ke,backendName:"cpu",kernelFunc:hw},pw=Xg(we,(t=>t?0:1),"bool"),dw={kernelName:we,backendName:"cpu",kernelFunc:pw},fw=iy(((t,e)=>t||e)),mw=Ny(xe,fw,null,"bool"),gw={kernelName:xe,backendName:"cpu",kernelFunc:mw},yw={kernelName:Ne,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{depthRadius:a,bias:i,alpha:o,beta:l}=s;Jg(r,"LRN");const u=r.shape[3],h=u-1,c=n.data.get(r.dataId).values,p=E(r.shape),d=new Float32Array(p);function f(t){const e=t%u;let n=t-e+Math.max(0,e-a);const s=t-e+Math.min(e+a,h);let r=0;for(;n<=s;n++){const t=c[n];r+=t*t}return r}for(let t=0;t<p;t++){const e=f(t),n=c[t]*Math.pow(i+o*e,-l);d[t]=n}return n.makeTensorInfo(r.shape,r.dtype,d)}},bw={kernelName:ve,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,y:a,dy:i}=e,{depthRadius:o,bias:l,alpha:u,beta:h}=s;Jg(i,"LRNGrad");const c=E(i.shape),p=i.shape[3],d=n.data.get(i.dataId).values,f=n.data.get(r.dataId).values,m=n.data.get(a.dataId).values,g=new Float32Array(c),y=c;for(let t=0;t<y;t++){const e=t%p,n=t-e+Math.max(0,e-o),s=t-e+Math.min(p,e+o+1);let r=0;for(let t=n;t<s;t++)r+=Math.pow(f[t],2);r=u*r+l;for(let e=n;e<s;e++){let n=-2*u*h*f[e]*m[t]/r;t===e&&(n+=Math.pow(r,-h)),n*=d[t],g[e]+=n}}return n.makeTensorInfo(i.shape,r.dtype,g)}};function kw(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{reductionIndices:a,keepDims:i}=s,o=n;let l=r.shape;const u=l.length,h=M(a,l);let c=h;const p=xi(c,u);let d=o.data.get(r.dataId).values;if(null!=p){const t=new Array(u);for(let e=0;e<t.length;e++)t[e]=l[p[e]];d=By(d,l,r.dtype,p,t),c=vi(c.length,u),l=t}Jg(r,"max"),wi("max",c,u);const[f,m]=bi(l,c),g=function(t,e,n,s){const r=F(s,E(n));for(let n=0;n<r.length;++n){const s=n*e;let a=t[s];for(let n=0;n<e;++n){const e=t[s+n];e>a&&(a=e)}r[n]=a}return r}(d,E(m),f,r.dtype),y=o.write(g,f,r.dtype);let b=f;return i&&(b=ki(f,h)),{dataId:y,shape:b,dtype:r.dtype}}const ww={kernelName:Ie,backendName:"cpu",kernelFunc:kw},xw=iy(((t,e)=>Math.max(t,e))),Nw=Ny(Se,xw),vw={kernelName:Se,backendName:"cpu",kernelFunc:Nw},Iw={kernelName:Te,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e;Jg(r,"maxPool");const{filterSize:a,strides:i,pad:o,dimRoundingMode:l}=s;v(wa(i,1),(()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${i} and dilations '1'`));const u=ha(r.shape,a,i,1,o,l);let h;if(1===u.filterWidth&&1===u.filterHeight&&A(u.inShape,u.outShape))h=ny({inputs:{x:r},backend:n});else{const t=n.data.get(r.dataId).values,e=B(r.shape),s=sb(t,r.shape,r.dtype,e,u,"max");h=n.makeTensorInfo(u.outShape,r.dtype,s.values)}return h}},Sw={kernelName:Ae,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{filterSize:a,strides:i,pad:o,dimRoundingMode:l,dataFormat:u,dilations:h}=s;Jg(r,"maxPool3d");let c=h;null==c&&(c=[1,1,1]);const p=ca(r.shape,a,i,c,o,l,u),d=ab(n.data.get(r.dataId).values,r.shape,r.dtype,B(r.shape),p,"max");return n.makeTensorInfo(d.shape,"float32",d.values)}},Tw={kernelName:De,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,input:a}=e,{filterSize:i,strides:o,pad:l,dilations:u,dimRoundingMode:h}=s;Jg([r,a],"maxPool3DGrad");const c=ca(a.shape,i,o,u,l,h),p=function(t,e){const n=vr(e.outShape,"int32"),s=e.strideDepth,r=e.strideHeight,a=e.strideWidth,i=e.dilationDepth,o=e.dilationHeight,l=e.dilationWidth,u=e.effectiveFilterDepth,h=e.effectiveFilterHeight,c=e.effectiveFilterWidth,p=e.padInfo.front,d=e.padInfo.top,f=e.padInfo.left;for(let m=0;m<e.batchSize;++m)for(let g=0;g<e.inChannels;++g)for(let y=0;y<e.outDepth;++y){const b=y*s-p;let k=b;for(;k<0;)k+=i;const w=Math.min(e.inDepth,u+b);for(let s=0;s<e.outHeight;++s){const u=s*r-d;let p=u;for(;p<0;)p+=o;const x=Math.min(e.inHeight,h+u);for(let r=0;r<e.outWidth;++r){const d=r*a-f;let N=d;for(;N<0;)N+=l;const v=Math.min(e.inWidth,c+d);let I=Number.NEGATIVE_INFINITY,S=-1;for(let e=k;e<w;e+=i){const n=e-b;for(let s=p;s<x;s+=o){const r=s-u;for(let a=N;a<v;a+=l){const i=a-d,o=t.get(m,e,s,a,g);o>=I&&(I=o,S=n*h*c+r*h+i)}}}n.set(S,m,y,s,r,g)}}}return n}(n.bufferSync(a),c),d=c.strideDepth,f=c.strideHeight,m=c.strideWidth,g=c.dilationDepth,y=c.dilationHeight,b=c.dilationWidth,k=c.effectiveFilterDepth,w=c.effectiveFilterHeight,x=c.effectiveFilterWidth,N=k-1-c.padInfo.front,v=x-1-c.padInfo.left,I=w-1-c.padInfo.top,S=vr(a.shape,"float32"),T=n.bufferSync(r);for(let t=0;t<c.batchSize;++t)for(let e=0;e<c.inChannels;++e)for(let n=0;n<c.inDepth;++n)for(let s=0;s<c.inHeight;++s)for(let r=0;r<c.inWidth;++r){const a=n-N,i=s-I,o=r-v;let l=0;for(let n=0;n<k;n+=g){const s=(a+n)/d;if(!(s<0||s>=c.outDepth||Math.floor(s)!==s))for(let r=0;r<w;r+=y){const a=(i+r)/f;if(!(a<0||a>=c.outHeight||Math.floor(a)!==a))for(let i=0;i<x;i+=b){const u=(o+i)/m;if(u<0||u>=c.outWidth||Math.floor(u)!==u)continue;const h=k*w*x-1-p.get(t,s,a,u,e)===n*w*x+r*x+i?1:0;0!==h&&(l+=T.get(t,s,a,u,e)*h)}}}S.set(l,t,n,s,r,e)}return n.makeTensorInfo(S.shape,S.dtype,S.values)}},Ew={kernelName:Ee,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{dy:r,input:a,output:i}=e,o=a;Jg([a,i],"maxPoolGrad");const{filterSize:l,strides:u,pad:h,dimRoundingMode:c}=s,p=ha(o.shape,l,u,1,h,c),d=n.data.get(o.dataId).values,f=vr(p.outShape,o.dtype,rb(d,o.shape,o.dtype,p).values),m=p.strideHeight,g=p.strideWidth,y=p.dilationHeight,b=p.dilationWidth,k=p.effectiveFilterHeight,w=p.effectiveFilterWidth,x=w-1-p.padInfo.left,N=k-1-p.padInfo.top,v=vr(o.shape,"float32"),I=n.data.get(r.dataId).values,S=vr(r.shape,"float32",I);for(let t=0;t<p.batchSize;++t)for(let e=0;e<p.inChannels;++e)for(let n=0;n<p.inHeight;++n)for(let s=0;s<p.inWidth;++s){const r=n-N,a=s-x;let i=0;for(let n=0;n<k;n+=y){const s=(r+n)/m;if(!(s<0||s>=p.outHeight||Math.floor(s)!==s))for(let r=0;r<w;r+=b){const o=(a+r)/g;if(o<0||o>=p.outWidth||Math.floor(o)!==o)continue;const l=k*w-1-f.get(t,s,o,e)===n*w+r?1:0;0!==l&&(i+=S.get(t,s,o,e)*l)}}v.set(i,t,n,s,e)}return n.makeTensorInfo(v.shape,v.dtype,v.values)}},Aw={kernelName:$e,backendName:"cpu",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{x:s}=t,{filterSize:r,strides:a,pad:i,includeBatchInIndex:o}=e,l=n;Jg(s,"MaxPoolWithArgmax");const u=l.data.get(s.dataId).values,h=ha(s.shape,r,a,[1,1],i),[c,p]=function(t,e,n,s,r){const a=sb(t,0,n,B(e),r,"max"),i=rb(t,e,n,r,!0,s);return[a.values,i.values]}(u,s.shape,s.dtype,o,h),d=l.write(c,h.outShape,s.dtype),f=l.write(p,h.outShape,s.dtype);return[{dataId:d,shape:h.outShape,dtype:s.dtype},{dataId:f,shape:h.outShape,dtype:"int32"}]}};function Dw(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{axis:a,keepDims:i}=s;let o;Jg(r,"sum"),o="bool"===r.dtype?wy({inputs:{x:r},backend:n,attrs:{dtype:"int32"}}):ny({inputs:{x:r},backend:n});const l=o.shape.length,u=M(a,o.shape),h=xi(u,l);let c=u,p=o;null!=h&&(p=Wy({inputs:{x:o},backend:n,attrs:{perm:h}}),c=vi(c.length,l)),wi("sum",c,p.shape.length);const[d,f]=bi(p.shape,c);let m=yy(n,d,vs(p.dtype,"int32"));const g=E(f),y=n.data.get(m.dataId).values,b=n.data.get(p.dataId).values;for(let t=0;t<y.length;++t){const e=t*g;let n=0;for(let t=0;t<g;++t)n+=b[e+t];y[t]=n}if(i){const t=m;m=Ay({inputs:{x:m},backend:n,attrs:{shape:ki(m.shape,u)}}),n.disposeIntermediateTensorInfo(t)}return n.disposeIntermediateTensorInfo(o),null!=h&&n.disposeIntermediateTensorInfo(p),m}const $w={kernelName:wn,backendName:"cpu",kernelFunc:Dw},Mw={kernelName:Me,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{axis:a,keepDims:i}=s,o=M(a,r.shape),l=E(bi(r.shape,o)[1]),u=[],h=n.makeTensorInfo([],"float32",new Float32Array([l]));u.push(h);const c=wy({inputs:{x:r},backend:n,attrs:{dtype:"float32"}});u.push(c);const p=mk({inputs:{a:c,b:h},backend:n});u.push(p);const d=Dw({inputs:{x:p},backend:n,attrs:{axis:a,keepDims:i}});return u.forEach((t=>n.disposeIntermediateTensorInfo(t))),d}},Fw={kernelName:Fe,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{axis:a,keepDims:i}=s;Jg(r,"min");const o=M(a,r.shape);let l=o;const u=xi(l,r.shape.length);let h=r;null!=u&&(h=Wy({inputs:{x:r},backend:n,attrs:{perm:u}}),l=vi(l.length,r.shape.length)),wi("min",l,h.shape.length);const[c,p]=bi(h.shape,l),d=E(p),f=U(E(c),h.dtype),m=n.data.get(h.dataId).values;for(let t=0;t<f.length;++t){const e=t*d;let n=m[e];for(let t=0;t<d;++t){const s=m[e+t];s<n&&(n=s)}f[t]=n}null!=u&&n.disposeIntermediateTensorInfo(h);const g=n.makeTensorInfo(c,h.dtype,f);if(i){const t=Ay({inputs:{x:g},backend:n,attrs:{shape:ki(c,o)}});return n.disposeIntermediateTensorInfo(g),t}return g}},_w=iy(((t,e)=>Math.min(t,e))),zw=Ny(_e,_w),Cw={kernelName:_e,backendName:"cpu",kernelFunc:zw},Ow={kernelName:ze,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{paddings:a,mode:i}=s;Jg(r,"mirrorPad");const o=a.map(((t,e)=>t[0]+r.shape[e]+t[1])),l=a.map((t=>t[0])),u=a.map(((t,e)=>t[0]+r.shape[e])),h="reflect"===i?0:1,c=n.data.get(r.dataId).values,p=r.shape.length,d=B(r.shape),f=E(o),m=o.length,g=B(o),y=F(r.dtype,f);for(let t=0;t<f;t++){let e=G(t,m,g);for(let t=0;t<m;t++)e[t]<l[t]?e[t]=2*l[t]-e[t]-h:e[t]>=u[t]&&(e[t]=2*(u[t]-1)-e[t]+h);e=e.map(((t,e)=>t-l[e]));const n=q(e,p,d);y[t]=c[n]}return{dataId:n.write(y,o,r.dtype),shape:o,dtype:r.dtype}}},Lw=iy(((t,e)=>{const n=t%e;return t<0&&e<0||t>=0&&e>=0?n:(n+e)%e})),Rw=Ny(Ce,Lw),Bw={kernelName:Ce,backendName:"cpu",kernelFunc:Rw};function Ww(t){const{inputs:e,backend:n,attrs:s}=t,{logits:r}=e,{dim:a}=s,i=r.shape.length;let o=a;if(-1===o&&(o=i-1),o!==i-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${i} and dim was ${o}`);const l=M([o],r.shape),u=kw({inputs:{x:r},backend:n,attrs:{reductionIndices:l,keepDims:!1}}),h=ki(u.shape,l),c=Ay({inputs:{x:u},backend:n,attrs:{shape:h}}),p=kk({inputs:{a:r,b:c},backend:n}),d=sk({inputs:{x:p},backend:n}),f=Dw({inputs:{x:d},backend:n,attrs:{axis:l,keepDims:!1}}),m=Ay({inputs:{x:f},backend:n,attrs:{shape:h}}),g=mk({inputs:{a:d,b:m},backend:n});return n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(c),n.disposeIntermediateTensorInfo(p),n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),n.disposeIntermediateTensorInfo(m),g}const Pw={kernelName:vn,backendName:"cpu",kernelFunc:Ww},Vw={kernelName:Oe,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{logits:r}=e,{numSamples:a,seed:i,normalized:o}=s;Jg(r,"multinomial");const l=o?r:Ww({inputs:{logits:r},backend:n,attrs:{dim:-1}}),u=l.shape[0],h=l.shape[1],c=n.data.get(l.dataId).values,p=[u,a],d=U(E(p),"int32");for(let t=0;t<u;++t){const e=t*h,n=new Float32Array(h-1);n[0]=c[e];for(let t=1;t<n.length;++t)n[t]=n[t-1]+c[e+t];const s=zi.alea(i.toString()),r=t*a;for(let t=0;t<a;++t){const e=s();d[r+t]=n.length;for(let s=0;s<n.length;s++)if(e<n[s]){d[r+t]=s;break}}}return o||n.disposeIntermediateTensorInfo(l),n.makeTensorInfo(p,"int32",d)}},Uw={kernelName:Re,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n}=t,{x:s}=e;Jg(s,"neg");const r=n.data.get(s.dataId).values,[a,i]=function(t,e,n){const s=is(-1,n);return hk([],e,s,t,n)}(r,s.shape,s.dtype);return n.makeTensorInfo(i,s.dtype,a)}},Hw=Po,jw={kernelName:We,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{boxes:r,scores:a}=e,{maxOutputSize:i,iouThreshold:o,scoreThreshold:l}=s;Jg(r,"NonMaxSuppression");const u=n.data.get(r.dataId).values,h=n.data.get(a.dataId).values,{selectedIndices:c}=Hw(u,h,i,o,l);return n.makeTensorInfo([c.length],"int32",new Int32Array(c))}},qw=Vo,Gw={kernelName:Pe,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{boxes:r,scores:a}=e,{maxOutputSize:i,iouThreshold:o,scoreThreshold:l,padToMaxOutputSize:u}=s;Jg(r,"NonMaxSuppressionPadded");const h=n.data.get(r.dataId).values,c=n.data.get(a.dataId).values,{selectedIndices:p,validOutputs:d}=qw(h,c,i,o,l,u);return[n.makeTensorInfo([p.length],"int32",new Int32Array(p)),n.makeTensorInfo([],"int32",new Int32Array([d]))]}},Kw=Uo,Jw={kernelName:Ve,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{boxes:r,scores:a}=e,{maxOutputSize:i,iouThreshold:o,scoreThreshold:l,softNmsSigma:u}=s;Jg(r,"NonMaxSuppressionWithScore");const h=n.data.get(r.dataId).values,c=n.data.get(a.dataId).values,p=i,d=o,f=l,m=u,{selectedIndices:g,selectedScores:y}=Kw(h,c,p,d,f,m);return[n.makeTensorInfo([g.length],"int32",new Int32Array(g)),n.makeTensorInfo([y.length],"float32",new Float32Array(y))]}},Zw=iy(((t,e)=>t!==e?1:0)),Yw=Ny(Be,Zw,null,"bool"),Xw={kernelName:Be,backendName:"cpu",kernelFunc:Yw},Qw={kernelName:He,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{indices:r}=e,{depth:a,onValue:i,offValue:o}=s;Jg(r,"oneHot");const l=E(r.shape),u=new Float32Array(l*a);u.fill(o);const h=n.data.get(r.dataId).values;for(let t=0;t<l;++t)h[t]>=0&&h[t]<a&&(u[t*a+h[t]]=i);return n.makeTensorInfo([...r.shape,a],"int32",u)}};function tx(t){const{inputs:e,backend:n}=t,{x:s}=e;if("string"===s.dtype)throw new Error("zerosLike is not supported for string tensors");if("complex64"===s.dtype){const t=by({inputs:{input:s},backend:n}),e=tx({inputs:{x:t},backend:n}),r=vb({inputs:{input:s},backend:n}),a=tx({inputs:{x:r},backend:n}),i=my({inputs:{real:e,imag:a},backend:n});return n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(a),i}return Sk({backend:n,attrs:{shape:s.shape,value:0,dtype:s.dtype}})}const ex={kernelName:Ln,backendName:"cpu",kernelFunc:tx},nx={kernelName:Ue,backendName:"cpu",kernelFunc:function t(e){const{inputs:n,backend:s}=e,{x:r}=n;if("string"===r.dtype)throw new Error("onesLike is not supported for string tensors");if("complex64"===r.dtype){const e=by({inputs:{input:r},backend:s}),n=t({inputs:{x:e},backend:s}),a=vb({inputs:{input:r},backend:s}),i=tx({inputs:{x:a},backend:s}),o=my({inputs:{real:n,imag:i},backend:s});return s.disposeIntermediateTensorInfo(e),s.disposeIntermediateTensorInfo(n),s.disposeIntermediateTensorInfo(a),s.disposeIntermediateTensorInfo(i),o}return Sk({backend:s,attrs:{shape:r.shape,value:1,dtype:r.dtype}})}};function sx(t){const{inputs:e,backend:n,attrs:s}=t,{axis:r}=s;if(1===e.length)return ak({inputs:{input:e[0]},backend:n,attrs:{dim:r}});const a=e[0].shape,i=e[0].dtype;e.forEach((t=>{I(a,t.shape,"All tensors passed to stack must have matching shapes"),v(i===t.dtype,(()=>"All tensors passed to stack must have matching dtypes"))}));const o=[],l=Sb({inputs:e.map((t=>{const e=ak({inputs:{input:t},backend:n,attrs:{dim:r}});return o.push(e),e})),backend:n,attrs:{axis:r}});return o.forEach((t=>n.disposeIntermediateTensorInfo(t))),l}const rx={kernelName:je,backendName:"cpu",kernelFunc:sx},ax={kernelName:qe,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{paddings:a,constantValue:i}=s;Jg(r,"pad");const o=a.map(((t,e)=>t[0]+r.shape[e]+t[1])),l=a.map((t=>t[0])),u=n.data.get(r.dataId).values,h=E(r.shape),c=r.shape.length,p=B(r.shape),d=E(o),f=o.length,m=B(o),g=F(r.dtype,d);0!==i&&g.fill(i);for(let t=0;t<h;t++)g[q(G(t,c,p).map(((t,e)=>t+l[e])),f,m)]=u[t];return{dataId:n.write(g,o,r.dtype),shape:o,dtype:r.dtype}}},ix=iy(((t,e)=>Math.pow(t,e))),ox=Ny(Ge,ix),lx={kernelName:Ge,backendName:"cpu",kernelFunc:ox},ux={kernelName:Je,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{axis:a,keepDims:i}=s;Jg(r,"prod");const o=r.shape.length,l=M(a,r.shape),u=xi(l,o);let h=l,c=r;const p=[];null!=u&&(c=Wy({inputs:{x:r},backend:n,attrs:{perm:u}}),p.push(c),h=vi(h.length,o));const d=n.data.get(c.dataId).values,{outVals:f,outShape:m,outDtype:g}=function(t,e,n,s){const[r,a]=bi(t,s),i=vs(e,"int32"),o=U(E(r),i),l=E(a);for(let t=0;t<o.length;++t){const e=t*l;let s=1;for(let t=0;t<l;++t)s*=n[e+t];o[t]=s}return{outVals:o,outShape:r,outDtype:i}}(c.shape,c.dtype,d,h);let y=m;return i&&(y=ki(m,l)),p.forEach((t=>n.disposeIntermediateTensorInfo(t))),n.makeTensorInfo(y,g,f)}},hx={kernelName:Ze,backendName:"cpu",kernelFunc:function(t){const{backend:e,attrs:n}=t,{start:s,stop:r,dtype:a,step:i}=n,o=function(t,e,n,s){if(t===e||t<e&&n<0||e<t&&n>1)return U(0,s);const r=U(Math.abs(Math.ceil((e-t)/n)),s);e<t&&1===n&&(n=-1),r[0]=t;for(let t=1;t<r.length;t++)r[t]=r[t-1]+n;return r}(s,r,i,a);return e.makeTensorInfo([o.length],a,o)}},cx=Xg(Xe,(t=>1/t)),px={kernelName:Xe,backendName:"cpu",kernelFunc:cx},dx={kernelName:sn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{images:r}=e,{alignCorners:a,halfPixelCenters:i,size:o}=s;Jg(r,"resizeBilinear");const l=B(r.shape),[u,h]=o,[c,p,d,f]=r.shape,m=n.data.get(r.dataId).values,g=new Float32Array(E([c,u,h,f])),y=[a&&u>1?p-1:p,a&&h>1?d-1:d],b=[a&&u>1?u-1:u,a&&h>1?h-1:h];let k=0;const w=y[0]/b[0],x=y[1]/b[1];for(let t=0;t<c;t++)for(let e=0;e<u;e++){let n;n=i?w*(e+.5)-.5:w*e;const s=Math.max(0,Math.floor(n)),r=n-s,a=Math.min(p-1,Math.ceil(n)),o=t*l[0]+s*l[1],u=t*l[0]+a*l[1];for(let t=0;t<h;t++){let e;e=i?x*(t+.5)-.5:x*t;const n=Math.max(0,Math.floor(e)),s=e-n,a=Math.min(d-1,Math.ceil(e)),h=o+n*l[2],c=u+n*l[2],p=o+a*l[2],y=u+a*l[2];for(let t=0;t<f;t++){const e=m[h+t],n=m[c+t],a=e+(m[p+t]-e)*s,i=a+(n+(m[y+t]-n)*s-a)*r;g[k++]=i}}}return n.makeTensorInfo([c,u,h,f],"float32",g)}},fx={kernelName:rn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{images:r,dy:a}=e,{alignCorners:i}=s;Jg([a,r],"resizeBilinearGrad");const o=B(r.shape),[l,u,h,c]=r.shape,[,p,d]=a.shape,f=new Float32Array(l*u*h*c),m=[i&&p>1?u-1:u,i&&d>1?h-1:h],g=[i&&p>1?p-1:p,i&&d>1?d-1:d],y=m[0]/g[0],b=m[1]/g[1],k=n.data.get(a.dataId).values;let w=0;for(let t=0;t<l;t++){const e=t*o[0];for(let t=0;t<p;t++){const n=t*y,s=Math.floor(n),r=Math.min(Math.ceil(n),u-1),a=e+s*o[1],i=e+r*o[1],l=n-s,p=1-l;for(let t=0;t<d;t++){const e=t*b,n=Math.floor(e),s=Math.min(Math.ceil(e),h-1),r=e-n,u=1-r,d=a+n*o[2],m=a+s*o[2],g=i+n*o[2],y=i+s*o[2],x=p*u,N=p*r,v=l*u,I=l*r;for(let t=0;t<c;t++){const e=k[w++];f[d+t]+=e*x,f[m+t]+=e*N,f[g+t]+=e*v,f[y+t]+=e*I}}}}return n.makeTensorInfo([l,h,u,c],"float32",f)}},mx={kernelName:en,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{images:r}=e,{alignCorners:a,halfPixelCenters:i,size:o}=s;Jg(r,"resizeNearestNeighbor");const l=B(r.shape),[u,h]=o,[c,p,d,f]=r.shape,m=n.data.get(r.dataId).values,g=new Float32Array(c*u*h*f),y=[a&&u>1?p-1:p,a&&h>1?d-1:d],b=[a&&u>1?u-1:u,a&&h>1?h-1:h],k=y[0]/b[0],w=y[1]/b[1];let x=0;for(let t=0;t<c;t++){const e=t*l[0];for(let t=0;t<u;t++){const n=i?k*(t+.5):k*t;let s=Math.min(p-1,a?Math.round(n):Math.floor(n));i&&(s=Math.max(0,s));const r=e+s*l[1];for(let t=0;t<h;t++){const e=i?w*(t+.5):w*t;let n=Math.min(d-1,a?Math.round(e):Math.floor(e));i&&(n=Math.max(0,n));const s=r+n*l[2];for(let t=0;t<f;t++){const e=m[s+t];g[x++]=e}}}}return n.makeTensorInfo([c,u,h,f],r.dtype,g)}},gx={kernelName:nn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{images:r,dy:a}=e,{alignCorners:i}=s;Jg([a,r],"resizeNearestNeighborGrad");const o=B(r.shape),l=B(a.shape),[u,h,c,p]=r.shape,[,d,f]=a.shape,m=new Float32Array(u*h*c*p),g=n.data.get(a.dataId).values,y=[i&&d>1?h-1:h,i&&f>1?c-1:c],b=[i&&d>1?d-1:d,i&&f>1?f-1:f],k=y[0]/b[0],w=y[1]/b[1],x=1/k,N=1/w,v=2*Math.ceil(x)+2,I=2*Math.ceil(N)+2;for(let t=0;t<u;t++){const e=t*o[0];for(let t=0;t<h;t++){const n=e+t*o[1],s=Math.floor(t*x),r=Math.floor(s-v/2);for(let s=0;s<c;s++){const a=n+s*o[2],u=Math.floor(s*N),y=Math.floor(u-I/2);for(let n=0;n<p;n++){let o=0;for(let a=0;a<v;a++){const u=a+r;if(u<0||u>=d)continue;const p=e+u*l[1],m=u*k;if(t===Math.min(h-1,i?Math.round(m):Math.floor(m)))for(let t=0;t<I;t++){const e=t+y;if(e<0||e>=f)continue;const r=p+e*l[2],a=e*w;s===Math.min(c-1,i?Math.round(a):Math.floor(a))&&(o+=g[r+n])}}m[a+n]=o}}}}return n.makeTensorInfo(r.shape,r.dtype,m)}},yx={kernelName:on,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{dims:a}=s;Jg(r,"reverse");const i=r.shape.length,o=M(a,r.shape);if(0===i)return ny({inputs:{x:r},backend:n});const l=new cs(r.shape,r.dtype),u=n.bufferSync(r);for(let t=0;t<l.size;t++){const e=l.indexToLoc(t),n=e.slice();o.forEach((t=>n[t]=r.shape[t]-1-n[t])),l.set(u.get(...n),...e)}return n.makeTensorInfo(l.shape,l.dtype,l.values)}},bx={kernelName:Wn,backendName:"cpu",kernelFunc:({inputs:t,attrs:e,backend:n})=>{const{image:s}=t,{radians:r,fillValue:a,center:i}=e,o=n,l=F(s.dtype,E(s.shape)),[u,h,c,p]=s.shape,[d,f]=function(t,e,n){return[n*("number"==typeof t?t:t[0]),e*("number"==typeof t?t:t[1])]}(i,h,c),m=Math.sin(r),g=Math.cos(r),y=o.data.get(s.dataId).values;for(let t=0;t<u;t++){const e=t*c*h*p;for(let t=0;t<h;t++){const n=t*(c*p);for(let s=0;s<c;s++){const r=s*p;for(let i=0;i<p;i++){const o=[u,t,s,i],b=o[2],k=o[1];let w=(b-d)*g-(k-f)*m,x=(b-d)*m+(k-f)*g;w=Math.round(w+d),x=Math.round(x+f);let N=a;"number"!=typeof a&&(N=3===i?255:a[i]),w>=0&&w<c&&x>=0&&x<h&&(N=y[e+x*(c*p)+w*p+i]),l[e+n+r+i]=N}}}}return{dataId:o.write(l,s.shape,s.dtype),shape:s.shape,dtype:s.dtype}}},kx=Xg(ln,(t=>{const e=Math.floor(t);return t-e<.5?Math.floor(t):t-e>.5?Math.ceil(t):e%2==0?e:e+1})),wx={kernelName:ln,backendName:"cpu",kernelFunc:kx},xx=gb((t=>1/Math.sqrt(t))),Nx=Qg(un,xx),vx={kernelName:un,backendName:"cpu",kernelFunc:Nx};function Ix(t,e,n,s,r,a,i,o,l,u){const h=[s/r,r],c=t.values,p=e.values;if(0===s)return vr(n,e.dtype);const d=vr(h,e.dtype);d.values.fill(l);for(let t=0;t<a;t++){const a=[];let l=0;for(let e=0;e<i;e++){const n=c[t*i+e];a.push(n),l+=n*o[e]}if(l<0||l>=s/r)throw new Error(`Invalid indices: ${a} does not index into ${n}`);for(let n=0;n<r;n++)u?d.values[l*r+n]+=p[t*r+n]:d.values[l*r+n]=0===e.rank?p[0]:p[t*r+n]}return d}const Sx={kernelName:hn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{indices:r,updates:a}=e,{shape:i}=s,{sliceRank:o,numUpdates:l,sliceSize:u,strides:h,outputSize:c}=Dl(0,r,i),p=Ix(n.bufferSync(r),n.bufferSync(a),i,c,u,l,o,h,0,!0);return n.makeTensorInfo(i,p.dtype,p.values)}},Tx={kernelName:cn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n}=t,{condition:s,t:r,e:a}=e;Jg([s,r,a],"select");const i=s.shape.length,o=n.data.get(s.dataId).values,l=n.data.get(r.dataId).values,u=n.data.get(a.dataId).values,h=vs(r.dtype,a.dtype),c=U(E(r.shape),h);let p=0;const d=0===i||i>1||1===r.shape.length?1:E(r.shape.slice(1));for(let t=0;t<o.length;t++)for(let e=0;e<d;e++)1===o[t]?c[p++]=l[t]:c[p++]=u[t];return n.makeTensorInfo(r.shape,h,c)}},Ex=Xg(pn,(t=>t>=0?1.0507009873554805*t:1.7580993408473768*(Math.exp(t)-1))),Ax={kernelName:pn,backendName:"cpu",kernelFunc:Ex},Dx=Xg(yn,(t=>1/(1+Math.exp(-t)))),$x={kernelName:yn,backendName:"cpu",kernelFunc:Dx},Mx=Xg(gn,(t=>t<0?-1:t>0?1:0)),Fx={kernelName:gn,backendName:"cpu",kernelFunc:Mx},_x=Xg(fn,(t=>Math.sin(t))),zx={kernelName:fn,backendName:"cpu",kernelFunc:_x},Cx=Xg(mn,(t=>Math.sinh(t))),Ox={kernelName:mn,backendName:"cpu",kernelFunc:Cx},Lx=Math.log(1.1920928955078125e-7)+2,Rx=Xg(bn,(t=>{const e=t>-Lx,n=t<Lx,s=Math.exp(t);let r;return r=n?s:e?t:Math.log(1+s),r})),Bx={kernelName:bn,backendName:"cpu",kernelFunc:Rx},Wx={kernelName:xn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{blockShape:a,paddings:i}=s;Jg([r],"spaceToBatchND");const o=E(a),l=[[0,0]];l.push(...i);for(let t=1+a.length;t<r.shape.length;++t)l.push([0,0]);const u=ax.kernelFunc({inputs:{x:r},backend:n,attrs:{paddings:l,constantValue:0}}),h=Tl(u.shape,a,o,!1),c=El(h.length,a.length,!1),p=Al(u.shape,a,o,!1),d=Ay({inputs:{x:u},backend:n,attrs:{shape:h}}),f=Wy({inputs:{x:d},backend:n,attrs:{perm:c}}),m=Ay({inputs:{x:f},backend:n,attrs:{shape:p}});return n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(f),m}},Px={kernelName:En,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{sparseIndices:r,sparseValues:a,defaultValue:i}=e,{outputShape:o}=s,{sliceRank:l,numUpdates:u,sliceSize:h,strides:c,outputSize:p}=Dl(0,r,o),d=Ix(n.bufferSync(r),n.bufferSync(a),o,p,h,u,l,c,n.data.get(i.dataId).values[0],!1);return n.makeTensorInfo(o,d.dtype,d.values)}},Vx={kernelName:Nn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{numOrSizeSplits:a,axis:i}=s,o=M(i,r.shape)[0],l=function(t,e,n=0){let s=[];if("number"==typeof e)v(t.shape[n]%e==0,(()=>"Number of splits must evenly divide the axis.")),s=new Array(e).fill(t.shape[n]/e);else{v(e.reduce(((t,e)=>(-1===e&&(t+=1),t)),0)<=1,(()=>"There should be only one negative value in split array."));const r=e.indexOf(-1);if(-1!==r){const s=e.reduce(((t,e)=>e>0?t+e:t));e[r]=t.shape[n]-s}v(t.shape[n]===e.reduce(((t,e)=>t+e)),(()=>"The sum of sizes must match the size of the axis dimension.")),s=e}return s}(r,a,o),u=new Array(r.shape.length).fill(0),h=r.shape.slice();return l.map((t=>{const e=[...h];e[o]=t;const s=cb({inputs:{x:r},backend:n,attrs:{begin:u,size:e}});return u[o]+=t,s}))}},Ux=Xg(kn,(t=>Math.sqrt(t))),Hx={kernelName:kn,backendName:"cpu",kernelFunc:Ux},jx={kernelName:Sn,backendName:"cpu",kernelFunc:({inputs:t,backend:e})=>{const{x:n}=t,s=e;Jg(n,"square");const r=s.data.get(n.dataId).values,a=new Float32Array(r.length);for(let t=0;t<r.length;++t){const e=r[t];a[t]=e*e}return{dataId:s.write(a,n.shape,n.dtype),shape:n.shape,dtype:n.dtype}}},qx=iy(((t,e)=>{const n=t-e;return n*n})),Gx=Ny(In,qx),Kx={kernelName:In,backendName:"cpu",kernelFunc:Gx},Jx=Xg(Rn,((t,e)=>{const n=e;return isNaN(t)?NaN:t>0?1:n.alpha})),Zx={kernelName:Rn,backendName:"cpu",kernelFunc:Jx},Yx={kernelName:An,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{begin:a,end:i,strides:o,beginMask:l,endMask:u,ellipsisMask:h,newAxisMask:c,shrinkAxisMask:p}=s;Jg(r,"stridedSlice");const{nonStrided:d,$begin:f,$strides:m,size:g,newShape:y,outShape:b}=jr(r.shape,a,i,o,l,u,h,c,p),k=Ay({inputs:{x:r},backend:n,attrs:{shape:y}});let w;if(d){const t=cb({inputs:{x:k},backend:n,attrs:{begin:f,size:g}});w=Ay({inputs:{x:t},backend:n,attrs:{shape:b}}),n.disposeIntermediateTensorInfo(t)}else if(b.some((t=>0===t)))w=n.makeTensorInfo(b,r.dtype,[]);else{const t=function(t,e,n,s){const r=vr(t,e.dtype);for(let t=0;t<r.size;t++){const a=r.indexToLoc(t),i=new Array(a.length);for(let t=0;t<i.length;t++)i[t]=a[t]*n[t]+s[t];r.set(e.get(...i),...a)}return r}(b,n.bufferSync(k),m,f);w=n.makeTensorInfo(t.shape,t.dtype,t.values)}const x=Ay({inputs:{x:w},backend:n,attrs:{shape:b}});return n.disposeIntermediateTensorInfo(k),n.disposeIntermediateTensorInfo(w),x}},Xx=Xg(Dn,(t=>Math.tan(t))),Qx={kernelName:Dn,backendName:"cpu",kernelFunc:Xx},tN=Xg($n,(t=>Math.tanh(t))),eN=[Fy,_y,Cy,Ly,Ey,Ry,Vy,Uy,Hy,jy,Gy,Jy,Yy,tb,nb,ib,ob,lb,ub,My,hb,db,mb,xy,kb,xb,gy,Nb,Tb,Db,$b,Ab,Fb,_b,Mb,Cb,Lb,Rb,Bb,Wb,Pb,Ub,Hb,jb,qb,Gb,Jb,Kb,gk,ey,Zb,Qb,ek,rk,ik,uk,Ik,Tk,Ek,$k,_k,zk,Ck,Ok,Lk,Wk,Uk,sy,Hk,Ib,qk,Kk,Zk,ay,Qk,nw,sw,iw,lw,cw,dw,gw,yw,bw,vw,Iw,Sw,Tw,Ew,Aw,ww,Mw,Fw,Cw,Ow,Bw,Vw,dk,Uw,jw,Gw,Jw,Xw,Qw,nx,rx,ax,lx,uy,ux,hx,ky,px,cy,dy,Dy,dx,fx,mx,gx,yx,bx,wx,vx,Sx,Tx,Ax,$x,Fx,zx,Ox,pb,Pw,Bx,Wx,Px,Vx,Hx,jx,Kx,Zx,Yx,wk,$w,Qx,{kernelName:$n,backendName:"cpu",kernelFunc:tN},{kernelName:Mn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{reps:a}=s;Jg(r,"tile");const i=function(t,e){const n=new Array(t.rank);for(let s=0;s<n.length;s++)n[s]=t.shape[s]*e[s];const s=vr(n,t.dtype);for(let e=0;e<s.values.length;++e){const n=s.indexToLoc(e),r=new Array(t.rank);for(let e=0;e<r.length;e++)r[e]=n[e]%t.shape[e];const a=t.locToIndex(r);s.values[e]=t.values[a]}return s}(n.bufferSync(r),a);return n.makeTensorInfo(i.shape,i.dtype,i.values)}},{kernelName:Fn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r}=e,{k:a,sorted:i}=s;Jg(r,"topk");const o=n.data.get(r.dataId).values,[l,u]=function(t,e,n,s,r){const a=e[e.length-1],[i,o]=[t.length/a,a],l=F(n,i*s),u=F("int32",i*s);for(let e=0;e<i;e++){const n=e*o,r=t.subarray(n,n+o),a=[];for(let t=0;t<r.length;t++)a.push({value:r[t],index:t});a.sort(((t,e)=>e.value-t.value));const i=e*s,h=l.subarray(i,i+s),c=u.subarray(i,i+s);for(let t=0;t<s;t++)h[t]=a[t].value,c[t]=a[t].index}const h=e.slice();return h[h.length-1]=s,[vr(h,n,l),vr(h,"int32",u)]}(o,r.shape,r.dtype,a);return[n.makeTensorInfo(l.shape,l.dtype,l.values),n.makeTensorInfo(u.shape,u.dtype,u.values)]}},Py,{kernelName:zn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,attrs:n,backend:s}=t,{axis:r}=n,{x:a}=e;Jg(a,"unique");const i=s.data.get(a.dataId).values,{outputValues:o,outputShape:l,indices:u}=function(t,e,n,s){const r=M(e,n)[0],a=[1,n[0],1];for(let t=0;t<r;t++)a[0]*=n[t];a[1]=n[r];for(let t=r+1;t<n.length;t++)a[2]*=n[t];const i={},o=new Int32Array(n[r]),l=new cs(a,s,t),u=[],h=1===a[0]&&1===a[2];for(let e=0;e<n[r];e++){let n;if(h)n=t[e].toString();else{const t=[];for(let n=0;n<a[0];n++)for(let s=0;s<a[2];s++)t.push(l.get(n,e,s));n=t.join(",")}if(void 0!==i[n])o[e]=i[n];else{const t=Object.keys(i).length;i[n]=t,o[e]=t,u.push(e)}}const c=a.slice();c[1]=Object.keys(i).length;const p=new cs(c,s);u.forEach(((t,e)=>{for(let n=0;n<a[0];n++)for(let s=0;s<a[2];s++)p.set(l.get(n,t,s),n,e,s)}));const d=n.slice();return d[r]=c[1],{outputValues:p.values,outputShape:d,indices:o}}(i,r,a.shape,a.dtype);return[s.makeTensorInfo(l,a.dtype,o),s.makeTensorInfo([u.length],"int32",u)]}},{kernelName:Cn,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{value:r}=e;let{axis:a}=s;a<0&&(a+=r.shape.length);const i=r.shape.length,o=r.shape[a],l=new Array(i-1);let u=0;for(let t=0;t<i;t++)t!==a&&(l[u++]=r.shape[t]);const h=new Array(i).fill(0),c=r.shape.slice();c[a]=1;const p=new Array(o);for(let t=0;t<p.length;t++){h[a]=t;const e=cb({inputs:{x:r},backend:n,attrs:{begin:h,size:c}});p[t]=Ay({inputs:{x:e},backend:n,attrs:{shape:l}}),n.disposeIntermediateTensorInfo(e)}return p}},{kernelName:On,backendName:"cpu",kernelFunc:function(t){const{inputs:e,backend:n,attrs:s}=t,{x:r,segmentIds:a}=e,{numSegments:i}=s;Jg(r,"unsortedSegmentSum");const o=[],l=[],u=r.shape.length-a.shape.length;let h=a;for(let t=0;t<u;++t){const e=ak({inputs:{input:h},backend:n,attrs:{dim:t+1}});h=e,l.push(e)}for(let t=0;t<i;++t){const e=is(t,"int32"),s=n.makeTensorInfo([],"int32",e),a=Xb({inputs:{a:s,b:h},backend:n}),i=wy({inputs:{x:a},backend:n,attrs:{dtype:"float32"}}),u=pk({inputs:{a:i,b:r},backend:n}),c=Dw({inputs:{x:u},backend:n,attrs:{axis:0,keepDims:!1}});o.push(c),l.push(s),l.push(a),l.push(i),l.push(u),l.push(c)}const c=sx({inputs:o,backend:n,attrs:{axis:0}});return l.forEach((t=>n.disposeIntermediateTensorInfo(t))),c}},ex];for(const t of eN)Jn(t);var nN,sN;!function(t){t[t.DT_INVALID=0]="DT_INVALID",t[t.DT_FLOAT=1]="DT_FLOAT",t[t.DT_DOUBLE=2]="DT_DOUBLE",t[t.DT_INT32=3]="DT_INT32",t[t.DT_UINT8=4]="DT_UINT8",t[t.DT_INT16=5]="DT_INT16",t[t.DT_INT8=6]="DT_INT8",t[t.DT_STRING=7]="DT_STRING",t[t.DT_COMPLEX64=8]="DT_COMPLEX64",t[t.DT_INT64=9]="DT_INT64",t[t.DT_BOOL=10]="DT_BOOL",t[t.DT_QINT8=11]="DT_QINT8",t[t.DT_QUINT8=12]="DT_QUINT8",t[t.DT_QINT32=13]="DT_QINT32",t[t.DT_BFLOAT16=14]="DT_BFLOAT16",t[t.DT_FLOAT_REF=101]="DT_FLOAT_REF",t[t.DT_DOUBLE_REF=102]="DT_DOUBLE_REF",t[t.DT_INT32_REF=103]="DT_INT32_REF",t[t.DT_UINT8_REF=104]="DT_UINT8_REF",t[t.DT_INT16_REF=105]="DT_INT16_REF",t[t.DT_INT8_REF=106]="DT_INT8_REF",t[t.DT_STRING_REF=107]="DT_STRING_REF",t[t.DT_COMPLEX64_REF=108]="DT_COMPLEX64_REF",t[t.DT_INT64_REF=109]="DT_INT64_REF",t[t.DT_BOOL_REF=110]="DT_BOOL_REF",t[t.DT_QINT8_REF=111]="DT_QINT8_REF",t[t.DT_QUINT8_REF=112]="DT_QUINT8_REF",t[t.DT_QINT32_REF=113]="DT_QINT32_REF",t[t.DT_BFLOAT16_REF=114]="DT_BFLOAT16_REF"}(nN||(nN={})),function(t){let e;!function(t){t[t.LEGACY=0]="LEGACY",t[t.V1=1]="V1",t[t.V2=2]="V2"}(e=t.CheckpointFormatVersion||(t.CheckpointFormatVersion={}))}(sN||(sN={}));const rN={};function aN(t){return rN[t]}function iN(t,e,n,s,r){const a=e.inputParams[t];if(a&&void 0!==a.inputIndexStart){const t=a.inputIndexStart,i=0===a.inputIndexEnd?void 0:void 0===a.inputIndexEnd?t+1:a.inputIndexEnd;if("tensor"===a.type)return oN(e.inputNames[a.inputIndexStart],n,s,r);if("tensors"===a.type)return e.inputNames.slice(t,i).map((t=>oN(t,n,s,r)));const o=oN(e.inputNames.slice(t)[0],n,s,r),l=o.dataSync();return"number"===a.type?l[0]:P(o.shape,l)}const i=e.attrParams[t];return i&&i.value}function oN(t,e,n,s){const[r,a]=hN(t);if(null!=s){const t=s.getHashTableHandleByName(r);if(null!=t)return t}const i=n.currentContextIds.find((t=>!!e[uN(r,t)]));return void 0!==i?e[uN(r,i)][a]:void 0}function lN(t,e){const[n,s]=hN(t);return[uN(n,e&&e.currentContextId),s]}function uN(t,e){return e?`${t}-${e}`:t}function hN(t){const e=t.split(":");return 1===e.length?[t,0]:[e[0],Number(e[e.length-1])]}function cN(t,e,n){let s=iN("pad",t,e,n);if("explicit"===s){s=iN("explicitPaddings",t,e,n);const r=[[0,0],[0,0],[0,0],[0,0]];for(let t=0;t<4;t++)r[t][0]=s[2*t],r[t][1]=s[2*t+1];return r}return s}function pN(t){return t.kept?t:Sr(t)}const dN=[{tfOpName:"Add",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AddV2",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AddN",category:"arithmetic",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"BiasAdd",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"Sub",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"RealDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Div",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"DivNoNan",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"FloorDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Mul",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Maximum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Minimum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Pow",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SquaredDifference",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Mod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"FloorMod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],fN=[{tfOpName:"Abs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Acos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Asin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atan2",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Ceil",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ClipByValue",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"clipValueMin",type:"number"},{start:2,name:"clipValueMax",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Complex",category:"basic_math",inputs:[{start:0,name:"real",type:"tensor"},{start:1,name:"imag",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ComplexAbs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Cos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Cosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Elu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Exp",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Floor",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Log",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Imag",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:!0}]},{tfOpName:"Neg",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Real",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:!0}]},{tfOpName:"Prelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"alpha",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Relu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Relu6",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Selu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sigmoid",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Rsqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Square",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Tan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Tanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sign",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Round",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Expm1",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Log1p",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Reciprocal",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Softplus",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Asinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Acosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Erf",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Prod",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axes",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool",notSupported:!0},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LeakyRelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"alpha",name:"alpha",type:"number",defaultValue:.2},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],mN=[{tfOpName:"EmptyTensorList",category:"control",inputs:[{start:0,name:"elementShape",type:"shape"},{start:1,name:"maxNumElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"LoopCond",category:"control",inputs:[{start:0,name:"pred",type:"tensor"}]},{tfOpName:"Switch",category:"control",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"pred",type:"tensor"}]},{tfOpName:"Merge",category:"control",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"Enter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"frame_name",name:"frameName",type:"string"},{tfName:"is_constant",name:"isConstant",type:"bool"}]},{tfOpName:"Exit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"NextIteration",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayV3",category:"control",inputs:[{start:0,name:"size",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"dynamic_size",name:"dynamicSize",type:"bool"},{tfName:"clear_after_read",name:"clearAfterRead",type:"bool"},{tfName:"identical_element_shapes",name:"identicalElementShapes",type:"bool"},{tfName:"tensor_array_name",name:"name",type:"string"}]},{tfOpName:"TensorArrayWriteV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayReadV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayGatherV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"}]},{tfOpName:"TensorArrayScatterV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArrayConcatV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape_except0",name:"elementShapeExcept0",type:"shape",notSupported:!0}]},{tfOpName:"TensorArraySplitV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"tensor",type:"tensor"},{start:2,name:"lengths",type:"number[]"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArraySizeV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}]},{tfOpName:"TensorArrayCloseV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"}]},{tfOpName:"StatelessIf",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"If",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"StatelessWhile",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"While",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"TensorListScatter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListScatterV2",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"},{start:3,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGather",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListSetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListReserve",category:"control",inputs:[{start:0,name:"elementShape",type:"shape"},{start:1,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListFromTensor",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListStack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"},{tfName:"num_elements",name:"numElements",type:"dtype"}]},{tfOpName:"TensorListSplit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"},{start:2,name:"lengths",type:"number[]"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListConcat",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"}],attrs:[{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPopBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPushBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]}],gN=[{tfOpName:"AvgPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[],notSupported:!0},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPoolWithArgmax",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"include_batch_in_index",name:"includeBatchInIndex",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AvgPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Conv1D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"stride",name:"stride",type:"number"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NWC"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"dilation",name:"dilation",type:"number",defaultValue:1}]},{tfOpName:"Conv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"useCudnnOnGpu",name:"useCudnnOnGpu",type:"bool"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"_FusedConv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"use_cudnn_on_gpu",name:"useCudnnOnGpu",type:"bool",defaultValue:!0},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4},{tfName:"leakyrelu_alpha",name:"leakyreluAlpha",type:"number"}]},{tfOpName:"Conv2DBackpropInput",category:"convolution",inputs:[{start:2,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:0,name:"outputShape",type:"number[]"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]",notSupported:!0}]},{tfOpName:"DepthwiseConv2d",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"DepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"FusedDepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]}]},{tfOpName:"Conv3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"Dilation2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"rates",name:"dilations",type:"number[]"},{tfName:"padding",name:"pad",type:"string"}]}],yN=[{tfOpName:"Fill",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"},{start:1,name:"value",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"LinSpace",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"num",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"OneHot",category:"creation",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"depth",type:"number"},{start:2,name:"onValue",type:"number",defaultValue:1},{start:3,name:"offValue",type:"number",defaultValue:0}],attrs:[{tfName:"axis",name:"axis",type:"number",notSupported:!0},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Ones",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"OnesLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"RandomUniform",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"minval",name:"minval",type:"number",defaultValue:0},{tfName:"maxval",name:"maxval",type:"number",defaultValue:1},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"seed",name:"seed",type:"number",defaultValue:0},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"Range",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"step",type:"number",defaultValue:0}],attrs:[{tfName:"Tidx",name:"dtype",type:"dtype"}]},{tfOpName:"TruncatedNormal",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"means",name:"mean",type:"number",defaultValue:0},{tfName:"stddev",name:"stdDev",type:"number",defaultValue:1},{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"Zeros",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"ZerosLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"Multinomial",category:"creation",inputs:[{start:0,name:"logits",type:"tensor"},{start:1,name:"numSamples",type:"number"}],attrs:[{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number"},{tfName:"T",name:"dtype",type:"dtype"},{tfName:"output_dtype",name:"output_dtype",type:"dtype"}]}],bN=[{tfOpName:"NonMaxSuppressionV2",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV3",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV4",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"T_threshold",name:"threshold",type:"dtype",notSupported:!0},{tfName:"pad_to_max_output_size",name:"padToMaxOutputSize",type:"bool"}]},{tfOpName:"NonMaxSuppressionV5",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"},{start:5,name:"softNmsSigma",type:"number"}]},{tfOpName:"Where",category:"dynamic",inputs:[{start:0,name:"condition",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ListDiff",category:"dynamic",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],kN=[{tfOpName:"TopKV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"k",type:"number"}],attrs:[{tfName:"sorted",name:"sorted",type:"bool"}]},{tfOpName:"Unique",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"UniqueV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]}],wN=[{tfOpName:"PlaceholderWithDefault",category:"graph",inputs:[{start:0,name:"default",type:"tensor"}],attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Placeholder",category:"graph",attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Const",category:"graph"},{tfOpName:"Identity",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IdentityN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Snapshot",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Rank",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Size",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Shape",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"ShapeN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Print",category:"graph",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"data",type:"tensors"}],attrs:[{tfName:"message",name:"message",type:"string"},{tfName:"first_n",name:"firstN",type:"number",notSupported:!0},{tfName:"summarize",name:"summarize",type:"number",defaultValue:3}]},{tfOpName:"NoOp",category:"graph",inputs:[]},{tfOpName:"StopGradient",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"FakeQuantWithMinMaxVars",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"min",name:"min",type:"number"},{tfName:"max",name:"max",type:"number"}]}],xN=[{tfOpName:"HashTable",category:"hash_table",inputs:[],attrs:[{tfName:"shared_name",name:"sharedName",type:"string"},{tfName:"use_node_name_sharing",name:"useNodeNameSharing",type:"bool"},{tfName:"key_dtype",name:"keyDType",type:"dtype"},{tfName:"value_dtype",name:"valueDType",type:"dtype"}]},{tfOpName:"HashTableV2",category:"hash_table",inputs:[],attrs:[{tfName:"shared_name",name:"sharedName",type:"string"},{tfName:"use_node_name_sharing",name:"useNodeNameSharing",type:"bool"},{tfName:"key_dtype",name:"keyDType",type:"dtype"},{tfName:"value_dtype",name:"valueDType",type:"dtype"}]},{tfOpName:"LookupTableImport",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableImportV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableFind",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableFindV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]}],NN=[{tfOpName:"ResizeBilinear",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"half_pixel_centers",name:"halfPixelCenters",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ResizeNearestNeighbor",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"half_pixel_centers",name:"halfPixelCenters",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"CropAndResize",category:"image",inputs:[{start:0,name:"image",type:"tensor"},{start:1,name:"boxes",type:"tensor"},{start:2,name:"boxInd",type:"tensor"},{start:3,name:"cropSize",type:"number[]"}],attrs:[{tfName:"method",name:"method",type:"string"},{tfName:"extrapolation_value",name:"extrapolationValue",type:"number"}]}],vN=[{tfOpName:"Equal",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"NotEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Greater",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"GreaterEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Less",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LessEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalAnd",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalNot",category:"logical",inputs:[{start:0,name:"a",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalOr",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Select",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SelectV2",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],IN=[{tfOpName:"_FusedMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4},{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"BatchMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"BatchMatMulV2",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Transpose",category:"matrices",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"perm",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}],SN=[{tfOpName:"FusedBatchNorm",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"FusedBatchNormV2",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"FusedBatchNormV3",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"LRN",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"depth_radius",name:"radius",type:"number",defaultValue:5},{tfName:"bias",name:"bias",type:"number",defaultValue:1},{tfName:"alpha",name:"alpha",type:"number",defaultValue:1},{tfName:"beta",name:"beta",type:"number",defaultValue:.5}]},{tfOpName:"Softmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"LogSoftmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"SparseToDense",category:"normalization",inputs:[{start:0,name:"sparseIndices",type:"tensor"},{start:1,name:"outputShape",type:"number[]"},{start:2,name:"sparseValues",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",defaultValue:!0,notSupported:!0}]}],TN=[{tfOpName:"Bincount",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"size",type:"number"},{start:2,name:"weights",type:"tensor"}]},{tfOpName:"DenseBincount",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"size",type:"number"},{start:2,name:"weights",type:"tensor"}],attrs:[{tfName:"binary_output",name:"binaryOutput",type:"bool"}]},{tfOpName:"Max",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Mean",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Min",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Sum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"All",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Any",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"ArgMax",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"ArgMin",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"Prod",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Cumsum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}],attrs:[{tfName:"exclusive",name:"exclusive",type:"bool"},{tfName:"reverse",name:"reverse",type:"bool"}]}],EN=[{tfOpName:"ConcatV2",category:"slice_join",inputs:[{start:0,end:-1,name:"tensors",type:"tensors"},{start:-1,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"Concat",category:"slice_join",inputs:[{start:1,end:0,name:"tensors",type:"tensors"},{start:0,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"GatherV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"axis",type:"number",defaultValue:0}],attrs:[{tfName:"batch_dims",name:"batchDims",type:"number",defaultValue:0}]},{tfOpName:"Gather",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",notSupported:!0}]},{tfOpName:"Reverse",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"dims",type:"bool[]"}]},{tfOpName:"ReverseV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}]},{tfOpName:"Slice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"size",type:"number[]"}]},{tfOpName:"StridedSlice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"end",type:"number[]"},{start:3,name:"strides",type:"number[]"}],attrs:[{tfName:"begin_mask",name:"beginMask",type:"number",defaultValue:0},{tfName:"end_mask",name:"endMask",type:"number",defaultValue:0},{tfName:"new_axis_mask",name:"newAxisMask",type:"number",defaultValue:0},{tfName:"ellipsis_mask",name:"ellipsisMask",type:"number",defaultValue:0},{tfName:"shrink_axis_mask",name:"shrinkAxisMask",type:"number",defaultValue:0}]},{tfOpName:"Pack",category:"slice_join",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0}]},{tfOpName:"Unpack",category:"slice_join",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0},{tfName:"num",name:"num",type:"number",defaultValue:0,notSupported:!0}]},{tfOpName:"Tile",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"reps",type:"number[]"}]},{tfOpName:"Split",category:"slice_join",inputs:[{start:0,name:"axis",type:"number",defaultValue:0},{start:1,name:"x",type:"tensor"}],attrs:[{tfName:"num_split",name:"numOrSizeSplits",type:"number",defaultValue:1}]},{tfOpName:"SplitV",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"numOrSizeSplits",type:"number[]"},{start:2,name:"axis",type:"number",defaultValue:0}]},{tfOpName:"ScatterNd",category:"slice_join",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"values",type:"tensor"},{start:2,name:"shape",type:"number[]"}]},{tfOpName:"GatherNd",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}]},{tfOpName:"SparseToDense",category:"slice_join",inputs:[{start:0,name:"sparseIndices",type:"tensor"},{start:1,name:"outputShape",type:"number[]"},{start:2,name:"sparseValues",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",defaultValue:!1,notSupported:!0}]}],AN=[{tfOpName:"FFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"RFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:!0}]},{tfOpName:"IRFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:!0}]}],DN=[{tfOpName:"Cast",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"SrcT",name:"sdtype",type:"dtype",notSupported:!0},{tfName:"DstT",name:"dtype",type:"dtype"}]},{tfOpName:"ExpandDims",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"MirrorPad",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"}],attrs:[{tfName:"mode",name:"mode",type:"string"}]},{tfOpName:"Pad",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"}],attrs:[{tfName:"constant_value",name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"PadV2",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"},{start:2,name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"Reshape",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}]},{tfOpName:"Squeeze",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"axis",tfDeprecatedName:"squeeze_dims",name:"axis",type:"number[]"}]},{tfOpName:"SpaceToBatchND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"paddings",type:"number[]"}]},{tfOpName:"BatchToSpaceND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"crops",type:"number[]"}]},{tfOpName:"DepthToSpace",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"block_size",name:"blockSize",type:"number"},{tfName:"data_format",name:"dataFormat",type:"string"}]},{tfOpName:"BroadcastTo",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}],attrs:[]}];class $N{static get Instance(){return this._instance||(this._instance=new this)}constructor(){const n=[].concat(...[t,e,s,r,a,i,o,c,h,l,p,d,f,m,g,y,u].map((t=>t.json)));this.opMappers=n.reduce(((t,e)=>(t[e.tfOpName]=e,t)),{})}transformGraph(t,e={}){const n=t.node,s=[],r=[],a=[],i=n.reduce(((t,e)=>(t[e.name]=this.mapNode(e),e.op.startsWith("Placeholder")?s.push(t[e.name]):"Const"===e.op?r.push(t[e.name]):null!=e.input&&0!==e.input.length||a.push(t[e.name]),t)),{});let o=[];const l=[];let u={},h={};null!=e&&(u=this.mapSignatureEntries(e.inputs),h=this.mapSignatureEntries(e.outputs));const c=Object.keys(i);c.forEach((t=>{const e=i[t];e.inputNames.forEach((t=>{const[n]=lN(t);e.inputs.push(i[n]),i[n].children.push(e)}))})),0===Object.keys(h).length?c.forEach((t=>{const e=i[t];0===e.children.length&&l.push(e)})):Object.keys(h).forEach((t=>{const[e]=lN(t),n=i[e];null!=n&&(n.signatureKey=h[t],l.push(n))})),Object.keys(u).length>0?Object.keys(u).forEach((t=>{const[e]=lN(t),n=i[e];n&&(n.signatureKey=u[t],o.push(n))})):o=s;let p={};null!=t.library&&null!=t.library.function&&(p=t.library.function.reduce(((t,e)=>(t[e.signature.name]=this.mapFunction(e),t)),{}));const d={nodes:i,inputs:o,outputs:l,weights:r,placeholders:s,signature:e,functions:p};return a.length>0&&(d.initNodes=a),d}mapSignatureEntries(t){return Object.keys(t||{}).reduce(((e,n)=>(e[t[n].name]=n,e)),{})}mapNode(t){const e=aN(t.op)||this.opMappers[t.op]||{};null==t.attr&&(t.attr={});const n={name:t.name,op:t.op,category:e.category,inputNames:(t.input||[]).map((t=>t.startsWith("^")?t.substr(1):t)),inputs:[],children:[],inputParams:{},attrParams:{},rawAttrs:t.attr};return null!=e.inputs&&(n.inputParams=e.inputs.reduce(((t,e)=>(t[e.name]={type:e.type,inputIndexStart:e.start,inputIndexEnd:e.end},t)),{})),null!=e.attrs&&(n.attrParams=e.attrs.reduce(((e,n)=>{const s=n.type;let r;switch(n.type){case"string":r=FN(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=FN(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"string[]":r=VN(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=VN(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"number":r=zN(t.attr,n.tfName,n.defaultValue||0),void 0===r&&n.tfDeprecatedName&&(r=zN(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"number[]":r=PN(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=PN(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"bool":r=_N(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=_N(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"bool[]":r=HN(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=HN(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"shape":r=WN(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=WN(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"shape[]":r=UN(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=UN(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"dtype":r=LN(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=LN(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"dtype[]":r=RN(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=RN(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"func":r=ON(t.attr,n.tfName,n.defaultValue),void 0===r&&n.tfDeprecatedName&&(r=ON(t.attr,n.tfDeprecatedName,n.defaultValue));break;case"tensor":case"tensors":break;default:throw new Error(`Unsupported param type: ${n.type} for op: ${t.op}`)}return e[n.name]={value:r,type:s},e}),{})),n}mapFunction(t){const e=t.nodeDef,n=[];let s={};null!=e&&(s=e.reduce(((t,e)=>(t[e.name]=this.mapNode(e),"Const"===e.op&&n.push(t[e.name]),t)),{}));const r=[],a=[];t.signature.inputArg.forEach((t=>{const[e]=lN(t.name),n={name:e,op:"Placeholder",inputs:[],inputNames:[],category:"graph",inputParams:{},attrParams:{dtype:{value:CN(t.type),type:"dtype"}},children:[]};n.signatureKey=t.name,r.push(n),s[e]=n})),Object.keys(s).forEach((t=>{const e=s[t];e.inputNames.forEach((t=>{const[n]=lN(t);e.inputs.push(s[n]),s[n].children.push(e)}))}));const i=t.ret;t.signature.outputArg.forEach((t=>{const[e,n]=lN(i[t.name]),r=s[e];null!=r&&(r.defaultOutput=n,a.push(r))}));const o=this.mapArgsToSignature(t);return{nodes:s,inputs:r,outputs:a,weights:n,placeholders:[],signature:o}}mapArgsToSignature(t){return{methodName:t.signature.name,inputs:t.signature.inputArg.reduce(((t,e)=>(t[e.name]=this.mapArgToTensorInfo(e),t)),{}),outputs:t.signature.outputArg.reduce(((e,n)=>(e[n.name]=this.mapArgToTensorInfo(n,t.ret),e)),{})}}mapArgToTensorInfo(t,e){let n=t.name;return null!=e&&(n=e[n]),{name:n,dtype:t.type}}}function MN(t,e){const n=Array.isArray(t)?String.fromCharCode.apply(null,t):function(t){const e=Z().global;if(void 0!==e.atob)return e.atob(t);if("undefined"!=typeof Buffer)return new Buffer(t,"base64").toString();throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()")}(t);return e?n:n.toLowerCase()}function FN(t,e,n,s=!1){const r=t[e];return null!=r?MN(r.s,s):n}function _N(t,e,n){const s=t[e];return s?s.b:n}function zN(t,e,n){const s=t[e]||{},r=null!=s.i?s.i:null!=s.f?s.f:n;return"number"==typeof r?r:parseInt(r,10)}function CN(t){switch("string"==typeof t&&(t=nN[t]),t){case nN.DT_FLOAT:return"float32";case nN.DT_INT32:case nN.DT_INT64:case nN.DT_INT8:case nN.DT_UINT8:return"int32";case nN.DT_BOOL:return"bool";case nN.DT_DOUBLE:return"float32";case nN.DT_STRING:return"string";default:return null}}function ON(t,e,n){const s=t[e];return s&&s.func?s.func.name:n}function LN(t,e,n){const s=t[e];return s&&s.type?CN(s.type):n}function RN(t,e,n){const s=t[e];return s&&s.list&&s.list.type?s.list.type.map((t=>CN(t))):n}function BN(t){if(!t.unknownRank)return null!=t.dim?t.dim.map((t=>"number"==typeof t.size?t.size:parseInt(t.size,10))):[]}function WN(t,e,n){const s=t[e];return s&&s.shape?BN(s.shape):n}function PN(t,e,n){const s=t[e];return s?((s.list.f&&s.list.f.length?s.list.f:s.list.i)||[]).map((t=>"number"==typeof t?t:parseInt(t,10))):n}function VN(t,e,n,s=!1){const r=t[e];return r&&r.list&&r.list.s?r.list.s.map((t=>MN(t,s))):n}function UN(t,e,n){const s=t[e];return s&&s.list&&s.list.shape?s.list.shape.map((t=>BN(t))):n}function HN(t,e,n){const s=t[e];return s&&s.list&&s.list.b?s.list.b:n}class jN{constructor(t,e,n){this.node=t,this.tensorMap=e,this.context=n,this.inputs=[],this.attrs={},this.inputs=t.inputNames.map((t=>this.getInput(t))),null!=t.rawAttrs&&(this.attrs=Object.keys(t.rawAttrs).reduce(((t,e)=>(t[e]=this.getAttr(e),t)),{}))}getInput(t){return oN(t,this.tensorMap,this.context)}getAttr(t,e){const n=this.node.rawAttrs[t];if(null!=n.tensor)return oN(t,this.tensorMap,this.context);if(null!=n.i||null!=n.f)return zN(this.node.rawAttrs,t,e);if(null!=n.s)return FN(this.node.rawAttrs,t,e);if(null!=n.b)return _N(this.node.rawAttrs,t,e);if(null!=n.shape)return WN(this.node.rawAttrs,t,e);if(null!=n.type)return LN(this.node.rawAttrs,t,e);if(null!=n.list){if(null!=n.list.i||null!=n.list.f)return PN(this.node.rawAttrs,t,e);if(null!=n.list.s)return VN(this.node.rawAttrs,t,e);if(null!=n.list.shape)return UN(this.node.rawAttrs,t,e);if(null!=n.list.b)return HN(this.node.rawAttrs,t,e);if(null!=n.list.type)return RN(this.node.rawAttrs,t,e)}return e}}const qN=Rs({addN_:function(t){v(Array.isArray(t),(()=>"The argument passed to tf.addN() must be a list of tensors")),v(t.length>=1,(()=>`Must pass at least one tensor to tf.addN(), but got ${t.length}`));const e=t.map(((t,e)=>Os(t,`tensors${e}`,"addN"))),n=e[0];e.forEach((t=>{if(t.dtype!==n.dtype)throw new Error("All tensors passed to tf.addN() must have the same dtype")})),e.forEach((t=>{if(!A(t.shape,n.shape))throw new Error("All tensors passed to tf.addN() must have the same shape")}));const s=e;return $s.runKernel(at,s)}});function GN(t,e,n=""){v(function(t,e){if(t.length!==e.length)return!1;for(let n=0;n<t.length;n++)if(-1!==t[n]&&-1!==e[n]&&t[n]!==e[n])return!1;return!0}(t,e),(()=>n+` Shapes ${t} and ${e} must match`))}class KN{constructor(t,e,n,s,r,a,i){this.name=t,this.dtype=e,this.maxSize=n,this.elementShape=s,this.identicalElementShapes=r,this.dynamicSize=a,this.clearAfterRead=i,this.tensors=[],this.closed_=!1,this.idTensor=na(0),ta(this.idTensor)}get id(){return this.idTensor.id}get closed(){return this.closed_}clearAndClose(t){this.tensors.forEach((e=>{null!=t&&t.has(e.tensor.id)||e.tensor.dispose()})),this.tensors=[],this.closed_=!0,this.idTensor.dispose()}size(){return this.tensors.length}read(t){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(t<0||t>=this.size())throw new Error(`Tried to read from index ${t}, but array size is: ${this.size()}`);const e=this.tensors[t];if(e.cleared)throw new Error(`TensorArray ${this.name}: Could not read index ${t} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);return this.clearAfterRead&&(e.cleared=!0),e.read=!0,e.tensor}readMany(t){return t.map((t=>this.read(t)))}write(t,e){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(t<0||!this.dynamicSize&&t>=this.maxSize)throw new Error(`Tried to write to index ${t}, but array is not resizeable and size is: ${this.maxSize}`);const n=this.tensors[t]||{};if(e.dtype!==this.dtype)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${t},\n          because the value dtype is ${e.dtype}, but TensorArray dtype is ${this.dtype}.`);if(0!==this.size()||null!=this.elementShape&&0!==this.elementShape.length||(this.elementShape=e.shape),GN(this.elementShape,e.shape,`TensorArray ${this.name}: Could not write to TensorArray index ${t}.`),n.read)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${t}, because it has already been read.`);if(n.written)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${t}, because it has already been written.`);n.tensor=e,ta(e),n.written=!0,this.tensors[t]=n}writeMany(t,e){if(t.length!==e.length)throw new Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${t.length} is not the same as tensors size: ${e.length}.`);t.forEach(((t,n)=>this.write(t,e[n])))}gather(t,e){if(e&&e!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${e}`);if(t)t=t.slice(0,this.size());else{t=[];for(let e=0;e<this.size();e++)t.push(e)}if(0===t.length)return Ps([],[0].concat(this.elementShape));const n=this.readMany(t);return GN(this.elementShape,n[0].shape,"TensorArray shape mismatch: "),to(n,0)}concat(t){if(t&&t!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${t}`);if(0===this.size())return Ps([],[0].concat(this.elementShape));const e=[];for(let t=0;t<this.size();t++)e.push(t);const n=this.readMany(e);return GN(this.elementShape,n[0].shape,`TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${n[0].shape})`),$a(n,0)}scatter(t,e){if(e.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${e.dtype}`);if(t.length!==e.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${t.length} vs. ${e.shape[0]}`);const n=Math.max(...t);if(!this.dynamicSize&&n>=this.maxSize)throw new Error(`Max index must be < array size (${n}  vs. ${this.maxSize})`);this.writeMany(t,ao(e,0))}split(t,e){if(e.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${e.dtype}`);let n=0;const s=t.map((t=>(n+=t,n)));if(n!==e.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${n}, and tensor's shape is: ${e.shape}`);if(!this.dynamicSize&&t.length!==this.maxSize)throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${t.length}), and the TensorArray is not marked as dynamically resizeable`);const r=0===n?0:e.size/n,a=[];Xr((()=>{e=Na(e,[1,n,r]);for(let n=0;n<t.length;++n){const i=[0,0===n?0:s[n-1],0],o=[1,t[n],r];a[n]=Na(Hi(e,i,o),this.elementShape)}return a}));const i=[];for(let e=0;e<t.length;e++)i[e]=e;this.writeMany(i,a)}}class JN{constructor(t,e,n,s=-1){this.tensors=t,this.elementShape=e,this.elementDtype=n,null!=t&&t.forEach((t=>{if(n!==t.dtype)throw new Error(`Invalid data types; op elements ${n}, but list elements ${t.dtype}`);GN(e,t.shape,"TensorList shape mismatch: "),ta(t)})),this.idTensor=na(0),this.maxNumElements=s,ta(this.idTensor)}get id(){return this.idTensor.id}copy(){return new JN([...this.tensors],this.elementShape,this.elementDtype)}clearAndClose(t){this.tensors.forEach((e=>{null!=t&&t.has(e.id)||e.dispose()})),this.tensors.length=0,this.idTensor.dispose()}size(){return this.tensors.length}stack(t,e,n=-1){if(e!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e}, but list elements ${this.elementDtype}`);if(-1!==n&&this.tensors.length!==n)throw new Error(`Operation expected a list with ${n} elements but got a list with ${this.tensors.length} elements.`);return GN(t,this.elementShape,"TensorList shape mismatch: "),Xr((()=>{const e=this.tensors.map((e=>Na(e,t)));return to(e,0)}))}popBack(t,e){if(e!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e}, but list elements ${this.elementDtype}`);if(0===this.size())throw new Error("Trying to pop from an empty list.");const n=this.tensors.pop();return GN(n.shape,t,"TensorList shape mismatch: "),Na(n,t)}pushBack(t){if(t.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t.dtype}, but list elements ${this.elementDtype}`);if(GN(t.shape,this.elementShape,"TensorList shape mismatch: "),this.maxNumElements===this.size())throw new Error("Trying to push element into a full list.");ta(t),this.tensors.push(t)}resize(t){if(t<0)throw new Error(`TensorListResize expects size to be non-negative. Got: ${t}`);if(-1!==this.maxNumElements&&t>this.maxNumElements)throw new Error(`TensorListResize input size ${t} is greater maxNumElement ${this.maxNumElements}.`);this.tensors.length=t}getItem(t,e,n){if(n!==this.elementDtype)throw new Error(`Invalid data types; op elements ${n}, but list elements ${this.elementDtype}`);if(t<0||t>this.tensors.length)throw new Error(`Trying to access element ${t} in a list with ${this.tensors.length} elements.`);if(null==this.tensors[t])throw new Error(`element at index ${t} is null.`);return GN(this.tensors[t].shape,e,"TensorList shape mismatch: "),this.tensors[t]}setItem(t,e){if(e.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e.dtype}, but list elements ${this.elementDtype}`);if(t<0||-1!==this.maxNumElements&&t>=this.maxNumElements)throw new Error(`Trying to set element ${t} in a list with max ${this.maxNumElements} elements.`);GN(this.elementShape,e.shape,"TensorList shape mismatch: "),ta(e),this.tensors[t]=e}gather(t,e,n){if(e!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e}, but list elements ${this.elementDtype}`);return GN(this.elementShape,n,"TensorList shape mismatch: "),0===(t=t.slice(0,this.size())).length?Ps([],[0].concat(this.elementShape)):Xr((()=>{const e=t.map((t=>Na(this.tensors[t],n)));return to(e,0)}))}concat(t,e){if(t&&t!==this.elementDtype)throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${t}`);return GN(this.elementShape,e,"TensorList shape mismatch: "),0===this.size()?Ps([],[0].concat(this.elementShape)):Xr((()=>{const t=this.tensors.map((t=>Na(t,e)));return $a(t,0)}))}}const ZN=Rs({maxPoolWithArgmax_:function(t,e,n,s,r=!1){const a={x:Os(t,"x","maxPoolWithArgmax")},i={filterSize:e,strides:n,pad:s,includeBatchInIndex:r},o=$s.runKernel($e,a,i);return{result:o[0],indexes:o[1]}}});function YN(t,e,n){const[s,r]=iN("fusedOps",t,e,n),a="biasadd"===s,i="prelu"===r,o="fusedbatchnorm"===s,l=iN("numArgs",t,e,n);if(a){if(i&&2!==l)throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");if(!i&&1!==l)throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.")}if(o)throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported.");const u=iN("strides",t,e,n),h=cN(t,e,n),c=iN("dataFormat",t,e,n).toUpperCase(),p=iN("dilations",t,e,n),[d,f]=iN("args",t,e,n);return{stride:u,pad:h,dataFormat:c,dilations:p,biasArg:d,preluArg:f,activationFunc:r,leakyreluAlpha:iN("leakyreluAlpha",t,e,n)}}function XN(t,e,n){if(n<=0)throw new Error("The number of values should be positive.");const s={start:t,stop:e,num:n};return $s.runKernel(ge,{},s)}const QN=Rs({multinomial_:function(t,e,n,s=!1){const r=Os(t,"logits","multinomial"),a=r.size,i=r.rank;if(a<2)throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${a}.`);if(i>2)throw new Error(`Rank of probabilities must be 1 or 2, but is ${i}`);n=n||Math.random();const o={logits:1===i?Na(r,[1,-1]):r},l={numSamples:e,seed:n,normalized:s},u=$s.runKernel(Oe,o,l);return 1===i?Na(u,[u.size]):u}}),tv=async function(t){const e=Os(t,"condition","whereAsync","bool"),n=await e.data(),s=Cl(e.shape,n);return t!==e&&e.dispose(),s};function ev(t,e,n){return{boxes:iN("boxes",t,e,n),scores:iN("scores",t,e,n),maxOutputSize:iN("maxOutputSize",t,e,n),iouThreshold:iN("iouThreshold",t,e,n),scoreThreshold:iN("scoreThreshold",t,e,n),softNmsSigma:iN("softNmsSigma",t,e,n)}}class nv{constructor(t,e){this.keyDType=t,this.valueDType=e,this.handle=na(0),this.tensorMap=new Map,ta(this.handle)}get id(){return this.handle.id}clearAndClose(){this.tensorMap.forEach((t=>t.dispose())),this.tensorMap.clear(),this.handle.dispose()}size(){return this.tensorMap.size}async import(t,e){this.checkKeyAndValueTensor(t,e);const n=await t.data();return this.tensorMap.forEach((t=>t.dispose())),this.tensorMap.clear(),Xr((()=>{const t=ao(e),s=n.length,r=t.length;v(s===r,(()=>`The number of elements doesn't match, keys has ${s} elements, the values has ${r} elements.`));for(let e=0;e<s;e++){const s=n[e],r=t[e];ta(r),this.tensorMap.set(s,r)}return this.handle}))}async find(t,e){this.checkKeyAndValueTensor(t,e);const n=await t.data();return Xr((()=>{const t=[];for(let s=0;s<n.length;s++){const r=n[s],a=this.findWithDefault(r,e);t.push(a)}return to(t)}))}findWithDefault(t,e){const n=this.tensorMap.get(t);return null!=n?n:e}checkKeyAndValueTensor(t,e){if(t.dtype!==this.keyDType)throw new Error(`Expect key dtype ${this.keyDType}, but got ${t.dtype}`);if(e.dtype!==this.valueDType)throw new Error(`Expect value dtype ${this.valueDType}, but got ${e.dtype}`)}}const sv=Rs({sparseToDense_:function(t,e,n,s=0){const r=Os(t,"sparseIndices","sparseToDense","int32"),a=Os(e,"sparseValues","sparseToDense"),i=Os(s,"defaultValue","sparseToDense",a.dtype);!function(t,e,n,s){if("int32"!==t.dtype)throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${t.dtype}.`);if(t.rank>2)throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${t.shape}.`);const r=t.rank>0?t.shape[0]:1,a=t.rank>1?t.shape[1]:1;if(n.length!==a)throw new Error(`outputShape has incorrect number of elements:, ${n.length}, should be: ${a}.`);const i=e.size;if(0!==e.rank&&(1!==e.rank||i!==r))throw new Error(`sparseValues has incorrect shape ${e.shape}, should be [] or [${r}]`);if(e.dtype!==s.dtype)throw new Error("sparseValues.dtype must match defaultValues.dtype")}(r,a,n,i);const o={sparseIndices:r,sparseValues:a,defaultValue:i},l={outputShape:n};return $s.runKernel(En,o,l)}}),rv=Rs({bincount_:function(t,e,n){const s=Os(t,"x","bincount"),r=Os(e,"weights","bincount");v("int32"===s.dtype,(()=>`Error in bincount: input dtype must be int32, but got ${s.dtype}`)),v(n>=0,(()=>`size must be non-negative, but got ${n}.`)),v(r.size===s.size||0===r.size,(()=>`Error in bincount: weights must have the same size as input or0-length, but got input shape: ${s.shape}, weights shape: ${r.shape}.`));const a={x:s,weights:r},i={size:n};return $s.runKernel(kt,a,i)}}),av=Rs({denseBincount_:function(t,e,n,s=!1){const r=Os(t,"x","denseBincount"),a=Os(e,"weights","denseBincount");v("int32"===r.dtype,(()=>`Error in denseBincount: input dtype must be int32, but got ${r.dtype}`)),v(r.rank<=2,(()=>`Error in denseBincount: input must be at most rank 2, but got rank ${r.rank}.`)),v(n>=0,(()=>`size must be non-negative, but got ${n}.`)),v(a.size===r.size||0===a.size,(()=>`Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${r.shape}, weights shape: ${a.shape}.`));const i={x:r,weights:a},o={size:n,binaryOutput:s};return $s.runKernel(Ot,i,o)}}),iv=Rs({scatterND_:function(t,e,n){const s=Os(t,"indices","scatterND","int32"),r=Os(e,"updates","scatterND");!function(t,e,n){if(e.rank<1)throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${e.rank}.`);if(t.rank<1)throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${t.rank}.`);if("int32"!==e.dtype)throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${e.dtype}`);if(n.length<1)throw new Error(`Output rank must be greater or equal to 1, but got shape: ${n}`);if(0===n.length){if(0===e.size)throw new Error(`Indices specified for empty output. indices shape: ${e.shape}`);if(0===t.size)throw new Error(`Updates specified for empty output. updates shape: ${t.shape}`)}!function(t,e,n){const s=e.rank>1?e.shape[e.rank-1]:1,r=e.rank>1?e.rank-1:1,a=`Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${n.shape}, indices.shape: ${e.shape}, shape: ${t}, sliceDim: ${s}, and batchDim: ${r}.`;if(n.rank<r)throw new Error(a+` update.rank < ${r}. `);if(t.length<s+(n.rank-r))throw new Error(a+` Output shape length < ${s+(n.rank-r)}`);if(n.rank!==r+t.length-s)throw new Error(a+" update.rank != "+(r+t.length-s));for(let t=0;t<r;++t)if(n.shape[t]!==e.shape[t])throw new Error(a+` updates.shape[${t}] (${n.shape[t]}) != indices.shape[${t}] (${e.shape[t]}).`);for(let e=0;e<n.rank-r;++e)if(n.shape[e+r]!==t[e+s])throw new Error(a+` updates.shape[${e+r}] (${n.shape[e+r]}) != shape[${e+r}] (${t[e+r]})`)}(n,e,t)}(r,s,n);const a={indices:s,updates:r},i={shape:n};return $s.runKernel(hn,a,i)}}),ov=Rs({gatherND_:function(t,e){const n=Os(e,"indices","gatherND","int32"),s={params:Os(t,"x","gatherND"),indices:n};return $s.runKernel(re,s)}});function lv(t,e,n,s){const r=((t,e,n)=>{switch(t.category){case"arithmetic":return Xr((()=>((t,e,n)=>{switch(t.op){case"BiasAdd":case"AddV2":case"Add":return[aa(iN("a",t,e,n),iN("b",t,e,n))];case"AddN":return[qN(iN("tensors",t,e,n))];case"FloorMod":case"Mod":return[Bh(iN("a",t,e,n),iN("b",t,e,n))];case"Mul":return[ii(iN("a",t,e,n),iN("b",t,e,n))];case"RealDiv":case"Div":return[Va(iN("a",t,e,n),iN("b",t,e,n))];case"DivNoNan":return[rc(iN("a",t,e,n),iN("b",t,e,n))];case"FloorDiv":return[Pa(iN("a",t,e,n),iN("b",t,e,n))];case"Sub":return[oi(iN("a",t,e,n),iN("b",t,e,n))];case"Minimum":return[gi(iN("a",t,e,n),iN("b",t,e,n))];case"Maximum":return[di(iN("a",t,e,n),iN("b",t,e,n))];case"Pow":return[el(iN("a",t,e,n),iN("b",t,e,n))];case"SquaredDifference":return[ul(iN("a",t,e,n),iN("b",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"basic_math":return Xr((()=>((t,e,n)=>{switch(t.op){case"Abs":case"ComplexAbs":return[ra(iN("x",t,e,n))];case"Acos":return[Lh(iN("x",t,e,n))];case"Acosh":return[Rh(iN("x",t,e,n))];case"Asin":return[Zh(iN("x",t,e,n))];case"Asinh":return[Yh(iN("x",t,e,n))];case"Atan":return[Xh(iN("x",t,e,n))];case"Atan2":return[Qh(iN("x",t,e,n),iN("y",t,e,n))];case"Atanh":return[tc(iN("x",t,e,n))];case"Ceil":return[ec(iN("x",t,e,n))];case"Complex":return[Bs(iN("real",t,e,n),iN("imag",t,e,n))];case"Cos":return[Th(iN("x",t,e,n))];case"Cosh":return[Ah(iN("x",t,e,n))];case"Elu":return[Ua(iN("x",t,e,n))];case"Erf":return[pc(iN("x",t,e,n))];case"Exp":return[ri(iN("x",t,e,n))];case"Expm1":return[dc(iN("x",t,e,n))];case"Floor":return[Xa(iN("x",t,e,n))];case"Log":return[si(iN("x",t,e,n))];case"Log1p":return[hl(iN("x",t,e,n))];case"Imag":return[co(iN("x",t,e,n))];case"Neg":return[Ti(iN("x",t,e,n))];case"Reciprocal":return[Ic(iN("x",t,e,n))];case"Real":return[po(iN("x",t,e,n))];case"Relu":return[Bi(iN("x",t,e,n))];case"Round":return[Sc(iN("x",t,e,n))];case"Selu":return[Pi(iN("x",t,e,n))];case"Sigmoid":return[Ui(iN("x",t,e,n))];case"Sin":return[pu(iN("x",t,e,n))];case"Sign":return[Tc(iN("x",t,e,n))];case"Sinh":return[fu(iN("x",t,e,n))];case"Softplus":return[Zi(iN("x",t,e,n))];case"Sqrt":return[Xi(iN("x",t,e,n))];case"Square":return[Ii(iN("x",t,e,n))];case"Tanh":return[eo(iN("x",t,e,n))];case"Tan":return[Ac(iN("x",t,e,n))];case"ClipByValue":return[Da(iN("x",t,e,n),iN("clipValueMin",t,e,n),iN("clipValueMax",t,e,n))];case"Relu6":return[ko(iN("x",t,e,n))];case"Rsqrt":return[Eu(oN(t.inputNames[0],e,n))];case"Prod":return[vc(iN("x",t,e,n),iN("axes",t,e,n))];case"LeakyRelu":return[ni(iN("x",t,e,n),iN("alpha",t,e,n))];case"Prelu":return[_i(iN("x",t,e,n),iN("alpha",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"control":return(async(t,e,n)=>{switch(t.op){case"If":case"StatelessIf":{const s=iN("thenBranch",t,e,n),r=iN("elseBranch",t,e,n),a=iN("cond",t,e,n),i=iN("args",t,e,n);return(await a.data())[0]?n.functionMap[s].executeFunctionAsync(i,n.tensorArrayMap,n.tensorListMap):n.functionMap[r].executeFunctionAsync(i,n.tensorArrayMap,n.tensorListMap)}case"While":case"StatelessWhile":{const s=iN("body",t,e,n),r=iN("cond",t,e,n),a=iN("args",t,e,n),i=await n.functionMap[r].executeFunctionAsync(a,n.tensorArrayMap,n.tensorListMap),o=a.map((t=>t.id));let l=await i[0].data();i.forEach((t=>{t.kept||-1!==o.indexOf(t.id)||t.dispose()}));let u=a;for(;l[0];){const t=u;u=await n.functionMap[s].executeFunctionAsync(u,n.tensorArrayMap,n.tensorListMap);const e=u.map((t=>t.id));t.forEach((t=>{t.kept||-1!==o.indexOf(t.id)||-1!==e.indexOf(t.id)||t.dispose()}));const a=await n.functionMap[r].executeFunctionAsync(u,n.tensorArrayMap,n.tensorListMap);l=await a[0].data(),a.forEach((t=>{t.kept||-1!==o.indexOf(t.id)||-1!==e.indexOf(t.id)||t.dispose()}))}return u}case"LoopCond":return[pN(iN("pred",t,e,n))];case"Switch":{const s=iN("pred",t,e,n);let r=iN("data",t,e,n);return r.kept||(r=pN(r)),(await s.data())[0]?[void 0,r]:[r,void 0]}case"Merge":{const s=t.inputNames.find((t=>void 0!==oN(t,e,n)));return s?[pN(oN(s,e,n))]:void 0}case"Enter":{const s=iN("frameName",t,e,n),r=iN("tensor",t,e,n);return n.enterFrame(s),[pN(r)]}case"Exit":{const s=iN("tensor",t,e,n);return n.exitFrame(),[pN(s)]}case"NextIteration":{const s=iN("tensor",t,e,n);return n.nextIteration(),[pN(s)]}case"TensorArrayV3":{const s=iN("size",t,e,n),r=iN("dtype",t,e,n),a=iN("elementShape",t,e,n),i=iN("dynamicSize",t,e,n),o=iN("clearAfterRead",t,e,n),l=iN("identicalElementShapes",t,e,n),u=iN("name",t,e,n),h=new KN(u,r,s,a,l,i,o);return n.addTensorArray(h),[h.idTensor,na(1)]}case"TensorArrayWriteV3":{const s=iN("tensorArrayId",t,e,n),r=iN("index",t,e,n),a=iN("tensor",t,e,n),i=n.getTensorArray(s.id);return i.write(r,a),[i.idTensor]}case"TensorArrayReadV3":{const s=iN("tensorArrayId",t,e,n),r=iN("index",t,e,n);return[n.getTensorArray(s.id).read(r)]}case"TensorArrayGatherV3":{const s=iN("tensorArrayId",t,e,n),r=iN("indices",t,e,n),a=iN("dtype",t,e,n);return[n.getTensorArray(s.id).gather(r,a)]}case"TensorArrayScatterV3":{const s=iN("tensorArrayId",t,e,n),r=iN("indices",t,e,n),a=iN("tensor",t,e,n),i=n.getTensorArray(s.id);return i.scatter(r,a),[i.idTensor]}case"TensorArrayConcatV3":{const s=iN("tensorArrayId",t,e,n),r=n.getTensorArray(s.id),a=iN("dtype",t,e,n);return[r.concat(a)]}case"TensorArraySplitV3":{const s=iN("tensorArrayId",t,e,n),r=iN("tensor",t,e,n),a=iN("lengths",t,e,n),i=n.getTensorArray(s.id);return i.split(a,r),[i.idTensor]}case"TensorArraySizeV3":{const s=iN("tensorArrayId",t,e,n);return[na(n.getTensorArray(s.id).size(),"int32")]}case"TensorArrayCloseV3":{const s=iN("tensorArrayId",t,e,n),r=n.getTensorArray(s.id);return r.clearAndClose(),[r.idTensor]}case"TensorListSetItem":{const s=iN("tensorListId",t,e,n),r=iN("index",t,e,n),a=iN("tensor",t,e,n),i=n.getTensorList(s.id);return i.setItem(r,a),[i.idTensor]}case"TensorListGetItem":{const s=iN("tensorListId",t,e,n),r=iN("index",t,e,n),a=iN("elementShape",t,e,n),i=iN("elementDType",t,e,n);return[n.getTensorList(s.id).getItem(r,a,i)]}case"TensorListScatterV2":case"TensorListScatter":{const s=iN("indices",t,e,n),r=function(t,e,n,s){if(e.length!==t.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${e.length} vs. ${t.shape[0]}`);const r=Math.max(...e);if(null!=s&&-1!==s&&r>=s)throw new Error(`Max index must be < array size (${r}  vs. ${s})`);const a=new JN([],n,t.dtype,s),i=ao(t,0);return e.forEach(((t,e)=>{a.setItem(t,i[e])})),a}(iN("tensor",t,e,n),s,iN("elementShape",t,e,n),iN("numElements",t,e,n));return n.addTensorList(r),[r.idTensor]}case"TensorListReserve":case"EmptyTensorList":{const s=iN("elementShape",t,e,n),r=iN("elementDType",t,e,n);let a;a="TensorListReserve"===t.op?"numElements":"maxNumElements";const i=function(t,e,n){return new JN([],t,e,n)}(s,r,iN(a,t,e,n));return n.addTensorList(i),[i.idTensor]}case"TensorListGather":{const s=iN("tensorListId",t,e,n),r=iN("indices",t,e,n),a=iN("elementShape",t,e,n),i=iN("elementDType",t,e,n);return[n.getTensorList(s.id).gather(r,i,a)]}case"TensorListStack":{const s=iN("tensorListId",t,e,n),r=iN("elementShape",t,e,n),a=iN("elementDType",t,e,n),i=iN("numElements",t,e,n);return[n.getTensorList(s.id).stack(r,a,i)]}case"TensorListFromTensor":{const s=function(t,e,n){const s=t.dtype;if(t.shape.length<1)throw new Error(`Tensor must be at least a vector, but saw shape: ${t.shape}`);if(t.dtype!==n)throw new Error(`Invalid data types; op elements ${t.dtype}, but list elements ${n}`);GN(t.shape.slice(1),e,"TensorList shape mismatch: ");const r=ao(t);return new JN(r,e,s)}(iN("tensor",t,e,n),iN("elementShape",t,e,n),iN("elementDType",t,e,n));return n.addTensorList(s),[s.idTensor]}case"TensorListConcat":{const s=iN("tensorListId",t,e,n),r=n.getTensorList(s.id),a=iN("dtype",t,e,n),i=iN("elementShape",t,e,n);return[r.concat(a,i)]}case"TensorListPushBack":{const s=iN("tensorListId",t,e,n),r=iN("tensor",t,e,n),a=n.getTensorList(s.id);return a.pushBack(r),[a.idTensor]}case"TensorListPopBack":{const s=iN("tensorListId",t,e,n),r=iN("elementShape",t,e,n),a=iN("elementDType",t,e,n);return[n.getTensorList(s.id).popBack(r,a)]}case"TensorListSplit":{const s=iN("tensor",t,e,n),r=iN("elementShape",t,e,n),a=function(t,e,n){let s=0;const r=e.map((t=>(s+=t,s)));if(s!==t.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${s}, and tensor's shape is: ${t.shape}`);const a=0===s?0:t.size/s,i=Xr((()=>{const i=[];t=Na(t,[1,s,a]);for(let s=0;s<e.length;++s){const o=[0,0===s?0:r[s-1],0],l=[1,e[s],a];i[s]=Na(Hi(t,o,l),n)}return t.dispose(),i})),o=new JN([],n,t.dtype,e.length);for(let t=0;t<i.length;t++)o.setItem(t,i[t]);return o}(s,iN("lengths",t,e,n),r);return n.addTensorList(a),[a.idTensor]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n);case"convolution":return Xr((()=>((t,e,n)=>{switch(t.op){case"Conv1D":{const s=iN("stride",t,e,n),r=iN("pad",t,e,n),a=iN("dataFormat",t,e,n).toUpperCase(),i=iN("dilation",t,e,n);return[Oa(iN("x",t,e,n),iN("filter",t,e,n),s,r,a,i)]}case"Conv2D":{const s=iN("strides",t,e,n),r=cN(t,e,n),a=iN("dataFormat",t,e,n).toUpperCase(),i=iN("dilations",t,e,n);return[Ca(iN("x",t,e,n),iN("filter",t,e,n),[s[1],s[2]],r,a,[i[1],i[2]])]}case"_FusedConv2D":{const{stride:s,pad:r,dataFormat:a,dilations:i,biasArg:o,preluArg:l,activationFunc:u,leakyreluAlpha:h}=YN(t,e,n);return[So({x:iN("x",t,e,n),filter:iN("filter",t,e,n),strides:[s[1],s[2]],pad:r,dataFormat:a,dilations:[i[1],i[2]],bias:o,activation:u,preluActivationWeights:l,leakyreluAlpha:h})]}case"FusedDepthwiseConv2dNative":{const{stride:s,pad:r,dataFormat:a,dilations:i,biasArg:o,preluArg:l,activationFunc:u,leakyreluAlpha:h}=YN(t,e,n);return[Ao({x:iN("x",t,e,n),filter:iN("filter",t,e,n),strides:[s[1],s[2]],pad:r,dataFormat:a,dilations:[i[1],i[2]],bias:o,activation:u,preluActivationWeights:l,leakyreluAlpha:h})]}case"Conv2DBackpropInput":case"Conv2dTranspose":{const s=iN("outputShape",t,e,n),r=iN("strides",t,e,n),a=cN(t,e,n);return[Ra(iN("x",t,e,n),iN("filter",t,e,n),s,[r[1],r[2]],a)]}case"DepthwiseConv2dNative":case"DepthwiseConv2d":{const s=iN("strides",t,e,n),r=cN(t,e,n),a=iN("dilations",t,e,n),i=iN("dataFormat",t,e,n).toUpperCase();return[Wa(iN("input",t,e,n),iN("filter",t,e,n),[s[1],s[2]],r,i,[a[1],a[2]])]}case"Conv3D":{const s=iN("strides",t,e,n),r=iN("pad",t,e,n),a=iN("dataFormat",t,e,n).toUpperCase(),i=iN("dilations",t,e,n);return[Ba(iN("x",t,e,n),iN("filter",t,e,n),[s[1],s[2],s[3]],r,a,[i[1],i[2],i[3]])]}case"AvgPool":{const s=iN("strides",t,e,n),r=iN("pad",t,e,n),a=iN("kernelSize",t,e,n);return[va(iN("x",t,e,n),[a[1],a[2]],[s[1],s[2]],r)]}case"MaxPool":{const s=iN("strides",t,e,n),r=iN("pad",t,e,n),a=iN("kernelSize",t,e,n);return[ci(iN("x",t,e,n),[a[1],a[2]],[s[1],s[2]],r)]}case"MaxPoolWithArgmax":{const s=iN("strides",t,e,n),r=iN("pad",t,e,n),a=iN("kernelSize",t,e,n),i=iN("includeBatchInIndex",t,e,n),{result:o,indexes:l}=ZN(iN("x",t,e,n),[a[1],a[2]],[s[1],s[2]],r,i);return[o,l]}case"AvgPool3D":{const s=iN("strides",t,e,n),r=iN("pad",t,e,n),a=iN("kernelSize",t,e,n);return[Ia(iN("x",t,e,n),[a[1],a[2],a[3]],[s[1],s[2],s[3]],r)]}case"MaxPool3D":{const s=iN("strides",t,e,n),r=iN("pad",t,e,n),a=iN("kernelSize",t,e,n);return[pi(iN("x",t,e,n),[a[1],a[2],a[3]],[s[1],s[2],s[3]],r)]}case"Dilation2D":{const s=iN("strides",t,e,n),r=iN("pad",t,e,n),a=iN("dilations",t,e,n),i=s[1],o=s[2],l=a[1],u=a[2];return[sc(iN("x",t,e,n),iN("filter",t,e,n),[i,o],r,[l,u],"NHWC")]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"creation":return Xr((()=>((t,e,n)=>{switch(t.op){case"Fill":{const s=iN("shape",t,e,n),r=iN("dtype",t,e,n);return[Ya(s,iN("value",t,e,n),r)]}case"LinSpace":return[XN(iN("start",t,e,n),iN("stop",t,e,n),iN("num",t,e,n))];case"Multinomial":{const s=iN("logits",t,e,n),r=iN("numSamples",t,e,n),a=iN("seed",t,e,n);return[QN(s,r,a)]}case"OneHot":{const s=iN("indices",t,e,n),r=iN("depth",t,e,n),a=iN("onValue",t,e,n),i=iN("offValue",t,e,n);return[Ai(s,r,a,i)]}case"Ones":return[$i(iN("shape",t,e,n),iN("dtype",t,e,n))];case"OnesLike":return[Mi(iN("x",t,e,n))];case"RandomUniform":return[Ri(iN("shape",t,e,n),iN("minval",t,e,n),iN("maxval",t,e,n),iN("dtype",t,e,n))];case"Range":return[Qo(iN("start",t,e,n),iN("stop",t,e,n),iN("step",t,e,n),iN("dtype",t,e,n))];case"TruncatedNormal":{const s=iN("shape",t,e,n),r=iN("mean",t,e,n),a=iN("stdDev",t,e,n),i=iN("seed",t,e,n);return[ro(s,r,a,iN("dtype",t,e,n),i)]}case"Zeros":return[Di(iN("shape",t,e,n),iN("dtype",t,e,n))];case"ZerosLike":return[lo(iN("x",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"dynamic":return(async(t,e,n)=>{switch(t.op){case"NonMaxSuppressionV5":{const{boxes:s,scores:r,maxOutputSize:a,iouThreshold:i,scoreThreshold:o,softNmsSigma:l}=ev(t,e,n),u=await pl.nonMaxSuppressionWithScoreAsync(s,r,a,i,o,l);return[u.selectedIndices,u.selectedScores]}case"NonMaxSuppressionV4":{const{boxes:s,scores:r,maxOutputSize:a,iouThreshold:i,scoreThreshold:o}=ev(t,e,n),l=iN("padToMaxOutputSize",t,e,n),u=await pl.nonMaxSuppressionPaddedAsync(s,r,a,i,o,l);return[u.selectedIndices,u.validOutputs]}case"NonMaxSuppressionV3":case"NonMaxSuppressionV2":{const{boxes:s,scores:r,maxOutputSize:a,iouThreshold:i,scoreThreshold:o}=ev(t,e,n);return[await pl.nonMaxSuppressionAsync(s,r,a,i,o)]}case"Where":{const s=Ir(iN("condition",t,e,n),"bool"),r=[await tv(s)];return s.dispose(),r}case"ListDiff":return async function(t,e){const n=Os(t,"x","setdiff1d"),s=Os(e,"y","setdiff1d");v(n.dtype===s.dtype,(()=>`x and y should have the same dtype, but got x (${n.dtype}) and y (${s.dtype}).`)),v(1===n.rank,(()=>`x should be 1D tensor, but got x (${n.shape}).`)),v(1===s.rank,(()=>`y should be 1D tensor, but got y (${s.shape}).`));const r=await n.data(),a=await s.data(),i=new Set(a);let o=0;for(let t=0;t<r.length;t++)i.has(r[t])||o++;const l=new cs([o],n.dtype),u=new cs([o],"int32");for(let t=0,e=0;t<r.length;t++)i.has(r[t])||(l.values[e]=r[t],u.values[e]=t,e++);return[l.toTensor(),u.toTensor()]}(iN("x",t,e,n),iN("y",t,e,n));default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n);case"evaluation":return Xr((()=>((t,e,n)=>{switch(t.op){case"TopKV2":{const s=iN("x",t,e,n),r=iN("k",t,e,n),a=iN("sorted",t,e,n),i=Dc(s,r,a);return[i.values,i.indices]}case"Unique":{const s=iN("x",t,e,n),r=$c(s);return[r.values,r.indices]}case"UniqueV2":{const s=iN("x",t,e,n),r=iN("axis",t,e,n),a=$c(s,r);return[a.values,a.indices]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"image":return Xr((()=>((t,e,n)=>{switch(t.op){case"ResizeBilinear":{const s=iN("images",t,e,n),r=iN("size",t,e,n),a=iN("alignCorners",t,e,n),i=iN("halfPixelCenters",t,e,n);return[pl.resizeBilinear(s,[r[0],r[1]],a,i)]}case"ResizeNearestNeighbor":{const s=iN("images",t,e,n),r=iN("size",t,e,n),a=iN("alignCorners",t,e,n),i=iN("halfPixelCenters",t,e,n);return[pl.resizeNearestNeighbor(s,[r[0],r[1]],a,i)]}case"CropAndResize":{const s=iN("image",t,e,n),r=iN("boxes",t,e,n),a=iN("boxInd",t,e,n),i=iN("cropSize",t,e,n),o=iN("method",t,e,n),l=iN("extrapolationValue",t,e,n);return[pl.cropAndResize(s,r,a,i,o,l)]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"graph":return Xr((()=>((t,e,n)=>{switch(t.op){case"Const":return e[t.name];case"PlaceholderWithDefault":const s=iN("default",t,e,n);return[oN(t.name,e,n)||s];case"Placeholder":return[oN(t.name,e,n)];case"Identity":case"StopGradient":case"FakeQuantWithMinMaxVars":return[pN(iN("x",t,e,n))];case"IdentityN":return iN("x",t,e,n).map((t=>pN(t)));case"Snapshot":return[pN(iN("x",t,e,n))];case"Shape":return[no(iN("x",t,e,n).shape,"int32")];case"ShapeN":return iN("x",t,e,n).map((t=>no(t.shape)));case"Size":return[na(iN("x",t,e,n).size,"int32")];case"Rank":return[na(iN("x",t,e,n).rank,"int32")];case"NoOp":return[na(1)];case"Print":const r=iN("x",t,e,n),a=iN("data",t,e,n),i=iN("message",t,e,n),o=iN("summarize",t,e,n);console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance."),console.log(i);for(let t=0;t<a.length;t++)console.log(Array.prototype.slice.call(a[t].dataSync()).slice(0,o));return[r];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"logical":return Xr((()=>((t,e,n)=>{switch(t.op){case"Equal":return[Ga(iN("a",t,e,n),iN("b",t,e,n))];case"NotEqual":return[Ei(iN("a",t,e,n),iN("b",t,e,n))];case"Greater":return[ti(iN("a",t,e,n),iN("b",t,e,n))];case"GreaterEqual":return[ei(iN("a",t,e,n),iN("b",t,e,n))];case"Less":return[qu(iN("a",t,e,n),iN("b",t,e,n))];case"LessEqual":return[Xo(iN("a",t,e,n),iN("b",t,e,n))];case"LogicalAnd":return[hi(iN("a",t,e,n),iN("b",t,e,n))];case"LogicalNot":return[xh(iN("a",t,e,n))];case"LogicalOr":return[kc(iN("a",t,e,n),iN("b",t,e,n))];case"Select":case"SelectV2":return[oo(iN("condition",t,e,n),iN("a",t,e,n),iN("b",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"matrices":return Xr((()=>((t,e,n)=>{switch(t.op){case"BatchMatMul":case"BatchMatMulV2":case"MatMul":return[Do(iN("a",t,e,n),iN("b",t,e,n),iN("transposeA",t,e,n),iN("transposeB",t,e,n))];case"Transpose":return[uo(iN("x",t,e,n),iN("perm",t,e,n))];case"_FusedMatMul":const[s,r]=iN("fusedOps",t,e,n),a="biasadd"===s,i="prelu"===r,o=iN("numArgs",t,e,n),l=iN("leakyreluAlpha",t,e,n);if(a){if(i&&2!==o)throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");if(!i&&1!==o)throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.")}const[u,h]=iN("args",t,e,n);return[$o({a:iN("a",t,e,n),b:iN("b",t,e,n),transposeA:iN("transposeA",t,e,n),transposeB:iN("transposeB",t,e,n),bias:u,activation:r,preluActivationWeights:h,leakyreluAlpha:l})];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"normalization":return Xr((()=>((t,e,n)=>{switch(t.op){case"FusedBatchNorm":case"FusedBatchNormV2":case"FusedBatchNormV3":return[Sa(iN("x",t,e,n),iN("mean",t,e,n),iN("variance",t,e,n),iN("offset",t,e,n),iN("scale",t,e,n),iN("epsilon",t,e,n))];case"LRN":return[yc(iN("x",t,e,n),iN("radius",t,e,n),iN("bias",t,e,n),iN("alpha",t,e,n),iN("beta",t,e,n))];case"Softmax":return[Ji(iN("x",t,e,n))];case"LogSoftmax":return[ui(iN("x",t,e,n))];case"SparseToDense":return[sv(iN("sparseIndices",t,e,n),iN("outputShape",t,e,n),iN("sparseValues",t,e,n),iN("defaultValue",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"reduction":return Xr((()=>((t,e,n)=>{switch(t.op){case"Max":{const s=iN("axis",t,e,n),r=iN("keepDims",t,e,n);return[ai(iN("x",t,e,n),s,r)]}case"Mean":{const s=iN("axis",t,e,n),r=iN("keepDims",t,e,n);return[fi(iN("x",t,e,n),s,r)]}case"Min":{const s=iN("axis",t,e,n),r=iN("keepDims",t,e,n);return[mi(iN("x",t,e,n),s,r)]}case"Sum":{const s=iN("axis",t,e,n),r=iN("keepDims",t,e,n);return[li(iN("x",t,e,n),s,r)]}case"All":{const s=iN("axis",t,e,n),r=iN("keepDims",t,e,n);return[ia(iN("x",t,e,n),s,r)]}case"Any":{const s=iN("axis",t,e,n),r=iN("keepDims",t,e,n);return[oa(iN("x",t,e,n),s,r)]}case"ArgMax":{const s=iN("axis",t,e,n);return[la(iN("x",t,e,n),s)]}case"ArgMin":{const s=iN("axis",t,e,n);return[Jh(iN("x",t,e,n),s)]}case"Prod":{const s=iN("axis",t,e,n),r=iN("keepDims",t,e,n);return[vc(iN("x",t,e,n),s,r)]}case"Cumsum":{const s=iN("axis",t,e,n),r=iN("exclusive",t,e,n),a=iN("reverse",t,e,n);return[gu(iN("x",t,e,n),s,r,a)]}case"Bincount":const s=iN("x",t,e,n),r=iN("weights",t,e,n),a=iN("size",t,e,n);return[rv(s,r,a)];case"DenseBincount":{const s=iN("x",t,e,n),r=iN("weights",t,e,n),a=iN("size",t,e,n),i=iN("binaryOutput",t,e,n);return[av(s,r,a,i)]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"slice_join":return Xr((()=>((t,e,n)=>{switch(t.op){case"ConcatV2":case"Concat":{const s=iN("n",t,e,n),r=iN("axis",t,e,n);let a=iN("tensors",t,e,n);return a=a.slice(0,s),[$a(a,r)]}case"Gather":{const s=iN("x",t,e,n),r=iN("indices",t,e,n);return[Qa(s,Ir(r,"int32"),0)]}case"GatherV2":{const s=iN("axis",t,e,n),r=iN("batchDims",t,e,n),a=iN("x",t,e,n),i=iN("indices",t,e,n);return[Qa(a,Ir(i,"int32"),s,r)]}case"Reverse":{const s=iN("dims",t,e,n),r=[];for(let t=0;t<s.length;t++)s[t]&&r.push(t);const a=iN("x",t,e,n);return[Wi(a,r)]}case"ReverseV2":{const s=iN("axis",t,e,n),r=iN("x",t,e,n);return[Wi(r,s)]}case"Slice":{const s=iN("begin",t,e,n),r=iN("size",t,e,n);return[Hi(iN("x",t,e,n),s,r)]}case"StridedSlice":{const s=iN("begin",t,e,n),r=iN("end",t,e,n),a=iN("strides",t,e,n),i=iN("beginMask",t,e,n),o=iN("endMask",t,e,n),l=iN("ellipsisMask",t,e,n),u=iN("newAxisMask",t,e,n),h=iN("shrinkAxisMask",t,e,n),c=iN("x",t,e,n);return[Ec(c,s,r,a,i,o,l,u,h)]}case"Pack":return Xr((()=>{const s=iN("axis",t,e,n),r=iN("tensors",t,e,n),a=r[0].shape,i=Qi(r[0]).shape,o=r.map((t=>{const e=A(t.shape,a);if(!e&&!A(Qi(t).shape,i))throw new Error("the input tensors shape does not match");return e?t:Na(t,a)}));return[to(o,s)]}));case"Unpack":{const s=iN("axis",t,e,n),r=iN("tensor",t,e,n);return ao(r,s)}case"Tile":{const s=iN("reps",t,e,n);return[Ja(iN("x",t,e,n),s)]}case"Split":case"SplitV":{const s=iN("axis",t,e,n),r=iN("numOrSizeSplits",t,e,n),a=iN("x",t,e,n);return Yi(a,r,s)}case"ScatterNd":{const s=iN("indices",t,e,n),r=iN("values",t,e,n),a=iN("shape",t,e,n);return[iv(s,r,a)]}case"GatherNd":{const s=iN("x",t,e,n),r=iN("indices",t,e,n);return[ov(s,r)]}case"SparseToDense":{const s=iN("sparseIndices",t,e,n),r=iN("outputShape",t,e,n),a=iN("sparseValues",t,e,n),i=iN("defaultValue",t,e,n);return[sv(s,a,r,a.dtype===i.dtype?i:Ir(i,a.dtype))]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"spectral":return Xr((()=>((t,e,n)=>{switch(t.op){case"FFT":return[fo(iN("x",t,e,n))];case"IFFT":return[go(iN("x",t,e,n))];case"RFFT":return[mo(iN("x",t,e,n))];case"IRFFT":return[yo(iN("x",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"transformation":return Xr((()=>((t,e,n)=>{switch(t.op){case"Cast":return[Ir(iN("x",t,e,n),iN("dtype",t,e,n))];case"ExpandDims":{const s=iN("axis",t,e,n);return[Ka(iN("x",t,e,n),s)]}case"Squeeze":{const s=iN("axis",t,e,n);return[Qi(iN("x",t,e,n),s)]}case"Reshape":return[Na(iN("x",t,e,n),iN("shape",t,e,n))];case"MirrorPad":return[xc(iN("x",t,e,n),iN("padding",t,e,n),iN("mode",t,e,n))];case"PadV2":case"Pad":return[Fi(iN("x",t,e,n),iN("padding",t,e,n),iN("constantValue",t,e,n))];case"SpaceToBatchND":{const s=iN("blockShape",t,e,n),r=iN("paddings",t,e,n);return[Ql(iN("x",t,e,n),s,r)]}case"BatchToSpaceND":{const s=iN("blockShape",t,e,n),r=iN("crops",t,e,n);return[_h(iN("x",t,e,n),s,r)]}case"DepthToSpace":{const s=iN("blockSize",t,e,n),r=iN("dataFormat",t,e,n).toUpperCase();return[nc(iN("x",t,e,n),s,r)]}case"BroadcastTo":return[io(iN("x",t,e,n),iN("shape",t,e,n))];default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n)));case"hash_table":return(async(t,e,n,s)=>{switch(t.op){case"HashTable":case"HashTableV2":{const r=iN("keyDType",t,e,n),a=iN("valueDType",t,e,n),i=new nv(r,a);return s.addHashTable(t.name,i),[i.handle]}case"LookupTableImport":case"LookupTableImportV2":{const r=iN("tableHandle",t,e,n,s),a=iN("keys",t,e,n),i=iN("values",t,e,n),o=s.getHashTableById(r.id);return[await o.import(a,i)]}case"LookupTableFind":case"LookupTableFindV2":{const r=iN("tableHandle",t,e,n,s),a=iN("keys",t,e,n),i=iN("defaultValue",t,e,n),o=s.getHashTableById(r.id);return[await o.find(a,i)]}default:throw TypeError(`Node type ${t.op} is not implemented`)}})(t,e,n,s);case"custom":const r=aN(t.op);if(r&&r.customExecutor)return r.customExecutor(new jN(t,e,n));throw TypeError(`Custom op ${t.op} is not registered.`);default:throw TypeError(`Unknown op '${t.op}'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()`)}})(t,e,n);return K(r)?r.then((t=>[].concat(t))):[].concat(r)}class uv{constructor(t={},e={},n={},s={}){this.weightMap=t,this.tensorArrayMap=e,this.tensorListMap=n,this.functionMap=s,this.rootContext={id:0,frameName:"",iterationId:0},this.contexts=[this.rootContext],this.lastId=0,this.generateCurrentContextIds()}newFrame(t,e){return{id:t,frameName:e,iterationId:0}}set currentContext(t){this.contexts!==t&&(this.contexts=t,this.generateCurrentContextIds())}get currentContext(){return this.contexts}get currentContextId(){return this._currentContextIds[0]}get currentContextIds(){return this._currentContextIds}generateCurrentContextIds(){const t=[];for(let e=0;e<this.contexts.length-1;e++){const n=this.contexts.slice(0,this.contexts.length-e);t.push(this.contextIdforContexts(n))}t.push(""),this._currentContextIds=t}contextIdforContexts(t){return t?t.map((t=>0===t.id&&0===t.iterationId?"":`${t.frameName}-${t.iterationId}`)).join("/"):""}enterFrame(t){this.contexts&&(this.lastId++,this.contexts=this.contexts.slice(),this.contexts.push(this.newFrame(this.lastId,t)),this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)))}exitFrame(){if(!(this.contexts&&this.contexts.length>1))throw new Error("Cannot exit frame, the context is empty");this.contexts=this.contexts.slice(),this.contexts.splice(-1),this.currentContextIds.shift()}nextIteration(){if(!(this.contexts&&this.contexts.length>0))throw new Error("Cannot increase frame iteration, the context is empty");{this.contexts=this.contexts.slice(),this.lastId++;const t=Object.assign({},this.contexts[this.contexts.length-1]);t.iterationId+=1,t.id=this.lastId,this.contexts.splice(-1,1,t),this._currentContextIds.splice(0,1,this.contextIdforContexts(this.contexts))}}getWeight(t){return this.weightMap[t]}addTensorArray(t){this.tensorArrayMap[t.id]=t}getTensorArray(t){return this.tensorArrayMap[t]}addTensorList(t){this.tensorListMap[t.id]=t}getTensorList(t){return this.tensorListMap[t]}dispose(t){for(const e in this.tensorArrayMap)this.tensorArrayMap[e].clearAndClose(t);for(const e in this.tensorListMap)this.tensorListMap[e].clearAndClose(t)}}function hv(t,e,n,s){const r=new Set,a=[];let i=null,o=null;const l=new Set,u=Object.keys(t).map((t=>hN(t)[0]));let h=[];null!=s&&(h=s.map((t=>hN(t.name)[0])));const c=[...e];for(;c.length>0;){const t=c.pop();(fv(t)||mv(t)||gv(t))&&null==i&&(i=t,o=i.children.map((t=>t.name)).filter((t=>r.has(t)))),r.add(t.name),null==n[t.name]&&-1===u.indexOf(t.name)&&-1===h.indexOf(t.name)&&(0!==t.inputs.length?t.inputs.forEach((t=>{l.has(t.name)||(l.add(t.name),c.push(t))})):a.push(t.name))}return{inputs:t,outputs:e,usedNodes:r,missingInputs:a,dynamicNode:i,syncInputs:o}}const cv=["Switch","Merge","Enter","Exit","NextIteration","StatelessIf","StatelessWhile","if","While"],pv=["NonMaxSuppressionV2","NonMaxSuppressionV3","NonMaxSuppressionV5","Where"],dv=["HashTable","HashTableV2","LookupTableImport","LookupTableImportV2","LookupTableFind","LookupTableFindV2"];function fv(t){return cv.indexOf(t.op)>=0}function mv(t){return pv.indexOf(t.op)>=0}function gv(t){return dv.indexOf(t.op)>=0}class yv{constructor(t,e){this.graph=t,this.parent=e,this.compiledMap=new Map,this._weightMap={},this.SEPERATOR=",",this._functions={},this._functionExecutorMap={},this._outputs=t.outputs,this._inputs=t.inputs,this._initNodes=t.initNodes,this._signature=t.signature,this._functions=t.functions,null!=t.functions&&Object.keys(t.functions).forEach((e=>{this._functionExecutorMap[e]=new yv(t.functions[e],this)}))}get weightIds(){return this.parent?this.parent.weightIds:this._weightIds}get functionExecutorMap(){return this.parent?this.parent.functionExecutorMap:this._functionExecutorMap}get weightMap(){return this.parent?this.parent.weightMap:this._weightMap}set weightMap(t){const e=Object.keys(t).map((e=>t[e].map((t=>t.id))));this._weightIds=[].concat(...e),this._weightMap=t}set resourceManager(t){this._resourceManager=t}get inputs(){return this._inputs.map((t=>({name:t.name,shape:t.attrParams.shape?t.attrParams.shape.value:void 0,dtype:t.attrParams.dtype?t.attrParams.dtype.value:void 0})))}get outputs(){return this._outputs.map((t=>({name:t.name,shape:t.attrParams.shape?t.attrParams.shape.value:void 0,dtype:t.attrParams.dtype?t.attrParams.dtype.value:void 0})))}get inputNodes(){return this._inputs.map((t=>t.signatureKey||t.name))}get outputNodes(){return this._outputs.map((t=>{const e=t.signatureKey||t.name;return t.defaultOutput?`${e}:${t.defaultOutput}`:e}))}get functions(){return Object.keys(this._functions).reduce(((t,e)=>(t[e]=this._functions[e].signature,t)),{})}getCompilationKey(t,e){const n=t.map((t=>t.name)).sort(),s=e.map((t=>t.name)).sort();return n.join(this.SEPERATOR)+"--"+s.join(this.SEPERATOR)}compile(t,e){const n=hv(t,e,this.weightMap,this._initNodes),{missingInputs:s,dynamicNode:r,syncInputs:a}=n;if(null!=r)throw new Error(`This execution contains the node '${r.name}', which has the dynamic op '${r.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${a}]`);if(s.length>0){const n=e.map((t=>t.name)),r=Object.keys(t);throw new Error(`Cannot compute the outputs [${n}] from the provided inputs [${r}]. Missing the following inputs: [${s}]`)}return function(t,e,n){const{usedNodes:s,inputs:r}=n,a=[],i=Object.keys(r).map((t=>hN(t)[0])).map((e=>t.nodes[e])),o=t.initNodes;i.forEach((t=>{s.has(t.name)&&a.push(t)})),t.weights.forEach((t=>{s.has(t.name)&&a.push(t)})),null!=o&&o.forEach((t=>{s.has(t.name)&&a.push(t)}));const l=new Set,u=[];for(;a.length>0;){const t=a.pop();l.add(t.name),e[t.name]||u.push(t),t.children.forEach((t=>{!l.has(t.name)&&s.has(t.name)&&t.inputs.every((t=>l.has(t.name)))&&a.push(t)}))}return u}(this.graph,this.weightMap,n)}execute(t,e){t=this.mapInputs(t);const n=Object.keys(t).sort();this.checkInputs(t),this.checkInputShapeAndType(t),e=this.mapOutputs(e),this.checkOutputs(e);const s=n.map((t=>this.graph.nodes[hN(t)[0]])),r=e.map((t=>hN(t)[0]));let a=r.map((t=>this.graph.nodes[t]));0===a.length&&(a=this._outputs);const i=this.getCompilationKey(s,a);let o=this.compiledMap.get(i);null==o&&(o=this.compile(t,a),this.compiledMap.set(i,o));const l={},u={};return Xr((()=>{const n=new uv(this.weightMap,l,u,this.functionExecutorMap),s=Object.assign({},this.weightMap);Object.keys(t).forEach((e=>{const[n,r]=hN(e),a=[];a[r]=t[e],s[n]=a}));const a=this.getFrozenTensorIds(s),i={};for(let t=0;t<o.length;t++){const e=o[t];if(!s[e.name]){const t=lv(e,s,n,this._resourceManager);if(K(t))throw new Error(`The execution of the op '${e.op}' returned a promise. Please use model.executeAsync() instead.`);s[e.name]=t,this.checkTensorForDisposal(e.name,e,s,n,a,r,i)}}return null==this.parent&&n.dispose(a),e.map((t=>oN(t,s,n)))}))}getFrozenTensorIds(t){const e=[].concat.apply([],Object.keys(t).map((e=>t[e])).map((t=>t.map((t=>t.id)))));return new Set(e)}checkTensorForDisposal(t,e,n,s,r,a,i){"control"!==e.category&&-1===a.indexOf(t)&&(n[t].forEach((t=>{null!=t&&(i[t.id]=(i[t.id]||0)+e.children.length)})),e.inputs.forEach((t=>{if("control"!==t.category){const e=function(t,e,n){return e[uN(t,n.currentContextId)]}(t.name,n,s);null!=e&&e.forEach((t=>{if(t&&!r.has(t.id)){const e=i[t.id];1===e?(t.dispose(),delete i[t.id]):null!=e&&i[t.id]--}}))}})))}async executeAsync(t,e){return this._executeAsync(t,e)}async _executeAsync(t,e,n=!1,s={},r={}){n||(t=this.mapInputs(t),this.checkInputs(t),this.checkInputShapeAndType(t),e=this.mapOutputs(e),this.checkOutputs(e));const a=new uv(this.weightMap,s,r,this.functionExecutorMap),i=await this.executeWithControlFlow(t,a,e,n),o=e.map((t=>oN(t,i,a))),l=o.map((t=>t.id)),u=Object.keys(t).map((e=>t[e].id)),h=new Set([...l,...u,...this.weightIds]);return Object.keys(i).forEach((t=>{i[t].forEach((t=>{!t||t.isDisposed||h.has(t.id)||t.dispose()}))})),null==this.parent&&a.dispose(h),o}async executeFunctionAsync(t,e,n){const s=t.reduce(((t,e,n)=>(t[this.inputs[n].name]=e,t)),{});return this._executeAsync(s,this.outputNodes,!0,e,n)}async executeWithControlFlow(t,e,n,s){const r=Object.keys(t),a=r.map((t=>this.graph.nodes[hN(t)[0]])),i=n.map((t=>hN(t)[0]));let o=i.map((t=>this.graph.nodes[t]));0===o.length&&(o=this._outputs);const{usedNodes:l,missingInputs:u,dynamicNode:h,syncInputs:c}=hv(t,o,this.weightMap,this._initNodes),p=[...a,...this.graph.weights,...this._initNodes||[]].map((t=>({node:t,contexts:e.currentContext}))),d=Object.assign({},this.weightMap);Object.keys(t).forEach((e=>{const[n,s]=hN(e),r=[];r[s]=t[e],d[n]=r}));const f={},m=this.getFrozenTensorIds(d),g={};for(;p.length>0;){const t=this.processStack(a,p,e,d,g,m,i,f,l);await Promise.all(t)}null!=h||s||console.warn("This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.");const y=o.filter((t=>!fv(t)&&!oN(t.name,d,e))).map((t=>t.name));if(y.length>0){let t="";throw null!=h&&(t=`Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${c}]`),new Error(`Cannot compute the outputs [${y}] from the provided inputs [${r}]. Consider providing the following inputs: [${u}]. ${t}`)}return d}processStack(t,e,n,s,r,a,i,o,l){const u=[];for(;e.length>0;){const t=e.pop();n.currentContext=t.contexts;let h="";if("Enter"===t.node.op&&iN("isConstant",t.node,s,n)&&([h]=lN(t.node.name,n)),null==s[t.node.name]){const c=lv(t.node,s,n,this._resourceManager);h||([h]=lN(t.node.name,n));const p=n.currentContext;K(c)?u.push(c.then((u=>(s[h]=u,n.currentContext=p,this.checkTensorForDisposal(h,t.node,s,n,a,i,o),this.processChildNodes(t.node,e,n,s,r,l),u)))):(s[h]=c,this.checkTensorForDisposal(h,t.node,s,n,a,i,o),this.processChildNodes(t.node,e,n,s,r,l))}else this.processChildNodes(t.node,e,n,s,r,l)}return u}processChildNodes(t,e,n,s,r,a){t.children.forEach((t=>{const[i]=lN(t.name,n);!r[i]&&a.has(t.name)&&("Merge"===t.op?t.inputNames.some((t=>!!oN(t,s,n)))&&(r[i]=!0,e.push({contexts:n.currentContext,node:t})):t.inputNames.every((t=>!!oN(t,s,n)))&&(r[i]=!0,e.push({contexts:n.currentContext,node:t})))}))}dispose(){Object.keys(this.weightMap).forEach((t=>this.weightMap[t].forEach((t=>t.dispose()))))}checkInputShapeAndType(t){Object.keys(t).forEach((e=>{const n=t[e],[s]=hN(e),r=this.graph.nodes[s];if(r.attrParams.shape&&r.attrParams.shape.value){const t=r.attrParams.shape.value;v(t.length===n.shape.length&&n.shape.every(((e,n)=>-1===t[n]||t[n]===e)),(()=>`The shape of dict['${r.name}'] provided in model.execute(dict) must be [${t}], but was [${n.shape}]`))}r.attrParams.dtype&&r.attrParams.dtype.value&&v(n.dtype===r.attrParams.dtype.value,(()=>`The dtype of dict['${r.name}'] provided in model.execute(dict) must be ${r.attrParams.dtype.value}, but was ${n.dtype}`))}))}mapInputs(t){const e={};for(const n in t)null!=this._signature&&null!=this._signature.inputs&&null!=this._signature.inputs[n]?e[this._signature.inputs[n].name]=t[n]:e[n]=t[n];return e}checkInputs(t){const e=Object.keys(t).filter((t=>{const[e]=hN(t);return null==this.graph.nodes[e]}));if(e.length>0)throw new Error(`The dict provided in model.execute(dict) has keys: [${e}] that are not part of graph`)}mapOutputs(t){return t.map((t=>null!=this._signature&&null!=this._signature.outputs&&null!=this._signature.outputs[t]?this._signature.outputs[t].name:t),{})}checkOutputs(t){t.forEach((t=>{const[e]=hN(t);if(!this.graph.nodes[e])throw new Error(`The output '${t}' is not found in the graph`)}))}}class bv{constructor(t={},e={}){this.hashTableNameToHandle=t,this.hashTableMap=e}addHashTable(t,e){this.hashTableNameToHandle[t]=e.handle,this.hashTableMap[e.id]=e}getHashTableHandleByName(t){return this.hashTableNameToHandle[t]}getHashTableById(t){return this.hashTableMap[t]}dispose(){for(const t in this.hashTableMap)this.hashTableMap[t].clearAndClose(),delete this.hashTableMap[t];for(const t in this.hashTableNameToHandle)this.hashTableNameToHandle[t].dispose(),delete this.hashTableNameToHandle[t]}}class kv{constructor(t,e={}){this.modelUrl=t,this.loadOptions=e,this.version="n/a",null==e&&(this.loadOptions={}),this.resourceManager=new bv}get modelVersion(){return this.version}get inputNodes(){return this.executor.inputNodes}get outputNodes(){return this.executor.outputNodes}get inputs(){return this.executor.inputs}get outputs(){return this.executor.outputs}get weights(){return this.executor.weightMap}get metadata(){return this.artifacts.userDefinedMetadata}get modelSignature(){return this.signature}findIOHandler(){const t=this.modelUrl;if(null!=t.load)this.handler=t;else if(null!=this.loadOptions.requestInit)this.handler=zr(t,this.loadOptions);else{const e=Qs(t,this.loadOptions);if(0===e.length)e.push(zr(t,this.loadOptions));else if(e.length>1)throw new Error(`Found more than one (${e.length}) load handlers for URL '${[t]}'`);this.handler=e[0]}}async load(){if(this.findIOHandler(),null==this.handler.load)throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const t=await this.handler.load();return this.loadSync(t)}loadSync(t){this.artifacts=t;const e=this.artifacts.modelTopology;let n;n=null!=this.artifacts.userDefinedMetadata&&null!=this.artifacts.userDefinedMetadata.signature?this.artifacts.userDefinedMetadata.signature:this.artifacts.signature,this.signature=n,this.version=`${e.versions.producer}.${e.versions.minConsumer}`;const s=Hs(this.artifacts.weightData,this.artifacts.weightSpecs);if(this.executor=new yv($N.Instance.transformGraph(e,this.signature)),this.executor.weightMap=this.convertTensorMapToTensorsMap(s),this.executor.resourceManager=this.resourceManager,null!=t.modelInitializer&&null!=t.modelInitializer.node){const e=$N.Instance.transformGraph(t.modelInitializer);this.initializer=new yv(e),this.initializer.weightMap=this.executor.weightMap,this.initializer.resourceManager=this.resourceManager,this.initializer.executeAsync({},[])}return!0}async save(t,e){if("string"==typeof t){const e=Xs(t);if(0===e.length)throw new Error(`Cannot find any save handlers for URL '${t}'`);if(e.length>1)throw new Error(`Found more than one (${e.length}) save handlers for URL '${t}'`);t=e[0]}if(null==t.save)throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");return t.save(this.artifacts)}predict(t,e){return this.execute(t,this.outputNodes)}normalizeInputs(t){if(!(t instanceof ms||Array.isArray(t)))return t;if((t=Array.isArray(t)?t:[t]).length!==this.inputNodes.length)throw new Error(`Input tensor count mismatch,the graph model has ${this.inputNodes.length} placeholders, while there are ${t.length} input tensors.`);return this.inputNodes.reduce(((e,n,s)=>(e[n]=t[s],e)),{})}normalizeOutputs(t){return t=t||this.outputNodes,Array.isArray(t)?t:[t]}execute(t,e){t=this.normalizeInputs(t),e=this.normalizeOutputs(e);const n=this.executor.execute(t,e);return n.length>1?n:n[0]}async executeAsync(t,e){t=this.normalizeInputs(t),e=this.normalizeOutputs(e);const n=await this.executor.executeAsync(t,e);return n.length>1?n:n[0]}convertTensorMapToTensorsMap(t){return Object.keys(t).reduce(((e,n)=>(e[n]=[t[n]],e)),{})}dispose(){this.executor.dispose(),this.initializer&&this.initializer.dispose(),this.resourceManager.dispose()}}async function wv(t,e={}){if(null==t)throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");null==e&&(e={}),e.fromTFHub&&null==t.load&&(t.endsWith("/")||(t+="/"),t=`${t}model.json?tfjs-format=file`);const n=new kv(t,e);return await n.load(),n}function xv(t,e,n,s){return new(n||(n=Promise))((function(r,a){function i(t){try{l(s.next(t))}catch(t){a(t)}}function o(t){try{l(s.throw(t))}catch(t){a(t)}}function l(t){t.done?r(t.value):new n((function(e){e(t.value)})).then(i,o)}l((s=s.apply(t,e||[])).next())}))}function Nv(t,e){var n,s,r,a,i={label:0,sent:function(){if(1&r[0])throw r[1];return r[1]},trys:[],ops:[]};return a={next:o(0),throw:o(1),return:o(2)},"function"==typeof Symbol&&(a[Symbol.iterator]=function(){return this}),a;function o(a){return function(o){return function(a){if(n)throw new TypeError("Generator is already executing.");for(;i;)try{if(n=1,s&&(r=2&a[0]?s.return:a[0]?s.throw||((r=s.return)&&r.call(s),0):s.next)&&!(r=r.call(s,a[1])).done)return r;switch(s=0,r&&(a=[2&a[0],r.value]),a[0]){case 0:case 1:r=a;break;case 4:return i.label++,{value:a[1],done:!1};case 5:i.label++,s=a[1],a=[0];continue;case 7:a=i.ops.pop(),i.trys.pop();continue;default:if(!(r=(r=i.trys).length>0&&r[r.length-1])&&(6===a[0]||2===a[0])){i=0;continue}if(3===a[0]&&(!r||a[1]>r[0]&&a[1]<r[3])){i.label=a[1];break}if(6===a[0]&&i.label<r[1]){i.label=r[1],r=a;break}if(r&&i.label<r[2]){i.label=r[2],i.ops.push(a);break}r[2]&&i.ops.pop(),i.trys.pop();continue}a=e.call(t,i)}catch(t){a=[6,t],s=0}finally{n=r=0}if(5&a[0])throw a[1];return{value:a[0]?a[1]:void 0,done:!0}}([a,o])}}}var vv=function(t){return{startEndTensor:t,startPoint:Hi(t,[0,0],[-1,2]),endPoint:Hi(t,[0,2],[-1,2])}},Iv={strides:[8,16],anchors:[2,6]};function Sv(t,e){var n,s,r;if(t.topLeft instanceof ms&&t.bottomRight instanceof ms){var a=Xr((function(){return[$a([Hi(oi(e-1,t.topLeft),0,1),Hi(t.topLeft,1,1)]),$a([oi(e-1,Hi(t.bottomRight,0,1)),Hi(t.bottomRight,1,1)])]}));n=a[0],s=a[1],null!=t.landmarks&&(r=Xr((function(){var n=oi(no([e-1,0]),t.landmarks),s=no([1,-1]);return ii(n,s)})))}else{var i=t.topLeft,o=i[0],l=i[1],u=t.bottomRight,h=u[0],c=u[1];n=[e-1-o,l],s=[e-1-h,c],null!=t.landmarks&&(r=t.landmarks.map((function(t){return[e-1-t[0],t[1]]})))}var p={topLeft:n,bottomRight:s};return null!=r&&(p.landmarks=r),null!=t.probability&&(p.probability=t.probability instanceof ms?t.probability.clone():t.probability),p}function Tv(t,e){return Xr((function(){var n;return n=t.hasOwnProperty("box")?t.box:t,Qi(function(t,e){var n=ii(t.startPoint,e),s=ii(t.endPoint,e),r=Fa([n,s],1);return vv(r)}(n,e).startEndTensor)}))}var Ev=function(){function t(t,e,n,s,r,a){this.blazeFaceModel=t,this.width=e,this.height=n,this.maxFaces=s,this.anchorsData=function(t,e,n){for(var s=[],r=0;r<n.strides.length;r++)for(var a=n.strides[r],i=Math.floor((e+a-1)/a),o=Math.floor((t+a-1)/a),l=n.anchors[r],u=0;u<i;u++)for(var h=a*(u+.5),c=0;c<o;c++)for(var p=a*(c+.5),d=0;d<l;d++)s.push([p,h]);return s}(e,n,Iv),this.anchors=so(this.anchorsData),this.inputSizeData=[e,n],this.inputSize=no([e,n]),this.iouThreshold=r,this.scoreThreshold=a}return t.prototype.getBoundingBoxes=function(t,e,n){return void 0===n&&(n=!0),xv(this,void 0,void 0,(function(){var s,r,a,i,o,l,u,h,c,p,d,f,m,g,y=this;return Nv(this,(function(b){switch(b.label){case 0:return s=Xr((function(){var e=pl.resizeBilinear(t,[y.width,y.height]),n=ii(oi(Va(e,255),.5),2),s=y.blazeFaceModel.predict(n),r=Qi(s),a=function(t,e,n){var s=Hi(t,[0,1],[-1,2]),r=aa(s,e),a=Hi(t,[0,3],[-1,2]),i=Va(a,n),o=Va(r,n),l=Va(i,2),u=oi(o,l),h=aa(o,l),c=ii(u,n),p=ii(h,n);return Fa([c,p],1)}(r,y.anchors,y.inputSize),i=Hi(r,[0,0],[-1,1]);return[r,a,Qi(Ui(i))]})),r=s[0],a=s[1],i=s[2],o=console.warn,console.warn=function(){},l=pl.nonMaxSuppression(a,i,this.maxFaces,this.iouThreshold,this.scoreThreshold),console.warn=o,[4,l.array()];case 1:return u=b.sent(),l.dispose(),h=u.map((function(t){return Hi(a,[t,0],[1,-1])})),e?[3,3]:[4,Promise.all(h.map((function(t){return xv(y,void 0,void 0,(function(){var e;return Nv(this,(function(n){switch(n.label){case 0:return[4,t.array()];case 1:return e=n.sent(),t.dispose(),[2,e]}}))}))})))];case 2:h=b.sent(),b.label=3;case 3:for(c=t.shape[1],p=t.shape[2],d=e?Va([p,c],this.inputSize):[p/this.inputSizeData[0],c/this.inputSizeData[1]],f=[],m=function(t){var s=h[t],a=Xr((function(){var a=vv(s instanceof ms?s:so(s));if(!n)return a;var o,l=u[t];return o=e?Hi(y.anchors,[l,0],[1,2]):y.anchorsData[l],{box:a,landmarks:Na(Qi(Hi(r,[l,5],[1,-1])),[6,-1]),probability:Hi(i,[l],[1]),anchor:o}}));f.push(a)},g=0;g<h.length;g++)m(g);return a.dispose(),i.dispose(),r.dispose(),[2,{boxes:f,scaleFactor:d}]}}))}))},t.prototype.estimateFaces=function(t,e,n,s){return void 0===e&&(e=!1),void 0===n&&(n=!1),void 0===s&&(s=!0),xv(this,void 0,void 0,(function(){var r,a,i,o,l,u,h=this;return Nv(this,(function(c){switch(c.label){case 0:return r=function(t){return t instanceof ms?[t.shape[0],t.shape[1]]:[t.height,t.width]}(t),a=r[1],i=Xr((function(){return t instanceof ms||(t=Lr(t)),Ka(Ir(t,"float32"),0)})),[4,this.getBoundingBoxes(i,e,s)];case 1:return o=c.sent(),l=o.boxes,u=o.scaleFactor,i.dispose(),e?[2,l.map((function(t){var e=Tv(t,u),r={topLeft:Hi(e,[0],[2]),bottomRight:Hi(e,[2],[2])};if(s){var i=t,o=i.landmarks,l=i.probability,h=i.anchor,c=ii(aa(o,h),u);r.landmarks=c,r.probability=l}return n&&(r=Sv(r,a)),r}))]:[2,Promise.all(l.map((function(t){return xv(h,void 0,void 0,(function(){var e,r,i,o,l,h,c,p,d,f,m,g=this;return Nv(this,(function(y){switch(y.label){case 0:return e=Tv(t,u),s?[3,2]:[4,e.array()];case 1:return l=y.sent(),r={topLeft:l.slice(0,2),bottomRight:l.slice(2)},[3,4];case 2:return[4,Promise.all([t.landmarks,e,t.probability].map((function(t){return xv(g,void 0,void 0,(function(){return Nv(this,(function(e){return[2,t.array()]}))}))})))];case 3:i=y.sent(),o=i[0],l=i[1],h=i[2],c=t.anchor,d=(p=u)[0],f=p[1],m=o.map((function(t){return[(t[0]+c[0])*d,(t[1]+c[1])*f]})),r={topLeft:l.slice(0,2),bottomRight:l.slice(2),landmarks:m,probability:h},function(t){t.startEndTensor.dispose(),t.startPoint.dispose(),t.endPoint.dispose()}(t.box),t.landmarks.dispose(),t.probability.dispose(),y.label=4;case 4:return e.dispose(),n&&(r=Sv(r,a)),[2,r]}}))}))})))]}}))}))},t}();const Av=n.p+"60dd8cd9d151dd56a6f22090571eed30.json",Dv=(n.p,n.p,n.p,n.p,n.p,n.p,n.p,n.p,n.p,n.p,n.p,n.p,n.p,n.p,n.p,n.p,n.p,n.p,n.p,[48,48]),$v={0:{label:"angry",emoji:""},1:{label:"disgust",emoji:""},2:{label:"fear",emoji:""},3:{label:"happy",emoji:""},4:{label:"sad",emoji:""},5:{label:"surprise",emoji:""},6:{label:"neutral",emoji:""}},Mv=async t=>{const e=await function(t){var e={},n=e.maxFaces,s=void 0===n?10:n,r=e.inputWidth,a=void 0===r?128:r,i=e.inputHeight,o=void 0===i?128:i,l=e.iouThreshold,u=void 0===l?.3:l,h=e.scoreThreshold,c=void 0===h?.75:h;return xv(this,void 0,void 0,(function(){var t;return Nv(this,(function(e){switch(e.label){case 0:return[4,wv("https://tfhub.dev/tensorflow/tfjs-model/blazeface/1/default/1",{fromTFHub:!0})];case 1:return t=e.sent(),[2,new Ev(t,a,o,s,u,c)]}}))}))}(),n=await e.estimateFaces(t,!1,!1,!1);for(const t of n){const e=[t.topLeft[1],t.topLeft[0]],n=[t.bottomRight[1],t.bottomRight[0]],s=n[1]-e[1]-(n[0]-e[0]);t.topLeft[1]-=s/2,t.bottomRight[1]+=s/2}return n},Fv=async t=>{const e=await(n=Av,null==s&&(s={}),async function(t,e){if(null==e&&(e={}),"string"==typeof t){const n=Qs(t,e);if(0===n.length)n.push(zr(t,e));else if(n.length>1)throw new Cc(`Found more than one (${n.length}) load handlers for URL '${t}'`);t=n[0]}return async function(t,e,n){if(null==n&&(n={}),null==t.load)throw new Cc("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const s=await t.load();let r=s.modelTopology;null!=r.model_config&&(r=r.model_config);const a=null==n.strict||n.strict,i=null!=s.weightData&&null!=s.weightSpecs&&a,o=Kd(xf(r),void 0,i),l=s.trainingConfig;if(null!=l&&o.loadTrainingConfig(l),null!=s.userDefinedMetadata&&o.setUserDefinedMetadata(s.userDefinedMetadata),null!=s.weightData){if(null==s.weightSpecs)throw new Cc("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");const{modelWeights:t,optimizerWeights:e}=function(t,e){const n=Hs(t,e),s={},r=[];return e.forEach((t=>{"optimizer"===t.group?r.push({name:t.name,tensor:n[t.name]}):s[t.name]=n[t.name]})),{modelWeights:s,optimizerWeights:r}}(s.weightData,s.weightSpecs);o.loadWeights(t,a),null!=o.optimizer&&e.length>0&&await o.optimizer.setWeights(e),Qr(t),Qr(e.map((t=>t.tensor)))}return o}(t,0,e)}(n,s));var n,s;const r=(await e.predict(t).data()).reduce(((t,e,n,s)=>e>s[t]?n:t),0);return $v[r]};var _v=n(238),zv=n.n(_v);const Cv=document.getElementById("imgCanvas"),Ov=Cv.getContext("2d"),Lv=document.getElementById("imgUpload"),Rv=document.getElementById("faces"),Bv=document.getElementById("log"),Wv=t=>{t?(Bv.innerHTML=t,Bv.classList.add("visible")):Bv.classList.remove("visible")},Pv=(t,e)=>{const n=document.createElement("DIV");n.classList.add("face-image__wrapper");const s=document.createElement("CANVAS");s.width=48,s.height=48;const r=s.getContext("2d");let a=r.createImageData(s.width,s.height);for(let e=0;e<t.length&&e<a.data.length;e++)a.data[e]=t[e];r.putImageData(a,0,0),n.appendChild(s);const i=document.createElement("P");i.innerHTML=`${e.emoji} ${e.label}`,n.appendChild(i),Rv.appendChild(n)},Vv=async t=>{(t=>{if(t instanceof HTMLElement==0)throw Error("The handed over img is no HTMLElement");const e=Cv.width/t.width;Cv.height=t.height*e,Ov.clearRect(0,0,Cv.width,Cv.height),Ov.drawImage(t,0,0,Cv.width,Cv.height)})(t);const{facePositions:e,faceImages:n,emotions:s}=await(async t=>{await $s.setBackend("cpu");const e=await Mv(t);if(0===e.length)return!1;const n=Lr(t).expandDims(0),s=await Promise.all(e.map((t=>(async(t,e)=>{const n=t.shape.slice(1,3),s=[e.topLeft[1],e.topLeft[0]],r=[e.bottomRight[1],e.bottomRight[0]],a=Va(s,n).dataSync(),i=Va(r,n).dataSync(),o=$a([a,i]).expandDims(0);return pl.cropAndResize(t,o,[0],Dv).div(na(255)).mean(3,!1).toFloat().expandDims(3)})(n,t))));if(0===s.length)return!1;const r=await Promise.all(s.map((t=>Fv(t)))),a=[];for(const t of s){const e=t.reshape([...Dv,1]);a.push(await Or(e))}return{facePositions:e,faceImages:a,emotions:r}})(t);if(!e)return Wv(" Couldn't detect any faces."),!1;if(!n)return Wv(" Couldn't extract face images."),!1;if(!s)return Wv(" Couldn't classify emotions."),!1;((t,e,n)=>{Ov.lineWidth="3",Ov.strokeStyle="#00ff00",Ov.font="20px Arial";for(let s=0;s<e.length;s++){let{topLeft:r,bottomRight:a}=e[s];const i=Cv.width/t.width;r[0]*=i,r[1]*=i,a[0]*=i,a[1]*=i;const o=[a[0]-r[0],a[1]-r[1]];Ov.strokeRect(r[0],r[1],o[0],o[1]),Ov.fillText(n[s].emoji,r[0]+-10,r[1]+7)}})(t,e,s);for(let t=0;t<n.length;t++)Pv(n[t],s[t]);Wv("")},Uv=t=>{Rv.innerHTML="",Wv("Loading...");const e=new Image;e.src=t,e.onload=()=>Vv(e)};Lv.onchange=()=>{const t=Lv.files[0],e=new FileReader;e.onload=t=>{Uv(t.target.result)},e.readAsDataURL(t)},Uv(zv())})()})();